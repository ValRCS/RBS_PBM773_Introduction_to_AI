{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents in Artificial Intelligence\n",
    "\n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2010.31.47%20-%20A%20picture%20of%20a%20robot%20that%20has%20features%20resembling%20Albert%20Einstein's%20distinctive%20hair.%20The%20robot%20should%20have%20a%20humanoid%20appearance%20with%20a%20metallic%20body.png?raw=true\" width=\"400\">\n",
    "\n",
    "Intelligent Agent is an autonomous entity which observes through sensors and acts upon an environment using actuators (i.e. it is an agent) and directs its activity towards achieving goals (i.e. it is 'rational', as defined in economics). Intelligent agents may also learn or use knowledge to achieve their goals. They may be very simple or very complex. A reflex machine, such as a thermostat, is considered an example of an intelligent agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2010.26.11%20-%20A%20picture%20of%20a%20modern%20thermostat%20mounted%20on%20a%20wall.%20The%20thermostat%20should%20have%20a%20sleek,%20contemporary%20design%20with%20a%20digital%20display%20showing%20the%20current.png?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older thermostat - agent?\n",
    "\n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2010.27.27%20-%20A%20picture%20of%20an%20older%20thermostat%20from%20the%20early%2020th%20century.%20The%20thermostat%20should%20have%20a%20vintage%20design,%20featuring%20a%20round,%20dial-type%20mechanism%20with.png?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of the Lecture\n",
    "\n",
    "\n",
    "- **Agents and Environment**\n",
    "   - Definition of Agents\n",
    "   - Types of Agents\n",
    "   - Understanding the Environment\n",
    "   - Agent-Environment Interaction\n",
    "- **Good Behavior: The Concept of Rationality**\n",
    "   - Defining Rationality in AI\n",
    "   - Rationality vs. Perfection\n",
    "   - Rationality and the Agent's Performance Measure\n",
    "   - Rationality in Different Environments\n",
    "- **The Nature of Environments**\n",
    "   - Properties of Environments\n",
    "   - Classifying Environments\n",
    "   - How Agents Perceive Their Environment\n",
    "   - Challenges Posed by Different Types of Environments\n",
    "- **The Structure of Agents**\n",
    "   - Basic Agent Structure\n",
    "   - Agent Program and Agent Architecture\n",
    "   - Examples of Various Agent Structures\n",
    "   - How Agent Structure Influences Interaction with the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/IntelligentAgent-SimpleReflex.svg/962px-IntelligentAgent-SimpleReflex.svg.png?20211115214238\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents and Environment\n",
    "\n",
    "\n",
    "- **Agents and Environment**\n",
    "   - **Definition of Agents**\n",
    "      - Understanding what constitutes an agent in AI.\n",
    "      - Characteristics of agents (autonomy, ability to perceive their environment, and ability to act upon that environment).\n",
    "   - **Types of Agents**\n",
    "      - Simple Reflex Agents: Act solely on the current percept.\n",
    "      - Model-based Reflex Agents: Consider the current state of the world in their decision-making.\n",
    "      - Goal-based Agents: Act to achieve their goals.\n",
    "      - Utility-based Agents: Act to maximize a given utility function.\n",
    "      - Learning Agents: Adapt and improve their performance over time.\n",
    "   - **Understanding the Environment**\n",
    "      - The concept of the environment in which agents operate.\n",
    "      - Characteristics of environments: dynamic vs. static, discrete vs. continuous, deterministic vs. stochastic.\n",
    "      - How different environments affect agent design and functionality.\n",
    "   - **Agent-Environment Interaction**\n",
    "      - How agents perceive their environment (sensors) and act upon it (actuators).\n",
    "      - The percept sequence and its role in decision-making.\n",
    "      - The feedback loop between agents and their environment.\n",
    "      - Examples of agent-environment interactions in different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Behavior: The Concept of Rationality\n",
    "\n",
    "  - **Defining Rationality in AI**\n",
    "      - Explanation of rationality as the ability to make the best decision given the information and resources available.\n",
    "      - Distinction between rationality and omniscience; rational agents do not necessarily have perfect information.\n",
    "      \n",
    "   - **Rationality vs. Perfection**\n",
    "      - Discussion on how rationality does not equate to perfection.\n",
    "      - Examples demonstrating that rational decisions may not always lead to the best outcome due to limited information or unforeseen circumstances.\n",
    "   - **Rationality and the Agent's Performance Measure**\n",
    "      - Introduction to performance measures as a way to evaluate an agent's behavior.\n",
    "      - Explanation of how rational behavior is relative to the agent's performance measure and the perceived environment.\n",
    "      - Case studies or examples where different performance measures lead to different notions of rationality.\n",
    "   - **Rationality in Different Environments**\n",
    "      - Analysis of how the nature of the environment affects what is considered rational behavior.\n",
    "      - Comparison of rational behavior in various environments (static vs. dynamic, deterministic vs. stochastic, etc.).\n",
    "      - Discussion of the challenges in designing rational agents for complex, real-world environments.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Good Behavior\n",
    "\n",
    "- **Defining Rationality in AI**\n",
    "   - **Example**: Consider a chess-playing AI. Rationality in this context means choosing the best move based on the current state of the board, the rules of chess, and its programmed strategy. The AI does not need to predict future moves perfectly; it just needs to make the best move considering what it knows at that moment.\n",
    "- **Rationality vs. Perfection**\n",
    "   - **Example**: Imagine a weather prediction AI. It makes forecasts based on current data and models. A rational weather AI may predict rain, which is a reasonable conclusion based on the data. However, if unforeseen conditions change and it doesn't rain, the AI's decision was still rational, even though the outcome wasn't perfect.\n",
    "\n",
    "   <img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2010.18.01%20-%20An%20illustration%20depicting%20changing%20weather%20conditions.%20The%20scene%20should%20be%20divided%20into%20three%20distinct%20parts_%20one%20part%20showing%20snowy%20weather%20with%20snow.png?raw=true\" width=\"400\">\n",
    "- **Rationality and the Agent's Performance Measure**\n",
    "   - **Example**: In a stock trading AI, the performance measure might be maximizing financial return. A rational decision in this scenario would be one that maximizes expected returns based on available market data. However, if the performance measure was to minimize risk, the AI's decisions might be different, focusing more on safe investments.\n",
    "- **Rationality in Different Environments**\n",
    "   - **Example**: For an autonomous car navigating in a controlled environment (like a well-mapped, low-traffic area), rational behavior involves straightforward route planning and obstacle avoidance. However, the same car in a dynamic, unpredictable environment (like a busy city center) requires more complex rational behavior, such as responding to unexpected pedestrian movements or navigating around sudden road closures.\n",
    "\n",
    "These examples demonstrate how rationality in AI is context-dependent, and how an agent's decision-making process can vary based on its environment, the information available, and its predefined goals or performance measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nature of Environments\n",
    "\n",
    " - **Properties of Environments**\n",
    "      - **Fully Observable vs. Partially Observable**: In a fully observable environment, the agent has access to the complete state of the environment at all times. For example, a chess game where all pieces are visible. In contrast, in a partially observable environment, like playing poker, some information is hidden from the agent.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-10%2021.48.50%20-%20A%20drawing%20of%20two%20robots%20sitting%20at%20a%20table,%20engaged%20in%20a%20game%20of%20poker.%20The%20robots%20should%20have%20a%20humanoid%20appearance%20with%20metallic%20bodies.%20They%20are%20si.png?raw=true\" width=\"400\">\n",
    "\n",
    "      - **Deterministic vs. Stochastic**: A deterministic environment is predictable and the next state is completely determined by the current state and action. An automated production line can be a deterministic environment. A stochastic environment has elements of unpredictability, like driving in varying traffic conditions.\n",
    "\n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2013.31.53%20-%20A%20picture%20of%20an%20automated%20production%20line%20for%20cars.%20The%20scene%20should%20depict%20a%20modern,%20industrial%20factory%20setting%20with%20robotic%20arms%20and%20machinery%20assem.png?raw=true\" width=\"400\">\n",
    "\n",
    "      - **Episodic vs. Sequential**: In episodic environments, each decision is isolated, such as a factory robot performing a repetitive task. In sequential environments, current decisions impact future decisions, like in long-term strategic business planning.\n",
    "      \n",
    "      - **Static vs. Dynamic**: A static environment remains unchanged until the agent acts, like a puzzle. A dynamic environment changes with or without the agent's actions, such as monitoring and responding to stock market fluctuations.\n",
    "      - **Discrete vs. Continuous**: Discrete environments have a limited number of distinct states, like a turn-based board game. Continuous environments have a range of states, such as an autonomous car navigating a city.\n",
    "   - **Classifying Environments**\n",
    "      - Explanation of how different environments require different types of agents.\n",
    "      - Examples of real-life AI applications in various types of environments.\n",
    "   - **How Agents Perceive Their Environment**\n",
    "      - Discussion on the role of sensors in perception.\n",
    "      - Examples of different sensing mechanisms in AI, like computer vision in autonomous vehicles or natural language processing in chatbots.\n",
    "   - **Challenges Posed by Different Types of Environments**\n",
    "      - Analysis of the complexities and AI design challenges in different environments.\n",
    "      - Real-life case studies, such as the difference in complexity between a warehouse sorting robot (more controlled environment) and a self-driving car in a city (less controlled, more variables).\n",
    "   \n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch2_intelligent_agents/DALL%C2%B7E%202024-01-11%2010.30.33%20-%20A%20top-down%20view%20of%20a%20bustling%20city%20with%20many%20taxi%20cars%20driving.%20The%20illustration%20should%20show%20a%20dense%20urban%20layout%20with%20a%20grid%20of%20streets%20filled%20with%20n.png?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Agents\n",
    "\n",
    " - **Basic Agent Structure**\n",
    "      - Description of the fundamental components of an AI agent: sensors (for perceiving the environment), actuators (for acting upon the environment), and the agent program (which decides actions based on perceptions).\n",
    "      - **Example**: A robotic vacuum cleaner uses sensors to detect dirt and obstacles, actuators to move and clean, and its programming to decide its path.\n",
    "   - **Agent Program and Agent Architecture**\n",
    "      - Explanation of how the agent program processes inputs (from sensors) and determines outputs (to actuators), and how the architecture (the hardware or software environment) supports this program.\n",
    "      - **Example**: In a recommendation system, the agent program analyzes user data and outputs recommendations. The architecture includes the database of user preferences and the algorithms for processing this data.\n",
    "   - **Examples of Various Agent Structures**\n",
    "      - Reflex Agents: Respond directly to percepts.\n",
    "         - **Example**: A spam filter that classifies emails as spam or not based on specific keywords.\n",
    "      - Model-Based Reflex Agents: Maintain an internal state to track aspects of the world.\n",
    "         - **Example**: A smart thermostat that adjusts the temperature based on the time of day and the current temperature.\n",
    "      - Goal-Based Agents: Take actions to achieve goals.\n",
    "         - **Example**: A navigation system in a car that plans routes based on the destination.\n",
    "      - Utility-Based Agents: Aim to maximize a utility function.\n",
    "         - **Example**: A stock-trading bot that makes buying or selling decisions to maximize financial profit.\n",
    "      - Learning Agents: Improve performance based on past experiences.\n",
    "         - **Example**: An AI in a video game that adapts its strategy based on the player's actions.\n",
    "      - **How Agent Structure Influences Interaction with the Environment**\n",
    "      - Discussion on the suitability of different agent structures for different environments and tasks.\n",
    "      - **Example**: Reflex agents are suitable for simple, predictable environments, like assembly lines in a factory. In contrast, learning agents are better for complex, unpredictable environments, like navigating traffic for autonomous vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Agents and Environment**\n",
    "   - Definition and types of agents (Simple Reflex, Model-based Reflex, Goal-based, Utility-based, Learning agents).\n",
    "   - Characteristics and interaction of agents with their environment.\n",
    "   - Role of sensors and actuators in perceiving and acting within the environment.\n",
    "- **Good Behavior: The Concept of Rationality**\n",
    "   - Rationality as making the best decision based on available information.\n",
    "   - Distinction between rationality and perfection; decision-making in uncertain environments.\n",
    "   - The importance of the agent's performance measure in defining rational behavior.\n",
    "   - Rationality's dependence on the nature of the agent's task and environment.\n",
    "- **The Nature of Environments**\n",
    "   - Characteristics of environments: fully vs. partially observable, deterministic vs. stochastic, episodic vs. sequential, static vs. dynamic, discrete vs. continuous.\n",
    "   - How different environments impact the design and function of agents.\n",
    "   - The challenges and complexities posed by various types of environments.\n",
    "- **The Structure of Agents**\n",
    "   - Basic structure of agents: sensors, actuators, and agent programs.\n",
    "   - Different types of agent structures: Reflex agents, Model-based reflex agents, Goal-based agents, Utility-based agents, Learning agents.\n",
    "   - The influence of agent structure on its ability to interact effectively with the environment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

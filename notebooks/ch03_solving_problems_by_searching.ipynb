{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxUaSOl19vIe"
      },
      "source": [
        "# Chapter 3 - Solving Problems with Search\n",
        "\n",
        "- **Chapter 3 Overview**: Focuses on problem-solving through search, demonstrating how an agent plans a sequence of actions to achieve a goal.\n",
        "- **Problem-solving Agent**: An agent that needs to plan a series of actions leading to a goal state; involves a computational process known as search.\n",
        "- **Atomic Representations**: Used by problem-solving agents, where states of the world are considered as indivisible wholes without internal structure (referenced from Section 2.4.7).\n",
        "- **Contrast with Planning Agents**: Planning agents, using factored or structured state representations, are discussed in later chapters (7 and 11).\n",
        "- **Search Algorithms**: Introduction to several search algorithms within simple environments characterized by being episodic, single-agent, fully observable, deterministic, static, discrete, and known.\n",
        "- **Informed vs. Uninformed Algorithms**: Distinction between algorithms where agents can estimate distance to the goal (informed) and those without such estimates (uninformed).\n",
        "- **Expansion in Subsequent Chapters**: Chapter 4 expands on environmental constraints, and Chapter 6 delves into scenarios involving multiple agents.\n",
        "- **Asymptotic Complexity**: The chapter employs concepts of asymptotic complexity, specifically O(n) notation, to describe algorithm efficiency.\n",
        "- **Search Trees**: The chapter uses search trees to represent the search space, where nodes represent states and edges represent actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zIqr9fO9vIw"
      },
      "source": [
        "## 3.1 Problem-Solving Agents\n",
        "\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/DALL%C2%B7E%202024-01-15%2012.42.35%20-%20Illustration%20of%20a%20problem-solving%20agent%20on%20vacation%20in%20Romania,%20traveling%20by%20car.%20The%20image%20should%20depict%20a%20humanoid%20figure,%20representing%20the%20agent,%20d.png?raw=true\" width=\"400\">\n",
        "\n",
        "- **Scenario Description**: An agent on vacation in Romania, starting in Arad and needing to reach Bucharest with limited knowledge of the area.\n",
        "\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/romania.jpg?raw=true\" width=\"400\">\n",
        "\n",
        "- **Problem Complexity**: Agent faces a complex decision problem due to unfamiliar geography and multiple choices (Sibiu, Timisoara, Zerind).\n",
        "- **Agent's Challenge in Unknown Environment**: Without additional information, the agent might choose actions randomly, a situation explored in Chapter 4.\n",
        "- **Four-Phase Problem-Solving Process**:\n",
        "   - **Goal Formulation**: Agent sets a clear objective (reaching Bucharest), simplifying decision-making by focusing on relevant actions.\n",
        "   - **Problem Formulation**: Agent develops an abstract model of the relevant world, here considering travel between adjacent cities, with the changing state being the current city.\n",
        "   - **Search**: Agent simulates action sequences in the model to find a solution (e.g., traveling through Sibiu, Fagaras to Bucharest) before acting in the real world.\n",
        "   - **Execution**: Once a solution is found, the agent executes the planned actions sequentially.\n",
        "\n",
        "- **Fixed Action Sequences in Certain Environments**: In fully observable, deterministic, known environments, a problem's solution is a fixed sequence of actions.\n",
        "- **Open-Loop System**: In such environments, the agent can ignore percepts during execution, as the solution is guaranteed if the model is correct.\n",
        "\n",
        "- **Adaptation in Less Predictable Environments**: In partially observable or nondeterministic environments, solutions involve branching strategies with contingency plans based on potential percepts (e.g., alternative routes in case of unexpected circumstances like road closures)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GxsQhyg9vI0"
      },
      "source": [
        "### 3.1.1 Search Problems and Solutions\n",
        "\n",
        "- **Formal Definition of a Search Problem**:\n",
        "   - **State Space**: A set of possible states in which the environment can exist.\n",
        "   - **Initial State**: The starting point of the agent, e.g., Arad.\n",
        "   - **Goal States**: One or more desired states. The goal might be a single state (like Bucharest), a set of states, or defined by a certain property applicable to many states.\n",
        "   - **IS-GOAL Method**: A method to determine if a state is a goal, accommodating various types of goal states.\n",
        "   - **Actions**: Defined for each state; `ACTIONS(s)` returns a set of actions executable in state `s`.\n",
        "   - **Transition Model**: Describes the outcome of actions; `RESULT(s, a)` gives the state resulting from action `a` in state `s`.\n",
        "   - **Action Cost Function**: Denoted as `ACTION-COST(S,a, s')` or `c(s, a, s')`, it quantifies the cost of performing action `a` in state `s` to reach state `s'`. Reflects the agent's performance measure (e.g., distance, time).\n",
        "\n",
        "#### **Solution and Path**:\n",
        "\n",
        "\n",
        "- **Path**: A sequence of actions.\n",
        "- **Solution**: A path leading from the initial state to a goal state.\n",
        "- **Optimal Solution**: The solution with the lowest path cost among all solutions.\n",
        "- **Assumption of Additive Action Costs**: Total path cost is the sum of individual action costs.\n",
        "- **Positive Action Costs**: Assumes all action costs are positive to avoid complications.\n",
        "\n",
        "#### **Graphical Representation**:\n",
        "\n",
        "\n",
        "- **State Space as a Graph**: States as vertices and actions as directed edges.\n",
        "- **Example**: The map of Romania, where roads represent actions between cities (states).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2LG1qmR9vI2"
      },
      "source": [
        "### 3.1.2 Formulating Problems\n",
        "\n",
        "- **Problem Formulation as a Model**: The process of getting to Bucharest is an abstract mathematical model, not an exact representation of reality.\n",
        "   - **Example of Simplification**: The model uses simple state descriptions like \"Arad\" instead of detailed real-world elements (travel companions, radio program, scenery, law enforcement proximity, etc.).\n",
        "\n",
        "#### **Abstraction in Problem Formulation**:\n",
        "- **Definition**: Removing irrelevant details to focus on key aspects of the problem.\n",
        "- **Importance of Right Detail Level**: Too much detail (e.g., \"move right foot forward a centimeter\") can hinder finding a solution.\n",
        "\n",
        "#### **Determining Appropriate Abstraction Level**:\n",
        "- **Abstract States and Actions**: Represent large sets of detailed world states and action sequences.\n",
        "- **Abstract Solutions Correspond to Detailed Paths**: An abstract solution like traveling from Arad to Bucharest maps to many detailed real-world paths.\n",
        "\n",
        "#### **Validity and Usefulness of Abstraction**:\n",
        "- **Valid Abstraction**: If every detailed state corresponding to an abstract state (e.g., \"in Arad\") can lead to a detailed path to the next abstract state (e.g., \"in Sibiu\").\n",
        "- **Useful Abstraction**: If executing actions in the abstract solution is simpler than solving the original problem without losing validity (e.g., \"drive from Arad to Sibiu\" is a manageable task).\n",
        "\n",
        "**Goal of Good Abstraction**: To eliminate as much detail as possible while maintaining the ability to find a valid, practical solution.\n",
        "- **Necessity for Intelligent Agents**: Useful abstractions prevent agents from being overwhelmed by real-world complexities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HxHkoH_9vI4"
      },
      "source": [
        "## 3.2 Example Problems\n",
        "\n",
        "Discusses the application of problem-solving approaches to various task environments, distinguishing between standardized and real-world problems.\n",
        "\n",
        "   - **Standardized Problems**: Designed to illustrate or test problem-solving methods; concise and exact, serving as benchmarks for algorithm performance comparison.\n",
        "   - **Real-World Problems**: Practical problems like robot navigation, with idiosyncratic formulations due to unique aspects (e.g., different sensors in robots).\n",
        "\n",
        "### **3.2.1 Standardized Problems: Grid World Problem**:\n",
        "\n",
        "\n",
        "- **Description**: A two-dimensional grid of square cells where agents move between cells, considering obstacles and objects.\n",
        "- **States**: Defined by the location of objects in cells. In a vacuum world scenario, states include agent and dirt positions. For example, a two-cell vacuum world has 8 possible states.\n",
        "- **Initial State**: Any state can be the starting point.\n",
        "- **Actions**: Includes movements like Suck, Left, Right, and potentially Upward, Downward, Forward, Backward, TurnRight, TurnLeft.\n",
        "- **Transition Model**: Describes the outcomes of actions, like Suck removing dirt, Forward moving the agent ahead unless blocked, and directional changes.\n",
        "- **Goal States**: Typically, all cells being clean.\n",
        "- **Action Cost**: Generally, each action incurs a cost of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25SC7XTM9vI7"
      },
      "source": [
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/DALL%C2%B7E%202024-01-15%2010.43.10%20-%20Picture%20of%20a%20robot%20navigating%20a%20two-dimensional%20grid.%20The%20image%20should%20depict%20a%20simple,%20stylized%20grid%20with%20squares,%20and%20a%20robot%20placed%20on%20this%20grid.%20T.png?raw=true\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkbkeOYa9vI-"
      },
      "source": [
        "### **3.2.2 Standardized Problems: Sokoban - 8-Puzzle Problem**:\n",
        "\n",
        "A grid world problem where the agent pushes boxes to designated storage locations.\n",
        "   - **Game Mechanics**: The agent moves forward into a cell with a box, pushing the box if the cell on the other side is empty.\n",
        "   - **Constraints**: Boxes cannot be pushed into other boxes or walls.\n",
        "   - **State Complexity**: In a grid with n non-obstacle cells and b boxes, there are n × n!/(b!(n – b)!) possible states. For example, a 12-box puzzle on an 8x8 grid has over 200 trillion states.\n",
        "\n",
        "#### **Sliding-Tile Puzzle (including 8-puzzle and 15-puzzle)**:\n",
        "\n",
        "![15 sliding tile puzzle on wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/15-Puzzle_solved.png/440px-15-Puzzle_solved.png)\n",
        "\n",
        "\n",
        "\n",
        "- **Setup**: Tiles arranged in a grid with one or more blank spaces, allowing for tile movement.\n",
        "- **Variants**: Includes Rush Hour puzzle (cars and trucks in a 6x6 grid) and well-known 8-puzzle (3x3 grid with eight tiles) and 15-puzzle (4x4 grid).\n",
        "- **Goal**: To achieve a specified goal state.\n",
        "\n",
        "#### **8-Puzzle Description**:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- **States**: Defined by the location of each tile.\n",
        "- **Initial State**: Any state can be the starting point, but reachable goals are limited by a parity property.\n",
        "- **Actions**: Conceptualized as moving the blank space in different directions (Left, Right, Up, Down).\n",
        "- **Transition Model**: Describes how actions lead to new states (e.g., moving the blank space).\n",
        "- **Goal State**: Typically, tiles arranged in numerical order.\n",
        "- **Action Cost**: Each action incurs a cost of 1.\n",
        "\n",
        "#### **Abstraction in Problem Formulation**:\n",
        "\n",
        "\n",
        "- **In the 8-puzzle**: Actions are simplified to start and end states, omitting the sliding process.\n",
        "- **Physical Manipulations Excluded**: Actions like shaking or altering the puzzle physically are not considered, focusing instead on the rules of the game."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-42WEU79vJE"
      },
      "source": [
        "### **3.2.3 Standardized problem : Knuth's Number problem**:\n",
        "\n",
        "- **Knuth's Problem Overview**: A standardized problem proposed by Donald Knuth in 1964 demonstrating infinite state spaces.\n",
        "   - **Concept**: Reaching any desired positive integer starting from the number 4 through a sequence of specific operations.\n",
        "\n",
        "#### **Problem Definition**:\n",
        "\n",
        "\n",
        "- **States**: Positive real numbers.\n",
        "- **Initial State**: The number 4.\n",
        "- **Actions**: Three possible operations - square root, floor, and factorial (factorial applicable only to integers).\n",
        "- **Transition Model**: Based on the mathematical definitions of the square root, floor, and factorial operations.\n",
        "- **Goal State**: A specific desired positive integer.\n",
        "- **Action Cost**: Each action incurs a cost of 1.\n",
        "\n",
        "<li>**Infinite State Space**:\n",
        "\n",
        "\n",
        "- **Expansion**: The factorial operation on any integer greater than 2 results in increasingly larger integers, leading to an infinite state space.\n",
        "- **Example**: The shortest path to reach the number 5 involves a number as large as (4!)!, demonstrating the exploration of extremely large numbers.\n",
        "\n",
        "#### **Relevance in Other Tasks**:\n",
        "\n",
        "\n",
        "- **Common Occurrence of Infinite State Spaces**: Frequently found in tasks involving the generation of mathematical expressions, circuits, proofs, programs, and other recursively defined objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fur72GGS9vJI",
        "outputId": "e4001b7a-6d13-464c-e9bd-61f96b63ff77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "620448401733239439360000\n",
            "787685471322.9382\n",
            "887516.4625644633\n",
            "942.0809214523258\n",
            "30.693336759829908\n",
            "5.540156745059647\n",
            "5\n",
            "Our goal from 4 to 5 has been achieved!\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt, factorial, floor\n",
        "# let's test it on 4 -> 5\n",
        "# so\n",
        "n = factorial(4)\n",
        "print(n)\n",
        "n = factorial(n)\n",
        "print(n)\n",
        "for _ in range(5):\n",
        "    n = sqrt(n)\n",
        "    print(n)\n",
        "n = floor(n)\n",
        "print(n)\n",
        "print(\"Our goal from 4 to 5 has been achieved!\")\n",
        "# TODO how to go from 4 to 6?\n",
        "# TODO how to go from 5 to 6?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VVmr8bc9vJS"
      },
      "source": [
        "### **3.2.4 Real-World Problems**\n",
        "\n",
        "Discusses real-world applications of problem-solving methods, contrasting with standardized problems. Examples include route-finding, airline travel planning, touring problems, VLSI layout, robot navigation, and automatic assembly sequencing.\n",
        "####  **Airline Travel Planning**:\n",
        "   - **States**: Include location, current time, and historical aspects like fare bases and domestic/international status.\n",
        "   - **Initial State**: User's home airport.\n",
        "   - **Actions**: Take any available flight, considering various factors like seat class and transfer times.\n",
        "   - **Transition Model**: New state includes flight's destination and arrival time.\n",
        "   - **Goal State**: Typically a destination city, sometimes with specific requirements (e.g., nonstop flight).\n",
        "   - **Action Cost**: Factors in monetary cost, waiting and flight times, customs procedures, seat quality, etc.\n",
        "\n",
        "#### **Touring Problems and Traveling Salesperson Problem (TSP)**:\n",
        "\n",
        "\n",
        "- **Concept**: Visiting a set of locations, not just a single goal.\n",
        "- **TSP**: Aim to find a cost-effective tour of all cities on a map.\n",
        "- **Applications**: Extended to fleet management, saving costs and reducing pollution.\n",
        "\n",
        "#### **VLSI Layout Problem**:\n",
        "\n",
        "\n",
        "- **Task**: Position components on a chip efficiently.\n",
        "- **Split into Two Parts**: Cell layout (grouping components) and channel routing (connecting wires).\n",
        "- **Complexity**: Extremely high, but crucial for manufacturing efficiency.\n",
        "\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/DALL%C2%B7E%202024-01-15%2010.42.07%20-%20Illustration%20of%20the%20VLSI%20layout%20problem,%20showing%20the%20placement%20of%20electronic%20components%20on%20a%20chip.%20The%20image%20should%20depict%20a%20close-up%20view%20of%20a%20chip%20w.png?raw=true\" width=\"400\">\n",
        "\n",
        "#### **Robot Navigation**:\n",
        "\n",
        "\n",
        "- **Generalization of Route-Finding**: Robots create paths in open spaces.\n",
        "- **Complexity**: Increases with additional capabilities like arms and legs.\n",
        "- **Challenges**: Sensor errors, partial observability, environmental changes.\n",
        "\n",
        "#### **Automatic Assembly Sequencing**:\n",
        "\n",
        "\n",
        "- **Application**: Standard in industries for assembling complex objects.\n",
        "- **Process**: Find a feasible assembly sequence and optimize it to reduce manual labor.\n",
        "- **Complexity**: Selecting the right assembly order to avoid redoing work.\n",
        "- **Related Problems**: Protein design for medical applications.\n",
        "\n",
        "#### **Key Points in Real-World Problem Solving**:\n",
        "\n",
        "\n",
        "- **Complexity and Uniqueness**: Real-world problems have idiosyncratic, complex specifications.\n",
        "- **Practical Applications**: Solutions have tangible, often significant, real-world impacts.\n",
        "- **Challenges**: Include managing large state spaces, handling real-world uncertainties, and optimizing for multiple factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9jd11KZ9vJV"
      },
      "source": [
        "## 3.3 Search Algorithms\n",
        "\n",
        "Focuses on algorithms that process a search problem and output a solution or indicate failure.\n",
        "   - **Function**: These algorithms create a search tree over the state-space graph to explore paths from the initial state to a goal state.\n",
        "   - **Tree Structure**: Each node in the search tree represents a state in the state space, and tree edges correspond to actions. The root of the tree is the initial state.\n",
        "\n",
        "### **Distinction Between State Space and Search Tree**:\n",
        "\n",
        "\n",
        "- **State Space**: Represents the set of all possible states in the world and the actions for state transitions.\n",
        "- **Search Tree**: Describes paths within the state space, aiming towards the goal.\n",
        "- **Tree Characteristics**: Multiple paths in the search tree can lead to the same state, but each node has a unique path back to the root.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHDe4G419vJW"
      },
      "source": [
        "![Search Tree](https://www.chessprogramming.org/images/6/65/Deep-prune.gif)\n",
        "\n",
        "Src: https://www.chessprogramming.org/Search_Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCY5nALW9vJZ"
      },
      "source": [
        "### 3.3.1 Best-First Search\n",
        "\n",
        "A search strategy that selects nodes to expand based on an evaluation function.\n",
        "   - **Key Concept**: Nodes are chosen for expansion based on their evaluation scores from a function f(n).\n",
        "   - **Process**:\n",
        "      - On each iteration, select a node from the frontier (the set of candidate nodes) with the minimum f(n) value.\n",
        "      - Check if the state of this node is a goal state; if so, return it as the solution.\n",
        "      - If not a goal state, expand the node to generate its child nodes.\n",
        "      - Add these children to the frontier if they represent new states or if they offer a lower path cost than previously encountered paths.\n",
        "   \n",
        "#### **BFS Outcome**:\n",
        "\n",
        "The algorithm returns either a path to a goal (via the selected node) or an indication of failure if no solution is found.<li>**Flexibility**: By varying the evaluation function <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(n)</annotation></semantics></math><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height: 1em; vertical-align: -0.25em;\"><span class=\"mord mathnormal\" style=\"margin-right: 0.10764em;\">, different specific algorithms can be derived."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGytfRK59vJb"
      },
      "source": [
        "### 3.3.2 Search Data Structures\n",
        "\n",
        "Essential structures for managing the search tree in search algorithms.\n",
        "    - **Function**: These data structures store the search tree, track the states that have already been reached, and prioritize nodes for expansion.\n",
        "\n",
        "   - **Node Representation**: Each node in the search tree has four components:\n",
        "      - **node.STATE**: Corresponds to the specific state in the state space.\n",
        "      - **node.PARENT**: The node that generated this node.\n",
        "      - **node.ACTION**: The action applied to the parent's state to generate this node.\n",
        "      - **node.PATH-COST**: The total cost from the initial state to this node, often represented mathematically as g(node).\n",
        "   \n",
        "- **Path Recovery**: By following the PARENT pointers from a node, the path of states and actions to that node can be traced back, providing the solution if the node is a goal.\n",
        "\n",
        "#### **Frontier Data Structure**:\n",
        "\n",
        "\n",
        "- **Function**: Stores the frontier, or the set of all nodes available for expansion.\n",
        "- **Queue Implementation**: The frontier is typically implemented as a queue, supporting operations like IS-EMPTY, POP, TOP, and ADD.\n",
        "- **Types of Queues**:\n",
        "   - **Priority Queue**: Used in best-first search, it prioritizes nodes based on an evaluation function f(n).\n",
        "   - **FIFO Queue**: A first-in-first-out queue, used in breadth-first search, pops the earliest added node.\n",
        "   - **LIFO Queue/Stack**: Used in depth-first search, it pops the most recently added node.\n",
        "\n",
        "#### **Reached States Storage**:\n",
        "\n",
        "\n",
        "- **Implementation**: A lookup table (like a hash table) where each key is a state, and each value is the corresponding node.\n",
        "- **Purpose**: Efficiently tracks the states that have already been reached in the search process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBVJhJGR9vJd"
      },
      "source": [
        "### 3.3.3 Redundant Paths\n",
        "\n",
        "Discusses the challenge of managing redundant paths in search algorithms and strategies to address it.\n",
        "   - **Redundancy Example**: In a 10x10 grid world, an agent can reach any square in 9 moves or fewer, but the number of paths of length 9 is nearly 8^9, leading to over 100 million paths and many redundancies.\n",
        "\n",
        "- **Strategies to Handle Redundant Paths**:\n",
        "\n",
        "\n",
        "- **Remembering Past States**:\n",
        "   - **Approach**: Store all previously reached states to detect and eliminate redundant paths.\n",
        "   - **Applicability**: Suitable for state spaces with many redundant paths and where the table of reached states can fit in memory.\n",
        "\n",
        "- **Ignoring Redundancy**:\n",
        "- **Approach**: In some problems, redundant paths are rare or impossible, so tracking reached states is unnecessary.\n",
        "- **Example**: Assembly problems with a specific part order.\n",
        "- **Graph vs. Tree-Like Search**: A graph search algorithm checks for redundant paths, while a tree-like search does not.\n",
        "\n",
        "- **Compromising by Checking for Cycles**:\n",
        "- **Approach**: Check for cycles in the path without storing all reached states.\n",
        "- **Implementation**: Trace the chain of parent pointers to see if a state reappears in its own path.\n",
        "- **Variations**: Some implementations check the entire parent chain (eliminating all cycles), while others check only a few levels up (eliminating short cycles).\n",
        "\n",
        "#### **Redundant Paths Impact on Performance**:\n",
        "\n",
        "\n",
        "- **Memory Usage**: Strategies vary in their memory requirements.\n",
        "- **Speed**: Eliminating redundant paths can significantly increase search efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGUd0gh29vJe"
      },
      "source": [
        "### 3.3.4 Measuring Problem-Solving Performance\n",
        "\n",
        "Criteria for evaluating the effectiveness of search algorithms.\n",
        "   - **Completeness**: Whether the algorithm can always find a solution if one exists and report failure when there is no solution.\n",
        "   - **Cost Optimality**: The ability of the algorithm to find the least costly solution among all possible solutions.\n",
        "   - **Time Complexity**: The duration or the number of states and actions considered to find a solution.\n",
        "   - **Space Complexity**: The amount of memory required to perform the search.\n",
        "\n",
        "#### **Understanding Completeness**:\n",
        "\n",
        "\n",
        "- **Finite State Spaces**: In these spaces, completeness is achievable by systematically exploring every reachable state and avoiding cycles.\n",
        "- **Infinite State Spaces**: Requires more systematic exploration to ensure every reachable state is eventually reached.\n",
        "- **Example**: On an infinite grid, a spiral path that incrementally expands outward is systematic but might not find a solution if the space is infinite and the solution is absent.\n",
        "\n",
        "#### **Time and Space Complexity**:\n",
        "\n",
        "\n",
        "- **Theoretical Measure**: Typically based on the size of the state-space graph (|V| + |E|), with |V| as vertices and |E| as edges.\n",
        "- **Implicit State Space Complexity**: Measured in terms of the depth of the solution (d), the maximum length of any path (m), and the branching factor (b) or the number of successors a node has.\n",
        "\n",
        "#### **Practical Implications**:\n",
        "\n",
        "\n",
        "- **Infinite State Spaces**: A complete algorithm must search indefinitely in the absence of a solution.\n",
        "- **Optimizing Performance**: Choosing an algorithm involves balancing time and space complexity with completeness and cost optimality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNR06Q6K9vJg"
      },
      "source": [
        "## 3.4 Uninformed Search Strategies\n",
        "\n",
        "Discusses search algorithms that operate without any information on the proximity of a state to the goal.\n",
        "\n",
        "   - **Key Characteristic**: These algorithms do not use any domain-specific knowledge or heuristics to estimate the distance to the goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4RWDQYA9vJh"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/DALL%C2%B7E%202024-01-15%2011.36.14%20-%20Illustration%20representing%20an%20uninformed%20agent.%20The%20image%20should%20depict%20a%20humanoid%20figure%20that%20embodies%20the%20concept%20of%20ignorance%20or%20lack%20of%20information.png?raw=true\" width=\"400\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3Ok57mn9vJi"
      },
      "source": [
        "### 3.4.1 Breadth-First Search Overview\n",
        "\n",
        " A search strategy used when all actions have the same cost.\n",
        "   - **Key Concept**: Expands the shallowest unexpanded node first.\n",
        "   - **Expansion Order**: The root node is expanded first, followed by all its successors, then their successors, and so on.\n",
        "   - **Completeness**: This method is complete, meaning it will find a solution if one exists, even in infinite state spaces.\n",
        "   - **Implementation as Best-First Search**: It can be implemented using the BEST-FIRST-SEARCH algorithm with the node depth as the evaluation function f(n).\n",
        "\n",
        "#### Efficiency Enhancements to BFS\n",
        "\n",
        "\n",
        "- **FIFO Queue**: A first-in-first-out queue is more efficient than a priority queue for this strategy. New nodes are added to the back of the queue, ensuring that shallower nodes are expanded first.\n",
        "- **Reached States as a Set**: The 'reached' structure can be a set of states, not a mapping from states to nodes, because once a state is reached, a better path to it is not possible under this strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRcAuzis9vJj"
      },
      "source": [
        "### 3.4.2 Dijkstra’s Algorithm or Uniform-Cost Search\n",
        "\n",
        " A search strategy used when actions have varying costs.\n",
        "\n",
        "    - **Key Concept**: Expands the node with the lowest path cost g(n).\n",
        "   - **Strategy**: Employs a best-first search where the evaluation function is the cumulative cost of the path from the root to the current node.\n",
        "   - **Naming**: Known as Dijkstra’s algorithm in theoretical computer science and uniform-cost search in AI.\n",
        "   - **Operation Principle**: Unlike breadth-first search, which expands nodes in waves based on uniform depth, uniform-cost search expands nodes in waves based on uniform path cost.\n",
        "   - **Implementation**: Can be executed as a call to BEST-FIRST-SEARCH, using PATH-COST as the evaluation function.\n",
        "\n",
        "   Note: we discuss the implementation of Dijkstra's algorithm extensively in algorithms course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEQlTSqs9vJj"
      },
      "source": [
        "### 3.4.3 Depth-First Search and Memory Considerations\n",
        "\n",
        " Focuses on the depth-first search strategy and its implications on memory usage.\n",
        "   - **Expansion Strategy**: Depth-first search always expands the deepest node in the frontier first.\n",
        "   - **Implementation**: Often implemented as a tree-like search without a table of reached states, unlike a typical graph search. Can be thought of as BEST-FIRST-SEARCH with an evaluation function f as the negative depth.\n",
        "   - **Behavior**: Proceeds to the deepest level of the search tree first, backing up when it encounters nodes without successors.\n",
        "   - **Cost-Optimality**: Not cost-optimal; finds the first solution, not necessarily the cheapest.\n",
        "\n",
        "##### DFS Efficiency and Completeness\n",
        "\n",
        "\n",
        "- **Finite Tree State Spaces**: Efficient and complete.\n",
        "- **Acyclic State Spaces**: Can expand the same state multiple times via different paths but will eventually explore the entire space.\n",
        "- **Cyclic State Spaces**: Risk of getting stuck in infinite loops; some implementations check for cycles to prevent this.\n",
        "- **Infinite State Spaces**: Incomplete as it can get stuck on an infinite path, especially in the absence of cycles.\n",
        "\n",
        "#### Advantages of Depth-First Search\n",
        "\n",
        "\n",
        "- **Memory Efficiency**: Particularly advantageous for problems where a tree-like search is feasible due to its lower memory requirements.\n",
        "- **Frontier Size**: Comparatively smaller than in breadth-first search; analogous to the radius of an expanding sphere versus its surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv8kSjIh9vJk"
      },
      "source": [
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/search_tree_solution.jpg?raw=true\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt17DWwp9vJl"
      },
      "source": [
        "### 3.4.4 Depth-Limited and Iterative Deepening Search Overview\n",
        "\n",
        " Strategies to improve and optimize depth-first search.\n",
        "\n",
        "- **Depth-Limited Search**:\n",
        "   - **Concept**: A variant of depth-first search with a predetermined depth limit\n",
        "   l\n",
        "   - **Behavior**: Treats nodes at depth l as if they have no successors.\n",
        "   - **Complexity**: Time complexity is O(b^l), space O(bl)\n",
        "   - **Limitation**: Incomplete if the depth limit is too low to reach the solution.\n",
        "\n",
        "\n",
        "#### Eliminating Cycles in Depth-Limited Search\n",
        "\n",
        "\n",
        "- **Strategy**: Check a few links up in the parent chain to catch most cycles.\n",
        "- **Depth Limit Based on Problem Knowledge**: Using known problem metrics, such as the state-space graph's diameter, to set a more effective depth limit.\n",
        "\n",
        "#### Iterative Deepening Search\n",
        "\n",
        "\n",
        "- **Method**: Repeatedly applies depth-limited search with incrementally increasing depth limits.\n",
        "- **Outcomes**: Returns a solution, failure (if no solution exists), or a cutoff (indicating a potential solution at a deeper level).\n",
        "- **Advantages**: Combines the benefits of depth-first search (low memory use) and breadth-first search (completeness and optimality for uniform-cost problems).\n",
        "- **Memory Efficiency**: Does not track reached states, using less memory but potentially revisiting states.\n",
        "- **Complexity**: Time complexity is\n",
        "O(b^d) when a solution exists or\n",
        "O(b^m) otherwise. What is m? m is the maximum depth of the state space. m is not known in advance, but it is at least d, the depth of the shallowest goal state. Therefore, the time complexity is at most O(b^m).\n",
        "- **Efficiency in State Space Exploration**: While it regenerates upper-level nodes multiple times, the bulk of nodes are often at the bottom level, making this repetition less significant.\n",
        "\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/iterative_deepening_search.jpg?raw=true\" width=\"600\">\n",
        "\n",
        "#### Hybrid Approach\n",
        "\n",
        "\n",
        "- **Combination of Strategies**: Starts with breadth-first search until memory is nearly full, then switches to iterative deepening.\n",
        "- **Applicability**: Preferred when the state space is too large for memory and the solution depth is unknown.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJjtroSE9vJn"
      },
      "source": [
        "### 3.4.5 Bidirectional Search Overview\n",
        "\n",
        " An alternative search strategy that operates simultaneously from both the initial and goal states.\n",
        "\n",
        "   - **Approach**: Searches forward from the initial state and backward from the goal state, aiming for the two searches to meet.\n",
        "   - **Efficiency**: Significantly more efficient than unidirectional search in many cases (e.g., reduces search effort from b^d to 2(b^d/2)).\n",
        "\n",
        "\n",
        "#### Implementation Requirements\n",
        "\n",
        "\n",
        "- **Dual Frontiers and Reached States**: Maintains two separate sets of frontiers and reached states for both forward and backward searches.\n",
        "- **Backward Reasoning Capability**: Ability to infer backward transitions from a state to its predecessors.\n",
        "- **Collision Detection**: Identifies when the two frontiers meet, indicating a solution.\n",
        "\n",
        "#### Bidirectional Best-First Search\n",
        "\n",
        "\n",
        "- **Node Selection**: Chooses the next node to expand based on the minimum value of the evaluation function across both frontiers.\n",
        "- **Variants**: When the evaluation function is the path cost, it becomes bidirectional uniform-cost search.\n",
        "- **Optimality**: If the evaluation function is path cost, the first solution found is optimal. With different evaluation functions, this may not be true.\n",
        "\n",
        "#### Optimizing Search Performance\n",
        "\n",
        "\n",
        "- **Forward and Backward Problem Versions**: Requires two versions of the problem and the evaluation function (one for each direction).\n",
        "- **Tracking Optimal Solutions**: Continuously updates the best solution found until it's certain no better solution exists.\n",
        "\n",
        "#### General Considerations\n",
        "\n",
        "\n",
        "- **Speedup Potential**: Can significantly reduce search time, especially in large state spaces.\n",
        "- **Complexity**: Requires handling two search processes and effectively managing their interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhxvg3MP9vJo"
      },
      "source": [
        "### 3.4.6 Uninformed Search Strategies Comparison\n",
        "\n",
        "![Comparison](https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/uninformed_search_comparison_315.jpg?raw=true)\n",
        "\n",
        "Src: Russell, Stuart J.; Norvig, Peter. Artificial Intelligence: A Modern Approach 4th Edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TbyrLmU9vJp"
      },
      "source": [
        "## 3.5 Informed (Heuristic) Search Strategies\n",
        "\n",
        "Discusses search strategies that use additional domain-specific information to find solutions more efficiently compared to uninformed strategies.\n",
        "\n",
        "   - **Key Feature**: Utilization of heuristic functions to guide the search.\n",
        "   - **Heuristic Function   h(n)**: Estimates the cost of the cheapest path from the state at node n to a goal state.\n",
        "\n",
        "### **Application Example**:\n",
        "\n",
        "\n",
        "- **Route-Finding Problems**: The heuristic might be the straight-line distance (as the crow flies) between the current state and the goal state, providing a simple yet effective estimation of distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-Ch20149vJq"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/DALL%C2%B7E%202024-01-15%2011.36.08%20-%20Illustration%20representing%20an%20informed%20agent.%20The%20image%20should%20depict%20a%20humanoid%20figure%20that%20embodies%20the%20concept%20of%20knowledge%20and%20understanding,%20parti.png?raw=true\" width=\"400\" alt=\"based robot\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Ld0PCW9vJr"
      },
      "source": [
        "### 3.5.1 Greedy Best-First Search\n",
        "\n",
        "Strategy that expands the node closest to the goal, as determined by the heuristic function.\n",
        "   - **Key Concept**: Expands the node that appears to be closest to the goal.\n",
        "   - **Implementation**: Can be implemented as a call to BEST-FIRST-SEARCH, using the heuristic function h(n) as the evaluation function.\n",
        "   - **Optimality**: Not optimal, can lead to suboptimal solutions. The tempting next jump solution is not always the best one!\n",
        "   - **Completeness**: Complete in finite state spaces but incomplete in infinite state spaces.\n",
        "\n",
        "#### Complexity\n",
        "\n",
        "Worst-case time and space complexity is O(|V|), where |V| is the number of vertices in the state space graph. With good heuristics, the complexity is often much lower aproaching O(bm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5GWNuDx9vJt"
      },
      "source": [
        "### 3.5.2 A* Search (A-Star Search)\n",
        "\n",
        "A search strategy that combines the advantages of uniform-cost search and greedy best-first search.\n",
        "   - **Key Concept**: Expands the node with the lowest value of g(n) + h(n).\n",
        "   - **Implementation**: Can be implemented as a call to BEST-FIRST-SEARCH, using the evaluation function f(n) = g(n) + h(n).\n",
        "   - **Optimality**: Optimal if the heuristic function h(n) is admissible, meaning it never overestimates the cost to reach the goal.\n",
        "   - **Completeness**: Complete in finite state spaces but incomplete in infinite state spaces.\n",
        "   - **Complexity**: Time and space complexity is O(b^d) in the worst case, where b is the branching factor and d is the depth of the shallowest goal state. With good heuristics, the complexity is often much lower.\n",
        "\n",
        "#### Importance of A* Search\n",
        "\n",
        "A* search is the most widely used search algorithm in AI, with applications in route planning, robotics, and other areas. It is also the basis for many other algorithms, including IDA* and AO*.\n",
        "\n",
        "A* search is widely used in computer games, where it is used to find paths for characters and to evaluate board positions in chess and other games."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeBGOZGK9vJu"
      },
      "source": [
        "### 3.5.3 Search Contours\n",
        "\n",
        "A method to visualize the search process in A* search.\n",
        "   - **Concept**: A contour is a set of nodes with the same value of f(n) = g(n) + h(n).\n",
        "   - **Visualization**: The search process can be visualized as a series of nested contours, with the goal state at the center.\n",
        "   - **Contour Expansion**: Contours are expanded in order of increasing f(n) values, with the lowest f(n) value expanded first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0sXCXUd9vJv"
      },
      "source": [
        "### 3.5.4 Satisficing search: Inadmissible heuristics and weighted A∗\n",
        "\n",
        "   - **Basic Concept**: Satisficing search aims to find a 'good enough' solution efficiently, rather than the optimal one. It's particularly useful in complex problems where finding the optimal solution is too time-consuming or computationally expensive.\n",
        "   - **Inadmissible Heuristics**: Unlike admissible heuristics (which never overestimate the cost to the goal), inadmissible heuristics can overestimate costs. They are used in satisficing search to potentially speed up the search process at the expense of optimality.\n",
        "   - *\n",
        "   Weighted A* Search\n",
        "   *: An extension of A* search, where the heuristic component\n",
        "    h(n) of the evaluation function\n",
        "   f(n) = g(n) + h(n)\n",
        "\n",
        " is multiplied by a weight\n",
        "   w\n",
        "   w\n",
        "   w greater than 1. This modification biases the search towards the goal, potentially reducing the search time.\n",
        "   - **Trade-Off**: The increase in weight\n",
        "   w can significantly speed up the search but also increases the risk of missing the shortest path. The goal is to strike a balance between search speed and solution quality.\n",
        "   - **Applicability**: Useful in scenarios where time or computational resources are limited, and a reasonably good solution is acceptable over the absolute best solution.\n",
        "   - **Practical Considerations**: Choosing the right weight and heuristic is crucial. Too high a weight might lead to very suboptimal solutions, while too low might not improve search efficiency appreciably."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search Algorithm Visualizations\n",
        "\n",
        "* https://clementmihailescu.github.io/Pathfinding-Visualizer/"
      ],
      "metadata": {
        "id": "ydTXLmkkTZvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXhJcYGaTfTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWcoAjmy9vJx"
      },
      "source": [
        "### 3.5.5 Memory-bounded search\n",
        "\n",
        "Focuses on reducing the memory usage of search algorithms, particularly A*.\n",
        "\n",
        "- **Memory Allocation in Search Algorithms**:\n",
        "   - **Duplication of States**: States are often stored in both the frontier and the reached table, which can be memory-intensive.\n",
        "   - **Strategies to Reduce Duplication**: Some implementations store a state in only one place (either frontier or reached table) to save space.\n",
        "\n",
        "#### **Removing Unnecessary States**:\n",
        "\n",
        "\n",
        "- **Separation Property**: Utilizes specific properties of problems to eliminate the need for a reached table, checking only the frontier for redundant paths.\n",
        "- **Reference Counts**: In some cases, states can be removed from the reached table after being reached a certain number of times.\n",
        "\n",
        "#### **New Algorithms for Memory Conservation**:\n",
        "\n",
        "\n",
        "- **Beam Search**:\n",
        "   - Limits the size of the frontier to the best k nodes based on their\n",
        "   f-scores.\n",
        "   - Makes the search incomplete and suboptimal but is efficient in using memory and often finds near-optimal solutions.\n",
        "   - Compares to A* as a focused exploration of the most promising nodes.\n",
        "\n",
        "#### **Alternative Beam Search**:\n",
        "- Keeps nodes within a certain range\n",
        "δ\n",
        "\\delta\n",
        "δ of the best\n",
        "f-score, allowing for more flexibility in the number of nodes kept based on the situation.\n",
        "\n",
        "#### Iterative-Deepening A* (IDA) Search**:\n",
        "- Combines iterative deepening with A*, offering the benefits of A* without needing to store all reached states.\n",
        "- Visits some states multiple times but significantly reduces memory usage.\n",
        "- Particularly useful for large problems that don't fit in memory.\n",
        "\n",
        "#### General Consideration\n",
        "\n",
        "\n",
        "- **Balance Between Memory and Completeness/Optimality**: These strategies trade off between reducing memory usage and maintaining the completeness and optimality of the search.\n",
        "- **Applicability**: Each approach has its specific use-cases, depending on the nature of the problem and available resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyET2IJG9vJy"
      },
      "source": [
        "### 3.5.6 Bidirectional Heuristic Search\n",
        "\n",
        "- **Key Concept**: A bidirectional search strategy that uses heuristic function(s) to guide the search.\n",
        "\n",
        "- **Efficiency Measurement Complexity**: In bidirectional search, efficiency needs to be evaluated based on pairs of nodes (one from each frontier) rather than individual nodes.\n",
        "\n",
        "**Research Insight**: According to Eckerle et al., 2017, the proof of efficiency in bidirectional heuristic search must consider the interactions and relationships between pairs of nodes from each search frontier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVQaY3tq9vJz"
      },
      "source": [
        "## 3.6 Heuristic Functions\n",
        "\n",
        "Explores the impact of heuristic accuracy on search performance and the methods for developing effective heuristics.\n",
        "   - **Role of Heuristics in Search Algorithms**: Heuristics provide an estimate of the cost from a given state to the goal, guiding the search algorithm towards efficient solutions.\n",
        "   - **Accuracy and Performance**: The effectiveness and efficiency of search algorithms, particularly heuristic-based searches like A*, are heavily influenced by the accuracy of the heuristic function.\n",
        "   - **Developing Heuristics**:\n",
        "      - **Inventing Heuristics**: Involves creating heuristic functions that are both efficient to compute and closely approximate the actual cost to the goal.\n",
        "      - **Balance Between Accuracy and Complexity**: Heuristics should strike a balance between providing accurate estimates and being computationally feasible.\n",
        "   \n",
        "### Example with the 8-Puzzle\n",
        "\n",
        "- **Contextual Application**: The section uses the 8-puzzle as a primary example to demonstrate how different heuristics can impact the performance of search algorithms.\n",
        "- **Types of Heuristics for 8-Puzzle**: Common heuristics for the 8-puzzle include the number of misplaced tiles and the total Manhattan distance of tiles from their goal positions.\n",
        "- **Comparative Analysis**: By comparing different heuristics on the 8-puzzle, the section illustrates how the choice of heuristic affects the number of states explored and the overall efficiency of the search process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et_mqE8y9vJ0"
      },
      "source": [
        "### 3.6.3 Generating heuristics from subproblems: Pattern databases\n",
        "\n",
        "- **Concept**: A method to generate heuristics by solving subproblems and combining their solutions.\n",
        "\n",
        "- **Process**:\n",
        "   - **Step 1**: Identify a set of subproblems that cover the entire state space.\n",
        "   - **Step 2**: Solve each subproblem and store the solutions in a database.\n",
        "   - **Step 3**: Combine the solutions to estimate the cost to the goal state.\n",
        "\n",
        "- **Example**: In the 8-puzzle, the subproblems can be the positions of individual tiles, and the solutions can be the number of moves required to move each tile to its goal position."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "828NMw5k9vJ0"
      },
      "source": [
        "### 3.6.4 Generating Heuristics with Landmarks\n",
        "\n",
        "- **Key Concept**: A method to generate heuristics by identifying landmarks in the state space and estimating the cost to reach them.\n",
        "\n",
        "- **Precomputation of Optimal Path Costs**: Online services that provide driving directions employ a crucial strategy of precomputing optimal path costs. This means that, before serving user requests, they calculate and store the optimal costs of various paths between locations on a map.\n",
        "- **Amortization**: While the precomputation process can be time-consuming and resource-intensive, it only needs to be done once for a given map or network. Once the optimal path costs are computed and stored, they can be reused and amortized over a massive number of user search requests.\n",
        "- **Landmarks**: Landmarks are specific points or locations on a map that serve as reference points for path calculations. By strategically selecting landmarks and computing the optimal distances between them, online services can estimate distances between any pair of locations on the map more efficiently.\n",
        "- **Speed**: This approach allows online services to find cost-optimal driving directions in a matter of milliseconds, even for maps with tens of millions of vertices. It is significantly faster than traditional search algorithms, which may be about a million times slower.\n",
        "- **User-Friendly and Real-Time**: The rapid response time achieved through this precomputation and landmark-based heuristic generation makes these services user-friendly and suitable for real-time navigation and route planning.\n",
        "- **Trade-Off**: While precomputation and landmark-based heuristics provide exceptional speed, they require substantial initial computational resources to generate the necessary data. However, this trade-off is highly advantageous for applications that involve frequent and real-time pathfinding requests.\n",
        "\n",
        "In summary, the key to the remarkable speed of online map services in finding cost-optimal driving directions lies in the precomputation of optimal path costs and the use of landmarks as reference points. This approach allows for efficient and near-instantaneous route calculations while incurring an initial computational cost that can be amortized over countless user requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idvIK_Om9vJ8"
      },
      "source": [
        "### 3.6.5 Learning to search better\n",
        "\n",
        "- **Concept**: A method to generate heuristics by learning from past search experiences.\n",
        "\n",
        "- **Metalevel State Space**: The metalevel state space is a concept that involves capturing the internal or computational state of a program that performs search operations within an ordinary state space. The ordinary state space, such as the map of Romania, is referred to as the object-level state space.\n",
        "- **Learning to Improve Search**: The central question addressed in this section is whether an agent can learn to perform more effective search operations. The answer is affirmative; agents can learn to search better by leveraging the metalevel state space.\n",
        "- **Internal State of Algorithms**: Each algorithm used for search, such as A*, has an internal state that includes information like the current search tree and other relevant data structures. This internal state represents the computational progress of the search algorithm.\n",
        "- **Metalevel Actions**: In the metalevel state space, actions correspond to computational steps taken by the search algorithm. For example, in the case of A*, each action might involve expanding a leaf node and adding its successors to the search tree.\n",
        "\n",
        "The key idea here is that agents can learn to make better decisions and improve their search strategies by analyzing and modifying the metalevel state space, which reflects the computational aspects of the search process. This approach opens up possibilities for developing more efficient and adaptive search algorithms that can learn from experience and become more proficient over time. It highlights the potential for machine learning and reinforcement learning techniques to enhance search performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZhzh1W9vJ-"
      },
      "source": [
        "### 3.6.6 Learning heuristics from experience\n",
        "\n",
        "- **Concept**: A method to generate heuristics by learning from past search experiences.\n",
        "\n",
        "- **Learning from Experience**: To invent a heuristic, one approach is to learn from experience. In this context, \"experience\" refers to solving numerous instances of a specific problem, such as solving many 8-puzzle problems.\n",
        "- **Example-Goal Pairs**: Each optimal solution to a problem provides an example in the form of a pair consisting of a goal state and the path leading to that goal. These examples are valuable for learning heuristic functions.\n",
        "- **Learning Algorithm**: Learning algorithms can be employed to analyze these examples and construct a heuristic function denoted as h. This learned heuristic function aims to approximate the true path cost for states encountered during the search.\n",
        "- **Imperfect Approximations**: Most of these learning approaches result in imperfect heuristic approximations. This means that the learned heuristics may not always be admissible, which introduces a tradeoff between the time spent on learning, the runtime of the search, and the quality of the solution.\n",
        "- **Tradeoff Consideration**: There is an inherent tradeoff between the time required for learning, the efficiency of the search algorithm, and the optimality of the solutions obtained using these learned heuristics.\n",
        "- **Future Chapters**: Techniques related to machine learning and reinforcement learning, discussed in later chapters (Chapter 19 and Chapter 23), can be applied to enhance search algorithms by improving heuristic functions.\n",
        "\n",
        "Note: Chapters 19 and 23 correspond to 4th edition of the book - global edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyTmcAlw9vJ_"
      },
      "source": [
        "## Chapter Summary\n",
        "\n",
        "- Search algorithms are essential for agents in single-agent, deterministic, fully observable, discrete, and known environments.\n",
        "- Trade-offs exist between search time, memory usage, and solution quality.\n",
        "- Problem formulation includes the initial state, actions, transition model, goal states, and action cost function.\n",
        "- The environment is represented as a state space graph, and a solution is a path from the initial state to a goal state.\n",
        "- Search algorithms treat states and actions as atomic, without internal structure.\n",
        "- Evaluation of search algorithms is based on completeness, cost optimality, time complexity, and space complexity.\n",
        "- Uninformed search methods build a search tree without domain-specific knowledge.\n",
        "- Informed search methods use a heuristic function (h(n)) to estimate solution cost.\n",
        "- Greedy best-first search expands nodes with minimal h(n), A* search with minimal f(n) (g(n) + h(n)), provided h(n) is admissible.\n",
        "- Bidirectional search explores from both initial and goal states.\n",
        "- IDA* (iterative deepening A*) is an iterative deepening variant of A*.\n",
        "- RBFS (recursive best-first search) and SMA* (simplified memory-bounded A*) are memory-efficient variants of A*.\n",
        "- Beam search limits the frontier size, trading completeness and optimality for speed.\n",
        "- Weighted A* focuses on the search towards the goal, sacrificing optimality.\n",
        "- The quality of heuristic search depends on the heuristic function's accuracy.\n",
        "- Heuristics can be generated from relaxed problems, pattern databases, landmarks, or learned from experience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAALfbgW9vKe"
      },
      "source": [
        "## References, Bibliography, Historical Notes\n",
        "\n",
        "- The origins of state-space search in AI date back to the work of Newell and Simon on the Logic Theorist (1957) and GPS (1961). This marked the establishment of search algorithms as a primary tool in AI.\n",
        "- Richard Bellman's work in operations research (1957) highlighted the importance of additive path costs in simplifying optimization algorithms.\n",
        "- Nils Nilsson's text in 1971 solidified the theoretical foundations of the field.\n",
        "- The 15-puzzle attracted significant attention in 1880, capturing the public and mathematicians' interest.\n",
        "- Sam Loyd falsely claimed to have invented the 15 puzzle; it was actually invented by Noyes Chapman.\n",
        "- The general n × n version of the 15-puzzle belongs to the class of NP-complete problems (Ratner and Warmuth, 1986).\n",
        "- Ernő Rubik invented Rubik's Cube in 1974, and Korf (1997) found optimal solutions using pattern databases and IDA* search.\n",
        "- Uninformed search algorithms are central to computer science and operations research.\n",
        "- The iterative deepening technique was introduced by Bertram Raphael in 1976.\n",
        "- Heuristic search, incorporating heuristic functions estimating the distance to the goal, came later (Newell and Ernst, 1965).\n",
        "- A* search, developed by Hart, Nilsson, and Raphael (1968), uses path cost along with heuristic information. Pearl (1984) introduced the consistency condition.\n",
        "- Various algorithms, including weighted A*, were developed to modify A* for specific applications.\n",
        "- Bidirectional search, introduced by Pohl (1971), explores from both initial and goal states.\n",
        "- Research has been done on solving real-world problems like airline ticket pricing and the traveling salesperson problem.\n",
        "- Memory-bounded heuristic search was an early research topic due to limited computer memory.\n",
        "- Pattern databases and relaxation methods have been used to derive admissible heuristics.\n",
        "- There's ongoing research on machine learning techniques to discover heuristic functions.\n",
        "- Several textbooks and conferences are dedicated to search algorithms, and research papers are published in various AI-related conferences and journals.\n",
        "\n",
        " TODO add conference and journal names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP8R-9BK9vKg"
      },
      "source": [
        "## XKCD - picking the wrong search\n",
        "\n",
        "![XKCD DFS](https://imgs.xkcd.com/comics/dfs.png)\n",
        "\n",
        "Alt text from the comic: \"A breadth-first search makes a lot of sense for dating in general, actually; it suggests dating a bunch of people casually before getting serious, rather than having a series of five-year relationships one after the other.\"\n",
        "\n",
        "Src: https://xkcd.com/761/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
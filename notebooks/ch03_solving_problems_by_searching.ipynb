{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Solving Problems with Search\n",
    "\n",
    "- **Chapter 3 Overview**: Focuses on problem-solving through search, demonstrating how an agent plans a sequence of actions to achieve a goal.\n",
    "- **Problem-solving Agent**: An agent that needs to plan a series of actions leading to a goal state; involves a computational process known as search.\n",
    "- **Atomic Representations**: Used by problem-solving agents, where states of the world are considered as indivisible wholes without internal structure (referenced from Section 2.4.7).\n",
    "- **Contrast with Planning Agents**: Planning agents, using factored or structured state representations, are discussed in later chapters (7 and 11).\n",
    "- **Search Algorithms**: Introduction to several search algorithms within simple environments characterized by being episodic, single-agent, fully observable, deterministic, static, discrete, and known.\n",
    "- **Informed vs. Uninformed Algorithms**: Distinction between algorithms where agents can estimate distance to the goal (informed) and those without such estimates (uninformed).\n",
    "- **Expansion in Subsequent Chapters**: Chapter 4 expands on environmental constraints, and Chapter 6 delves into scenarios involving multiple agents.\n",
    "- **Asymptotic Complexity**: The chapter employs concepts of asymptotic complexity, specifically O(n) notation, to describe algorithm efficiency.\n",
    "- **Search Trees**: The chapter uses search trees to represent the search space, where nodes represent states and edges represent actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Problem-Solving Agents\n",
    "\n",
    "- **Scenario Description**: An agent on vacation in Romania, starting in Arad and needing to reach Bucharest with limited knowledge of the area.\n",
    "- **Problem Complexity**: Agent faces a complex decision problem due to unfamiliar geography and multiple choices (Sibiu, Timisoara, Zerind).\n",
    "- **Agent's Challenge in Unknown Environment**: Without additional information, the agent might choose actions randomly, a situation explored in Chapter 4.\n",
    "- **Four-Phase Problem-Solving Process**:\n",
    "   - **Goal Formulation**: Agent sets a clear objective (reaching Bucharest), simplifying decision-making by focusing on relevant actions.\n",
    "   - **Problem Formulation**: Agent develops an abstract model of the relevant world, here considering travel between adjacent cities, with the changing state being the current city.\n",
    "   - **Search**: Agent simulates action sequences in the model to find a solution (e.g., traveling through Sibiu, Fagaras to Bucharest) before acting in the real world.\n",
    "   - **Execution**: Once a solution is found, the agent executes the planned actions sequentially.\n",
    "\n",
    "- **Fixed Action Sequences in Certain Environments**: In fully observable, deterministic, known environments, a problem's solution is a fixed sequence of actions.\n",
    "- **Open-Loop System**: In such environments, the agent can ignore percepts during execution, as the solution is guaranteed if the model is correct.\n",
    "\n",
    "- **Adaptation in Less Predictable Environments**: In partially observable or nondeterministic environments, solutions involve branching strategies with contingency plans based on potential percepts (e.g., alternative routes in case of unexpected circumstances like road closures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Search Problems and Solutions\n",
    "\n",
    "- **Formal Definition of a Search Problem**:\n",
    "   - **State Space**: A set of possible states in which the environment can exist.\n",
    "   - **Initial State**: The starting point of the agent, e.g., Arad.\n",
    "   - **Goal States**: One or more desired states. The goal might be a single state (like Bucharest), a set of states, or defined by a certain property applicable to many states.\n",
    "   - **IS-GOAL Method**: A method to determine if a state is a goal, accommodating various types of goal states.\n",
    "   - **Actions**: Defined for each state; `ACTIONS(s)` returns a set of actions executable in state `s`.\n",
    "   - **Transition Model**: Describes the outcome of actions; `RESULT(s, a)` gives the state resulting from action `a` in state `s`.\n",
    "   - **Action Cost Function**: Denoted as `ACTION-COST(S,a, s')` or `c(s, a, s')`, it quantifies the cost of performing action `a` in state `s` to reach state `s'`. Reflects the agent's performance measure (e.g., distance, time).\n",
    "\n",
    "#### **Solution and Path**:\n",
    "\n",
    "\n",
    "- **Path**: A sequence of actions.\n",
    "- **Solution**: A path leading from the initial state to a goal state.\n",
    "- **Optimal Solution**: The solution with the lowest path cost among all solutions.\n",
    "- **Assumption of Additive Action Costs**: Total path cost is the sum of individual action costs.\n",
    "- **Positive Action Costs**: Assumes all action costs are positive to avoid complications.\n",
    "\n",
    "#### **Graphical Representation**:\n",
    "\n",
    "\n",
    "- **State Space as a Graph**: States as vertices and actions as directed edges.\n",
    "- **Example**: The map of Romania, where roads represent actions between cities (states).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Formulating Problems\n",
    "\n",
    "- **Problem Formulation as a Model**: The process of getting to Bucharest is an abstract mathematical model, not an exact representation of reality.\n",
    "   - **Example of Simplification**: The model uses simple state descriptions like \"Arad\" instead of detailed real-world elements (travel companions, radio program, scenery, law enforcement proximity, etc.).\n",
    "\n",
    "#### **Abstraction in Problem Formulation**:\n",
    "- **Definition**: Removing irrelevant details to focus on key aspects of the problem.\n",
    "- **Importance of Right Detail Level**: Too much detail (e.g., \"move right foot forward a centimeter\") can hinder finding a solution.\n",
    "\n",
    "#### **Determining Appropriate Abstraction Level**:\n",
    "- **Abstract States and Actions**: Represent large sets of detailed world states and action sequences.\n",
    "- **Abstract Solutions Correspond to Detailed Paths**: An abstract solution like traveling from Arad to Bucharest maps to many detailed real-world paths.\n",
    "\n",
    "#### **Validity and Usefulness of Abstraction**:\n",
    "- **Valid Abstraction**: If every detailed state corresponding to an abstract state (e.g., \"in Arad\") can lead to a detailed path to the next abstract state (e.g., \"in Sibiu\").\n",
    "- **Useful Abstraction**: If executing actions in the abstract solution is simpler than solving the original problem without losing validity (e.g., \"drive from Arad to Sibiu\" is a manageable task).\n",
    "\n",
    "**Goal of Good Abstraction**: To eliminate as much detail as possible while maintaining the ability to find a valid, practical solution.\n",
    "- **Necessity for Intelligent Agents**: Useful abstractions prevent agents from being overwhelmed by real-world complexities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Example Problems\n",
    "\n",
    "Discusses the application of problem-solving approaches to various task environments, distinguishing between standardized and real-world problems.\n",
    "\n",
    "   - **Standardized Problems**: Designed to illustrate or test problem-solving methods; concise and exact, serving as benchmarks for algorithm performance comparison.\n",
    "   - **Real-World Problems**: Practical problems like robot navigation, with idiosyncratic formulations due to unique aspects (e.g., different sensors in robots).\n",
    "\n",
    "### **3.2.1 Standardized Problems: Grid World Problem**:\n",
    "\n",
    "\n",
    "- **Description**: A two-dimensional grid of square cells where agents move between cells, considering obstacles and objects.\n",
    "- **States**: Defined by the location of objects in cells. In a vacuum world scenario, states include agent and dirt positions. For example, a two-cell vacuum world has 8 possible states.\n",
    "- **Initial State**: Any state can be the starting point.\n",
    "- **Actions**: Includes movements like Suck, Left, Right, and potentially Upward, Downward, Forward, Backward, TurnRight, TurnLeft.\n",
    "- **Transition Model**: Describes the outcomes of actions, like Suck removing dirt, Forward moving the agent ahead unless blocked, and directional changes.\n",
    "- **Goal States**: Typically, all cells being clean.\n",
    "- **Action Cost**: Generally, each action incurs a cost of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.2 Standardized Problems: Sokoban - 8-Puzzle Problem**:\n",
    "\n",
    "A grid world problem where the agent pushes boxes to designated storage locations.\n",
    "   - **Game Mechanics**: The agent moves forward into a cell with a box, pushing the box if the cell on the other side is empty.\n",
    "   - **Constraints**: Boxes cannot be pushed into other boxes or walls.\n",
    "   - **State Complexity**: In a grid with n non-obstacle cells and b boxes, there are n × n!/(b!(n – b)!) possible states. For example, a 12-box puzzle on an 8x8 grid has over 200 trillion states.\n",
    "\n",
    "#### **Sliding-Tile Puzzle (including 8-puzzle and 15-puzzle)**:\n",
    "\n",
    "![15 sliding tile puzzle on wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/15-Puzzle_solved.png/440px-15-Puzzle_solved.png)\n",
    "\n",
    "\n",
    "\n",
    "- **Setup**: Tiles arranged in a grid with one or more blank spaces, allowing for tile movement.\n",
    "- **Variants**: Includes Rush Hour puzzle (cars and trucks in a 6x6 grid) and well-known 8-puzzle (3x3 grid with eight tiles) and 15-puzzle (4x4 grid).\n",
    "- **Goal**: To achieve a specified goal state.\n",
    "\n",
    "#### **8-Puzzle Description**:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **States**: Defined by the location of each tile.\n",
    "- **Initial State**: Any state can be the starting point, but reachable goals are limited by a parity property.\n",
    "- **Actions**: Conceptualized as moving the blank space in different directions (Left, Right, Up, Down).\n",
    "- **Transition Model**: Describes how actions lead to new states (e.g., moving the blank space).\n",
    "- **Goal State**: Typically, tiles arranged in numerical order.\n",
    "- **Action Cost**: Each action incurs a cost of 1.\n",
    "\n",
    "#### **Abstraction in Problem Formulation**:\n",
    "\n",
    "\n",
    "- **In the 8-puzzle**: Actions are simplified to start and end states, omitting the sliding process.\n",
    "- **Physical Manipulations Excluded**: Actions like shaking or altering the puzzle physically are not considered, focusing instead on the rules of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.3 Standardized problem : Knuth's Number problem**:\n",
    "\n",
    "- **Knuth's Problem Overview**: A standardized problem proposed by Donald Knuth in 1964 demonstrating infinite state spaces.\n",
    "   - **Concept**: Reaching any desired positive integer starting from the number 4 through a sequence of specific operations.\n",
    "\n",
    "#### **Problem Definition**:\n",
    "\n",
    "\n",
    "- **States**: Positive real numbers.\n",
    "- **Initial State**: The number 4.\n",
    "- **Actions**: Three possible operations - square root, floor, and factorial (factorial applicable only to integers).\n",
    "- **Transition Model**: Based on the mathematical definitions of the square root, floor, and factorial operations.\n",
    "- **Goal State**: A specific desired positive integer.\n",
    "- **Action Cost**: Each action incurs a cost of 1.\n",
    "\n",
    "<li>**Infinite State Space**:\n",
    "\n",
    "\n",
    "- **Expansion**: The factorial operation on any integer greater than 2 results in increasingly larger integers, leading to an infinite state space.\n",
    "- **Example**: The shortest path to reach the number 5 involves a number as large as (4!)!, demonstrating the exploration of extremely large numbers.\n",
    "\n",
    "#### **Relevance in Other Tasks**:\n",
    "\n",
    "\n",
    "- **Common Occurrence of Infinite State Spaces**: Frequently found in tasks involving the generation of mathematical expressions, circuits, proofs, programs, and other recursively defined objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.4 Real-World Problems**\n",
    "\n",
    "Discusses real-world applications of problem-solving methods, contrasting with standardized problems. Examples include route-finding, airline travel planning, touring problems, VLSI layout, robot navigation, and automatic assembly sequencing.\n",
    "####  **Airline Travel Planning**:\n",
    "   - **States**: Include location, current time, and historical aspects like fare bases and domestic/international status.\n",
    "   - **Initial State**: User's home airport.\n",
    "   - **Actions**: Take any available flight, considering various factors like seat class and transfer times.\n",
    "   - **Transition Model**: New state includes flight's destination and arrival time.\n",
    "   - **Goal State**: Typically a destination city, sometimes with specific requirements (e.g., nonstop flight).\n",
    "   - **Action Cost**: Factors in monetary cost, waiting and flight times, customs procedures, seat quality, etc.\n",
    "\n",
    "#### **Touring Problems and Traveling Salesperson Problem (TSP)**:\n",
    "\n",
    "\n",
    "- **Concept**: Visiting a set of locations, not just a single goal.\n",
    "- **TSP**: Aim to find a cost-effective tour of all cities on a map.\n",
    "- **Applications**: Extended to fleet management, saving costs and reducing pollution.\n",
    "\n",
    "#### **VLSI Layout Problem**:\n",
    "\n",
    "\n",
    "- **Task**: Position components on a chip efficiently.\n",
    "- **Split into Two Parts**: Cell layout (grouping components) and channel routing (connecting wires).\n",
    "- **Complexity**: Extremely high, but crucial for manufacturing efficiency.\n",
    "\n",
    "#### **Robot Navigation**:\n",
    "\n",
    "\n",
    "- **Generalization of Route-Finding**: Robots create paths in open spaces.\n",
    "- **Complexity**: Increases with additional capabilities like arms and legs.\n",
    "- **Challenges**: Sensor errors, partial observability, environmental changes.\n",
    "\n",
    "#### **Automatic Assembly Sequencing**:\n",
    "\n",
    "\n",
    "- **Application**: Standard in industries for assembling complex objects.\n",
    "- **Process**: Find a feasible assembly sequence and optimize it to reduce manual labor.\n",
    "- **Complexity**: Selecting the right assembly order to avoid redoing work.\n",
    "- **Related Problems**: Protein design for medical applications.\n",
    "\n",
    "#### **Key Points in Real-World Problem Solving**:\n",
    "\n",
    "\n",
    "- **Complexity and Uniqueness**: Real-world problems have idiosyncratic, complex specifications.\n",
    "- **Practical Applications**: Solutions have tangible, often significant, real-world impacts.\n",
    "- **Challenges**: Include managing large state spaces, handling real-world uncertainties, and optimizing for multiple factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Search Algorithms\n",
    "\n",
    "Focuses on algorithms that process a search problem and output a solution or indicate failure.\n",
    "   - **Function**: These algorithms create a search tree over the state-space graph to explore paths from the initial state to a goal state.\n",
    "   - **Tree Structure**: Each node in the search tree represents a state in the state space, and tree edges correspond to actions. The root of the tree is the initial state.\n",
    "\n",
    "### **Distinction Between State Space and Search Tree**:\n",
    "\n",
    "\n",
    "- **State Space**: Represents the set of all possible states in the world and the actions for state transitions.\n",
    "- **Search Tree**: Describes paths within the state space, aiming towards the goal.\n",
    "- **Tree Characteristics**: Multiple paths in the search tree can lead to the same state, but each node has a unique path back to the root.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Best-First Search\n",
    "\n",
    "A search strategy that selects nodes to expand based on an evaluation function.\n",
    "   - **Key Concept**: Nodes are chosen for expansion based on their evaluation scores from a function f(n).\n",
    "   - **Process**:\n",
    "      - On each iteration, select a node from the frontier (the set of candidate nodes) with the minimum f(n) value.\n",
    "      - Check if the state of this node is a goal state; if so, return it as the solution.\n",
    "      - If not a goal state, expand the node to generate its child nodes.\n",
    "      - Add these children to the frontier if they represent new states or if they offer a lower path cost than previously encountered paths.\n",
    "   \n",
    "#### **BFS Outcome**: \n",
    "\n",
    "The algorithm returns either a path to a goal (via the selected node) or an indication of failure if no solution is found.<li>**Flexibility**: By varying the evaluation function <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(n)</annotation></semantics></math><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height: 1em; vertical-align: -0.25em;\"><span class=\"mord mathnormal\" style=\"margin-right: 0.10764em;\">, different specific algorithms can be derived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Search Data Structures\n",
    "\n",
    "Essential structures for managing the search tree in search algorithms.\n",
    "    - **Function**: These data structures store the search tree, track the states that have already been reached, and prioritize nodes for expansion.\n",
    "\n",
    "   - **Node Representation**: Each node in the search tree has four components:\n",
    "      - **node.STATE**: Corresponds to the specific state in the state space.\n",
    "      - **node.PARENT**: The node that generated this node.\n",
    "      - **node.ACTION**: The action applied to the parent's state to generate this node.\n",
    "      - **node.PATH-COST**: The total cost from the initial state to this node, often represented mathematically as g(node).\n",
    "   \n",
    "- **Path Recovery**: By following the PARENT pointers from a node, the path of states and actions to that node can be traced back, providing the solution if the node is a goal.\n",
    "\n",
    "#### **Frontier Data Structure**:\n",
    "\n",
    "\n",
    "- **Function**: Stores the frontier, or the set of all nodes available for expansion.\n",
    "- **Queue Implementation**: The frontier is typically implemented as a queue, supporting operations like IS-EMPTY, POP, TOP, and ADD.\n",
    "- **Types of Queues**:\n",
    "   - **Priority Queue**: Used in best-first search, it prioritizes nodes based on an evaluation function f(n).\n",
    "   - **FIFO Queue**: A first-in-first-out queue, used in breadth-first search, pops the earliest added node.\n",
    "   - **LIFO Queue/Stack**: Used in depth-first search, it pops the most recently added node.\n",
    "\n",
    "#### **Reached States Storage**:\n",
    "\n",
    "\n",
    "- **Implementation**: A lookup table (like a hash table) where each key is a state, and each value is the corresponding node.\n",
    "- **Purpose**: Efficiently tracks the states that have already been reached in the search process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Redundant Paths\n",
    "\n",
    "Discusses the challenge of managing redundant paths in search algorithms and strategies to address it.\n",
    "   - **Redundancy Example**: In a 10x10 grid world, an agent can reach any square in 9 moves or fewer, but the number of paths of length 9 is nearly 8^9, leading to over 100 million paths and many redundancies.\n",
    "\n",
    "- **Strategies to Handle Redundant Paths**:\n",
    "\n",
    "\n",
    "- **Remembering Past States**:\n",
    "   - **Approach**: Store all previously reached states to detect and eliminate redundant paths.\n",
    "   - **Applicability**: Suitable for state spaces with many redundant paths and where the table of reached states can fit in memory.\n",
    "\n",
    "- **Ignoring Redundancy**:\n",
    "- **Approach**: In some problems, redundant paths are rare or impossible, so tracking reached states is unnecessary.\n",
    "- **Example**: Assembly problems with a specific part order.\n",
    "- **Graph vs. Tree-Like Search**: A graph search algorithm checks for redundant paths, while a tree-like search does not.\n",
    "\n",
    "- **Compromising by Checking for Cycles**:\n",
    "- **Approach**: Check for cycles in the path without storing all reached states.\n",
    "- **Implementation**: Trace the chain of parent pointers to see if a state reappears in its own path.\n",
    "- **Variations**: Some implementations check the entire parent chain (eliminating all cycles), while others check only a few levels up (eliminating short cycles).\n",
    "\n",
    "#### **Redundant Paths Impact on Performance**:\n",
    "\n",
    "\n",
    "- **Memory Usage**: Strategies vary in their memory requirements.\n",
    "- **Speed**: Eliminating redundant paths can significantly increase search efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Measuring Problem-Solving Performance\n",
    "\n",
    "Criteria for evaluating the effectiveness of search algorithms.\n",
    "   - **Completeness**: Whether the algorithm can always find a solution if one exists and report failure when there is no solution.\n",
    "   - **Cost Optimality**: The ability of the algorithm to find the least costly solution among all possible solutions.\n",
    "   - **Time Complexity**: The duration or the number of states and actions considered to find a solution.\n",
    "   - **Space Complexity**: The amount of memory required to perform the search.\n",
    "\n",
    "#### **Understanding Completeness**:\n",
    "\n",
    "\n",
    "- **Finite State Spaces**: In these spaces, completeness is achievable by systematically exploring every reachable state and avoiding cycles.\n",
    "- **Infinite State Spaces**: Requires more systematic exploration to ensure every reachable state is eventually reached.\n",
    "- **Example**: On an infinite grid, a spiral path that incrementally expands outward is systematic but might not find a solution if the space is infinite and the solution is absent.\n",
    "\n",
    "#### **Time and Space Complexity**:\n",
    "\n",
    "\n",
    "- **Theoretical Measure**: Typically based on the size of the state-space graph (|V| + |E|), with |V| as vertices and |E| as edges.\n",
    "- **Implicit State Space Complexity**: Measured in terms of the depth of the solution (d), the maximum length of any path (m), and the branching factor (b) or the number of successors a node has.\n",
    "\n",
    "#### **Practical Implications**:\n",
    "\n",
    "\n",
    "- **Infinite State Spaces**: A complete algorithm must search indefinitely in the absence of a solution.\n",
    "- **Optimizing Performance**: Choosing an algorithm involves balancing time and space complexity with completeness and cost optimality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Uninformed Search Strategies \n",
    "\n",
    "Discusses search algorithms that operate without any information on the proximity of a state to the goal.\n",
    "\n",
    "   - **Key Characteristic**: These algorithms do not use any domain-specific knowledge or heuristics to estimate the distance to the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Breadth-First Search Overview\n",
    "\n",
    " A search strategy used when all actions have the same cost.\n",
    "   - **Key Concept**: Expands the shallowest unexpanded node first.\n",
    "   - **Expansion Order**: The root node is expanded first, followed by all its successors, then their successors, and so on.\n",
    "   - **Completeness**: This method is complete, meaning it will find a solution if one exists, even in infinite state spaces.\n",
    "   - **Implementation as Best-First Search**: It can be implemented using the BEST-FIRST-SEARCH algorithm with the node depth as the evaluation function f(n).\n",
    "\n",
    "#### Efficiency Enhancements to BFS\n",
    "\n",
    "\n",
    "- **FIFO Queue**: A first-in-first-out queue is more efficient than a priority queue for this strategy. New nodes are added to the back of the queue, ensuring that shallower nodes are expanded first.\n",
    "- **Reached States as a Set**: The 'reached' structure can be a set of states, not a mapping from states to nodes, because once a state is reached, a better path to it is not possible under this strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Dijkstra’s Algorithm or Uniform-Cost Search\n",
    "\n",
    " A search strategy used when actions have varying costs.\n",
    "\n",
    "    - **Key Concept**: Expands the node with the lowest path cost g(n).\n",
    "   - **Strategy**: Employs a best-first search where the evaluation function is the cumulative cost of the path from the root to the current node.\n",
    "   - **Naming**: Known as Dijkstra’s algorithm in theoretical computer science and uniform-cost search in AI.\n",
    "   - **Operation Principle**: Unlike breadth-first search, which expands nodes in waves based on uniform depth, uniform-cost search expands nodes in waves based on uniform path cost.\n",
    "   - **Implementation**: Can be executed as a call to BEST-FIRST-SEARCH, using PATH-COST as the evaluation function.\n",
    "\n",
    "   Note: we discuss the implementation of Dijkstra's algorithm extensively in algorithms course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Depth-First Search and Memory Considerations\n",
    "\n",
    " Focuses on the depth-first search strategy and its implications on memory usage.\n",
    "   - **Expansion Strategy**: Depth-first search always expands the deepest node in the frontier first.\n",
    "   - **Implementation**: Often implemented as a tree-like search without a table of reached states, unlike a typical graph search. Can be thought of as BEST-FIRST-SEARCH with an evaluation function f as the negative depth.\n",
    "   - **Behavior**: Proceeds to the deepest level of the search tree first, backing up when it encounters nodes without successors.\n",
    "   - **Cost-Optimality**: Not cost-optimal; finds the first solution, not necessarily the cheapest.\n",
    "\n",
    "##### DFS Efficiency and Completeness\n",
    "\n",
    "\n",
    "- **Finite Tree State Spaces**: Efficient and complete.\n",
    "- **Acyclic State Spaces**: Can expand the same state multiple times via different paths but will eventually explore the entire space.\n",
    "- **Cyclic State Spaces**: Risk of getting stuck in infinite loops; some implementations check for cycles to prevent this.\n",
    "- **Infinite State Spaces**: Incomplete as it can get stuck on an infinite path, especially in the absence of cycles.\n",
    "\n",
    "#### Advantages of Depth-First Search\n",
    "\n",
    "\n",
    "- **Memory Efficiency**: Particularly advantageous for problems where a tree-like search is feasible due to its lower memory requirements.\n",
    "- **Frontier Size**: Comparatively smaller than in breadth-first search; analogous to the radius of an expanding sphere versus its surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Depth-Limited and Iterative Deepening Search Overview\n",
    "\n",
    " Strategies to improve and optimize depth-first search.\n",
    "\n",
    "- **Depth-Limited Search**:\n",
    "   - **Concept**: A variant of depth-first search with a predetermined depth limit\n",
    "   l\n",
    "   - **Behavior**: Treats nodes at depth l as if they have no successors.\n",
    "   - **Complexity**: Time complexity is O(bl)\n",
    "   - **Limitation**: Incomplete if the depth limit is too low to reach the solution.\n",
    "\n",
    "\n",
    "#### Eliminating Cycles in Depth-Limited Search\n",
    "\n",
    "\n",
    "- **Strategy**: Check a few links up in the parent chain to catch most cycles.\n",
    "- **Depth Limit Based on Problem Knowledge**: Using known problem metrics, such as the state-space graph's diameter, to set a more effective depth limit.\n",
    "\n",
    "#### Iterative Deepening Search\n",
    "\n",
    "\n",
    "- **Method**: Repeatedly applies depth-limited search with incrementally increasing depth limits.\n",
    "- **Outcomes**: Returns a solution, failure (if no solution exists), or a cutoff (indicating a potential solution at a deeper level).\n",
    "- **Advantages**: Combines the benefits of depth-first search (low memory use) and breadth-first search (completeness and optimality for uniform-cost problems).\n",
    "- **Memory Efficiency**: Does not track reached states, using less memory but potentially revisiting states.\n",
    "- **Complexity**: Time complexity is\n",
    "O(b^d) when a solution exists or\n",
    "O(b^m) otherwise. What is m? m is the maximum depth of the state space. m is not known in advance, but it is at least d, the depth of the shallowest goal state. Therefore, the time complexity is at most O(b^m).\n",
    "- **Efficiency in State Space Exploration**: While it regenerates upper-level nodes multiple times, the bulk of nodes are often at the bottom level, making this repetition less significant.\n",
    "\n",
    "#### Hybrid Approach\n",
    "\n",
    "\n",
    "- **Combination of Strategies**: Starts with breadth-first search until memory is nearly full, then switches to iterative deepening.\n",
    "- **Applicability**: Preferred when the state space is too large for memory and the solution depth is unknown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Bidirectional Search Overview\n",
    "\n",
    " An alternative search strategy that operates simultaneously from both the initial and goal states.\n",
    "\n",
    "   - **Approach**: Searches forward from the initial state and backward from the goal state, aiming for the two searches to meet.\n",
    "   - **Efficiency**: Significantly more efficient than unidirectional search in many cases (e.g., reduces search effort from b^d to 2(b^d/2)).\n",
    "\n",
    "\n",
    "#### Implementation Requirements\n",
    "\n",
    "\n",
    "- **Dual Frontiers and Reached States**: Maintains two separate sets of frontiers and reached states for both forward and backward searches.\n",
    "- **Backward Reasoning Capability**: Ability to infer backward transitions from a state to its predecessors.\n",
    "- **Collision Detection**: Identifies when the two frontiers meet, indicating a solution.\n",
    "\n",
    "#### Bidirectional Best-First Search\n",
    "\n",
    "\n",
    "- **Node Selection**: Chooses the next node to expand based on the minimum value of the evaluation function across both frontiers.\n",
    "- **Variants**: When the evaluation function is the path cost, it becomes bidirectional uniform-cost search.\n",
    "- **Optimality**: If the evaluation function is path cost, the first solution found is optimal. With different evaluation functions, this may not be true.\n",
    "\n",
    "#### Optimizing Search Performance \n",
    "\n",
    "\n",
    "- **Forward and Backward Problem Versions**: Requires two versions of the problem and the evaluation function (one for each direction).\n",
    "- **Tracking Optimal Solutions**: Continuously updates the best solution found until it's certain no better solution exists.\n",
    "\n",
    "#### General Considerations\n",
    "\n",
    "\n",
    "- **Speedup Potential**: Can significantly reduce search time, especially in large state spaces.\n",
    "- **Complexity**: Requires handling two search processes and effectively managing their interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6 Uninformed Search Strategies Comparison\n",
    "\n",
    "![Comparison](https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch3_solving_problems_by_search/uninformed_search_comparison_315.jpg?raw=true)\n",
    "\n",
    "Src: Russell, Stuart J.; Norvig, Peter. Artificial Intelligence: A Modern Approach 4th Edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Informed (Heuristic) Search Strategies\n",
    "\n",
    "Discusses search strategies that use additional domain-specific information to find solutions more efficiently compared to uninformed strategies.\n",
    "\n",
    "   - **Key Feature**: Utilization of heuristic functions to guide the search.\n",
    "   - **Heuristic Function   h(n)**: Estimates the cost of the cheapest path from the state at node n to a goal state.\n",
    "\n",
    "### **Application Example**:\n",
    "\n",
    "\n",
    "- **Route-Finding Problems**: The heuristic might be the straight-line distance (as the crow flies) between the current state and the goal state, providing a simple yet effective estimation of distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Greedy Best-First Search\n",
    "\n",
    "Strategy that expands the node closest to the goal, as determined by the heuristic function.\n",
    "   - **Key Concept**: Expands the node that appears to be closest to the goal.\n",
    "   - **Implementation**: Can be implemented as a call to BEST-FIRST-SEARCH, using the heuristic function h(n) as the evaluation function.\n",
    "   - **Optimality**: Not optimal, can lead to suboptimal solutions. The tempting next jump solution is not always the best one!\n",
    "   - **Completeness**: Complete in finite state spaces but incomplete in infinite state spaces.\n",
    "\n",
    "#### Complexity\n",
    "\n",
    "Worst-case time and space complexity is O(|V|), where |V| is the number of vertices in the state space graph. With good heuristics, the complexity is often much lower aproaching O(bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 A* Search (A-Star Search)\n",
    "\n",
    "A search strategy that combines the advantages of uniform-cost search and greedy best-first search.\n",
    "   - **Key Concept**: Expands the node with the lowest value of g(n) + h(n).\n",
    "   - **Implementation**: Can be implemented as a call to BEST-FIRST-SEARCH, using the evaluation function f(n) = g(n) + h(n).\n",
    "   - **Optimality**: Optimal if the heuristic function h(n) is admissible, meaning it never overestimates the cost to reach the goal.\n",
    "   - **Completeness**: Complete in finite state spaces but incomplete in infinite state spaces.\n",
    "   - **Complexity**: Time and space complexity is O(b^d) in the worst case, where b is the branching factor and d is the depth of the shallowest goal state. With good heuristics, the complexity is often much lower.\n",
    "\n",
    "#### Importance of A* Search\n",
    "\n",
    "A* search is the most widely used search algorithm in AI, with applications in route planning, robotics, and other areas. It is also the basis for many other algorithms, including IDA* and AO*. \n",
    "\n",
    "A* search is widely used in computer games, where it is used to find paths for characters and to evaluate board positions in chess and other games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Search Contours\n",
    "\n",
    "A method to visualize the search process in A* search.\n",
    "   - **Concept**: A contour is a set of nodes with the same value of f(n) = g(n) + h(n).\n",
    "   - **Visualization**: The search process can be visualized as a series of nested contours, with the goal state at the center.\n",
    "   - **Contour Expansion**: Contours are expanded in order of increasing f(n) values, with the lowest f(n) value expanded first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Satisficing search: Inadmissible heuristics and weighted A∗\n",
    "\n",
    "   - **Basic Concept**: Satisficing search aims to find a 'good enough' solution efficiently, rather than the optimal one. It's particularly useful in complex problems where finding the optimal solution is too time-consuming or computationally expensive.\n",
    "   - **Inadmissible Heuristics**: Unlike admissible heuristics (which never overestimate the cost to the goal), inadmissible heuristics can overestimate costs. They are used in satisficing search to potentially speed up the search process at the expense of optimality.\n",
    "   - *\n",
    "   Weighted A* Search\n",
    "   *: An extension of A* search, where the heuristic component\n",
    "    h(n) of the evaluation function\n",
    "   f(n) = g(n) + h(n)\n",
    "\n",
    " is multiplied by a weight\n",
    "   w\n",
    "   w\n",
    "   w greater than 1. This modification biases the search towards the goal, potentially reducing the search time.\n",
    "   - **Trade-Off**: The increase in weight\n",
    "   w can significantly speed up the search but also increases the risk of missing the shortest path. The goal is to strike a balance between search speed and solution quality.\n",
    "   - **Applicability**: Useful in scenarios where time or computational resources are limited, and a reasonably good solution is acceptable over the absolute best solution.\n",
    "   - **Practical Considerations**: Choosing the right weight and heuristic is crucial. Too high a weight might lead to very suboptimal solutions, while too low might not improve search efficiency appreciably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

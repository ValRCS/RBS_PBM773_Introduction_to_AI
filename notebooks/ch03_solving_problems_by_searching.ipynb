{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Solving Problems with Search\n",
    "\n",
    "- **Chapter 3 Overview**: Focuses on problem-solving through search, demonstrating how an agent plans a sequence of actions to achieve a goal.\n",
    "- **Problem-solving Agent**: An agent that needs to plan a series of actions leading to a goal state; involves a computational process known as search.\n",
    "- **Atomic Representations**: Used by problem-solving agents, where states of the world are considered as indivisible wholes without internal structure (referenced from Section 2.4.7).\n",
    "- **Contrast with Planning Agents**: Planning agents, using factored or structured state representations, are discussed in later chapters (7 and 11).\n",
    "- **Search Algorithms**: Introduction to several search algorithms within simple environments characterized by being episodic, single-agent, fully observable, deterministic, static, discrete, and known.\n",
    "- **Informed vs. Uninformed Algorithms**: Distinction between algorithms where agents can estimate distance to the goal (informed) and those without such estimates (uninformed).\n",
    "- **Expansion in Subsequent Chapters**: Chapter 4 expands on environmental constraints, and Chapter 6 delves into scenarios involving multiple agents.\n",
    "- **Asymptotic Complexity**: The chapter employs concepts of asymptotic complexity, specifically O(n) notation, to describe algorithm efficiency.\n",
    "- **Search Trees**: The chapter uses search trees to represent the search space, where nodes represent states and edges represent actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Problem-Solving Agents\n",
    "\n",
    "- **Scenario Description**: An agent on vacation in Romania, starting in Arad and needing to reach Bucharest with limited knowledge of the area.\n",
    "- **Problem Complexity**: Agent faces a complex decision problem due to unfamiliar geography and multiple choices (Sibiu, Timisoara, Zerind).\n",
    "- **Agent's Challenge in Unknown Environment**: Without additional information, the agent might choose actions randomly, a situation explored in Chapter 4.\n",
    "- **Four-Phase Problem-Solving Process**:\n",
    "   - **Goal Formulation**: Agent sets a clear objective (reaching Bucharest), simplifying decision-making by focusing on relevant actions.\n",
    "   - **Problem Formulation**: Agent develops an abstract model of the relevant world, here considering travel between adjacent cities, with the changing state being the current city.\n",
    "   - **Search**: Agent simulates action sequences in the model to find a solution (e.g., traveling through Sibiu, Fagaras to Bucharest) before acting in the real world.\n",
    "   - **Execution**: Once a solution is found, the agent executes the planned actions sequentially.\n",
    "\n",
    "- **Fixed Action Sequences in Certain Environments**: In fully observable, deterministic, known environments, a problem's solution is a fixed sequence of actions.\n",
    "- **Open-Loop System**: In such environments, the agent can ignore percepts during execution, as the solution is guaranteed if the model is correct.\n",
    "\n",
    "- **Adaptation in Less Predictable Environments**: In partially observable or nondeterministic environments, solutions involve branching strategies with contingency plans based on potential percepts (e.g., alternative routes in case of unexpected circumstances like road closures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Search Problems and Solutions\n",
    "\n",
    "- **Formal Definition of a Search Problem**:\n",
    "   - **State Space**: A set of possible states in which the environment can exist.\n",
    "   - **Initial State**: The starting point of the agent, e.g., Arad.\n",
    "   - **Goal States**: One or more desired states. The goal might be a single state (like Bucharest), a set of states, or defined by a certain property applicable to many states.\n",
    "   - **IS-GOAL Method**: A method to determine if a state is a goal, accommodating various types of goal states.\n",
    "   - **Actions**: Defined for each state; `ACTIONS(s)` returns a set of actions executable in state `s`.\n",
    "   - **Transition Model**: Describes the outcome of actions; `RESULT(s, a)` gives the state resulting from action `a` in state `s`.\n",
    "   - **Action Cost Function**: Denoted as `ACTION-COST(S,a, s')` or `c(s, a, s')`, it quantifies the cost of performing action `a` in state `s` to reach state `s'`. Reflects the agent's performance measure (e.g., distance, time).\n",
    "\n",
    "#### **Solution and Path**:\n",
    "\n",
    "\n",
    "- **Path**: A sequence of actions.\n",
    "- **Solution**: A path leading from the initial state to a goal state.\n",
    "- **Optimal Solution**: The solution with the lowest path cost among all solutions.\n",
    "- **Assumption of Additive Action Costs**: Total path cost is the sum of individual action costs.\n",
    "- **Positive Action Costs**: Assumes all action costs are positive to avoid complications.\n",
    "\n",
    "#### **Graphical Representation**:\n",
    "\n",
    "\n",
    "- **State Space as a Graph**: States as vertices and actions as directed edges.\n",
    "- **Example**: The map of Romania, where roads represent actions between cities (states).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Formulating Problems\n",
    "\n",
    "- **Problem Formulation as a Model**: The process of getting to Bucharest is an abstract mathematical model, not an exact representation of reality.\n",
    "   - **Example of Simplification**: The model uses simple state descriptions like \"Arad\" instead of detailed real-world elements (travel companions, radio program, scenery, law enforcement proximity, etc.).\n",
    "\n",
    "#### **Abstraction in Problem Formulation**:\n",
    "- **Definition**: Removing irrelevant details to focus on key aspects of the problem.\n",
    "- **Importance of Right Detail Level**: Too much detail (e.g., \"move right foot forward a centimeter\") can hinder finding a solution.\n",
    "\n",
    "#### **Determining Appropriate Abstraction Level**:\n",
    "- **Abstract States and Actions**: Represent large sets of detailed world states and action sequences.\n",
    "- **Abstract Solutions Correspond to Detailed Paths**: An abstract solution like traveling from Arad to Bucharest maps to many detailed real-world paths.\n",
    "\n",
    "#### **Validity and Usefulness of Abstraction**:\n",
    "- **Valid Abstraction**: If every detailed state corresponding to an abstract state (e.g., \"in Arad\") can lead to a detailed path to the next abstract state (e.g., \"in Sibiu\").\n",
    "- **Useful Abstraction**: If executing actions in the abstract solution is simpler than solving the original problem without losing validity (e.g., \"drive from Arad to Sibiu\" is a manageable task).\n",
    "\n",
    "**Goal of Good Abstraction**: To eliminate as much detail as possible while maintaining the ability to find a valid, practical solution.\n",
    "- **Necessity for Intelligent Agents**: Useful abstractions prevent agents from being overwhelmed by real-world complexities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Example Problems\n",
    "\n",
    "Discusses the application of problem-solving approaches to various task environments, distinguishing between standardized and real-world problems.\n",
    "\n",
    "   - **Standardized Problems**: Designed to illustrate or test problem-solving methods; concise and exact, serving as benchmarks for algorithm performance comparison.\n",
    "   - **Real-World Problems**: Practical problems like robot navigation, with idiosyncratic formulations due to unique aspects (e.g., different sensors in robots).\n",
    "\n",
    "### **3.2.1 Standardized Problems: Grid World Problem**:\n",
    "\n",
    "\n",
    "- **Description**: A two-dimensional grid of square cells where agents move between cells, considering obstacles and objects.\n",
    "- **States**: Defined by the location of objects in cells. In a vacuum world scenario, states include agent and dirt positions. For example, a two-cell vacuum world has 8 possible states.\n",
    "- **Initial State**: Any state can be the starting point.\n",
    "- **Actions**: Includes movements like Suck, Left, Right, and potentially Upward, Downward, Forward, Backward, TurnRight, TurnLeft.\n",
    "- **Transition Model**: Describes the outcomes of actions, like Suck removing dirt, Forward moving the agent ahead unless blocked, and directional changes.\n",
    "- **Goal States**: Typically, all cells being clean.\n",
    "- **Action Cost**: Generally, each action incurs a cost of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.2 Standardized Problems: Sokoban - 8-Puzzle Problem**:\n",
    "\n",
    "A grid world problem where the agent pushes boxes to designated storage locations.\n",
    "   - **Game Mechanics**: The agent moves forward into a cell with a box, pushing the box if the cell on the other side is empty.\n",
    "   - **Constraints**: Boxes cannot be pushed into other boxes or walls.\n",
    "   - **State Complexity**: In a grid with n non-obstacle cells and b boxes, there are n × n!/(b!(n – b)!) possible states. For example, a 12-box puzzle on an 8x8 grid has over 200 trillion states.\n",
    "\n",
    "#### **Sliding-Tile Puzzle (including 8-puzzle and 15-puzzle)**:\n",
    "\n",
    "![15 sliding tile puzzle on wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/15-Puzzle_solved.png/440px-15-Puzzle_solved.png)\n",
    "\n",
    "\n",
    "\n",
    "- **Setup**: Tiles arranged in a grid with one or more blank spaces, allowing for tile movement.\n",
    "- **Variants**: Includes Rush Hour puzzle (cars and trucks in a 6x6 grid) and well-known 8-puzzle (3x3 grid with eight tiles) and 15-puzzle (4x4 grid).\n",
    "- **Goal**: To achieve a specified goal state.\n",
    "\n",
    "#### **8-Puzzle Description**:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **States**: Defined by the location of each tile.\n",
    "- **Initial State**: Any state can be the starting point, but reachable goals are limited by a parity property.\n",
    "- **Actions**: Conceptualized as moving the blank space in different directions (Left, Right, Up, Down).\n",
    "- **Transition Model**: Describes how actions lead to new states (e.g., moving the blank space).\n",
    "- **Goal State**: Typically, tiles arranged in numerical order.\n",
    "- **Action Cost**: Each action incurs a cost of 1.\n",
    "\n",
    "#### **Abstraction in Problem Formulation**:\n",
    "\n",
    "\n",
    "- **In the 8-puzzle**: Actions are simplified to start and end states, omitting the sliding process.\n",
    "- **Physical Manipulations Excluded**: Actions like shaking or altering the puzzle physically are not considered, focusing instead on the rules of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.3 Standardized problem : Knuth's Number problem**:\n",
    "\n",
    "- **Knuth's Problem Overview**: A standardized problem proposed by Donald Knuth in 1964 demonstrating infinite state spaces.\n",
    "   - **Concept**: Reaching any desired positive integer starting from the number 4 through a sequence of specific operations.\n",
    "\n",
    "#### **Problem Definition**:\n",
    "\n",
    "\n",
    "- **States**: Positive real numbers.\n",
    "- **Initial State**: The number 4.\n",
    "- **Actions**: Three possible operations - square root, floor, and factorial (factorial applicable only to integers).\n",
    "- **Transition Model**: Based on the mathematical definitions of the square root, floor, and factorial operations.\n",
    "- **Goal State**: A specific desired positive integer.\n",
    "- **Action Cost**: Each action incurs a cost of 1.\n",
    "\n",
    "<li>**Infinite State Space**:\n",
    "\n",
    "\n",
    "- **Expansion**: The factorial operation on any integer greater than 2 results in increasingly larger integers, leading to an infinite state space.\n",
    "- **Example**: The shortest path to reach the number 5 involves a number as large as (4!)!, demonstrating the exploration of extremely large numbers.\n",
    "\n",
    "#### **Relevance in Other Tasks**:\n",
    "\n",
    "\n",
    "- **Common Occurrence of Infinite State Spaces**: Frequently found in tasks involving the generation of mathematical expressions, circuits, proofs, programs, and other recursively defined objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2.4 Real-World Problems**\n",
    "\n",
    "Discusses real-world applications of problem-solving methods, contrasting with standardized problems. Examples include route-finding, airline travel planning, touring problems, VLSI layout, robot navigation, and automatic assembly sequencing.\n",
    "####  **Airline Travel Planning**:\n",
    "   - **States**: Include location, current time, and historical aspects like fare bases and domestic/international status.\n",
    "   - **Initial State**: User's home airport.\n",
    "   - **Actions**: Take any available flight, considering various factors like seat class and transfer times.\n",
    "   - **Transition Model**: New state includes flight's destination and arrival time.\n",
    "   - **Goal State**: Typically a destination city, sometimes with specific requirements (e.g., nonstop flight).\n",
    "   - **Action Cost**: Factors in monetary cost, waiting and flight times, customs procedures, seat quality, etc.\n",
    "\n",
    "#### **Touring Problems and Traveling Salesperson Problem (TSP)**:\n",
    "\n",
    "\n",
    "- **Concept**: Visiting a set of locations, not just a single goal.\n",
    "- **TSP**: Aim to find a cost-effective tour of all cities on a map.\n",
    "- **Applications**: Extended to fleet management, saving costs and reducing pollution.\n",
    "\n",
    "#### **VLSI Layout Problem**:\n",
    "\n",
    "\n",
    "- **Task**: Position components on a chip efficiently.\n",
    "- **Split into Two Parts**: Cell layout (grouping components) and channel routing (connecting wires).\n",
    "- **Complexity**: Extremely high, but crucial for manufacturing efficiency.\n",
    "\n",
    "#### **Robot Navigation**:\n",
    "\n",
    "\n",
    "- **Generalization of Route-Finding**: Robots create paths in open spaces.\n",
    "- **Complexity**: Increases with additional capabilities like arms and legs.\n",
    "- **Challenges**: Sensor errors, partial observability, environmental changes.\n",
    "\n",
    "#### **Automatic Assembly Sequencing**:\n",
    "\n",
    "\n",
    "- **Application**: Standard in industries for assembling complex objects.\n",
    "- **Process**: Find a feasible assembly sequence and optimize it to reduce manual labor.\n",
    "- **Complexity**: Selecting the right assembly order to avoid redoing work.\n",
    "- **Related Problems**: Protein design for medical applications.\n",
    "\n",
    "#### **Key Points in Real-World Problem Solving**:\n",
    "\n",
    "\n",
    "- **Complexity and Uniqueness**: Real-world problems have idiosyncratic, complex specifications.\n",
    "- **Practical Applications**: Solutions have tangible, often significant, real-world impacts.\n",
    "- **Challenges**: Include managing large state spaces, handling real-world uncertainties, and optimizing for multiple factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Search Algorithms\n",
    "\n",
    "Focuses on algorithms that process a search problem and output a solution or indicate failure.\n",
    "   - **Function**: These algorithms create a search tree over the state-space graph to explore paths from the initial state to a goal state.\n",
    "   - **Tree Structure**: Each node in the search tree represents a state in the state space, and tree edges correspond to actions. The root of the tree is the initial state.\n",
    "\n",
    "### **Distinction Between State Space and Search Tree**:\n",
    "\n",
    "\n",
    "- **State Space**: Represents the set of all possible states in the world and the actions for state transitions.\n",
    "- **Search Tree**: Describes paths within the state space, aiming towards the goal.\n",
    "- **Tree Characteristics**: Multiple paths in the search tree can lead to the same state, but each node has a unique path back to the root.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Best-First Search\n",
    "\n",
    "A search strategy that selects nodes to expand based on an evaluation function.\n",
    "   - **Key Concept**: Nodes are chosen for expansion based on their evaluation scores from a function f(n).\n",
    "   - **Process**:\n",
    "      - On each iteration, select a node from the frontier (the set of candidate nodes) with the minimum f(n) value.\n",
    "      - Check if the state of this node is a goal state; if so, return it as the solution.\n",
    "      - If not a goal state, expand the node to generate its child nodes.\n",
    "      - Add these children to the frontier if they represent new states or if they offer a lower path cost than previously encountered paths.\n",
    "   \n",
    "#### **BFS Outcome**: \n",
    "\n",
    "The algorithm returns either a path to a goal (via the selected node) or an indication of failure if no solution is found.<li>**Flexibility**: By varying the evaluation function <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(n)</annotation></semantics></math><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height: 1em; vertical-align: -0.25em;\"><span class=\"mord mathnormal\" style=\"margin-right: 0.10764em;\">, different specific algorithms can be derived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Search Data Structures\n",
    "\n",
    "Essential structures for managing the search tree in search algorithms.\n",
    "    - **Function**: These data structures store the search tree, track the states that have already been reached, and prioritize nodes for expansion.\n",
    "\n",
    "   - **Node Representation**: Each node in the search tree has four components:\n",
    "      - **node.STATE**: Corresponds to the specific state in the state space.\n",
    "      - **node.PARENT**: The node that generated this node.\n",
    "      - **node.ACTION**: The action applied to the parent's state to generate this node.\n",
    "      - **node.PATH-COST**: The total cost from the initial state to this node, often represented mathematically as g(node).\n",
    "   \n",
    "- **Path Recovery**: By following the PARENT pointers from a node, the path of states and actions to that node can be traced back, providing the solution if the node is a goal.\n",
    "\n",
    "#### **Frontier Data Structure**:\n",
    "\n",
    "\n",
    "- **Function**: Stores the frontier, or the set of all nodes available for expansion.\n",
    "- **Queue Implementation**: The frontier is typically implemented as a queue, supporting operations like IS-EMPTY, POP, TOP, and ADD.\n",
    "- **Types of Queues**:\n",
    "   - **Priority Queue**: Used in best-first search, it prioritizes nodes based on an evaluation function f(n).\n",
    "   - **FIFO Queue**: A first-in-first-out queue, used in breadth-first search, pops the earliest added node.\n",
    "   - **LIFO Queue/Stack**: Used in depth-first search, it pops the most recently added node.\n",
    "\n",
    "#### **Reached States Storage**:\n",
    "\n",
    "\n",
    "- **Implementation**: A lookup table (like a hash table) where each key is a state, and each value is the corresponding node.\n",
    "- **Purpose**: Efficiently tracks the states that have already been reached in the search process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Redundant Paths\n",
    "\n",
    "Discusses the challenge of managing redundant paths in search algorithms and strategies to address it.\n",
    "   - **Redundancy Example**: In a 10x10 grid world, an agent can reach any square in 9 moves or fewer, but the number of paths of length 9 is nearly 8^9, leading to over 100 million paths and many redundancies.\n",
    "\n",
    "- **Strategies to Handle Redundant Paths**:\n",
    "\n",
    "\n",
    "- **Remembering Past States**:\n",
    "   - **Approach**: Store all previously reached states to detect and eliminate redundant paths.\n",
    "   - **Applicability**: Suitable for state spaces with many redundant paths and where the table of reached states can fit in memory.\n",
    "\n",
    "- **Ignoring Redundancy**:\n",
    "- **Approach**: In some problems, redundant paths are rare or impossible, so tracking reached states is unnecessary.\n",
    "- **Example**: Assembly problems with a specific part order.\n",
    "- **Graph vs. Tree-Like Search**: A graph search algorithm checks for redundant paths, while a tree-like search does not.\n",
    "\n",
    "- **Compromising by Checking for Cycles**:\n",
    "- **Approach**: Check for cycles in the path without storing all reached states.\n",
    "- **Implementation**: Trace the chain of parent pointers to see if a state reappears in its own path.\n",
    "- **Variations**: Some implementations check the entire parent chain (eliminating all cycles), while others check only a few levels up (eliminating short cycles).\n",
    "\n",
    "#### **Redundant Paths Impact on Performance**:\n",
    "\n",
    "\n",
    "- **Memory Usage**: Strategies vary in their memory requirements.\n",
    "- **Speed**: Eliminating redundant paths can significantly increase search efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

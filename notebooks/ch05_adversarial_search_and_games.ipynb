{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search and Games\n",
    "\n",
    "From: [Artificial Intelligence: A Modern Approach](http://aima.cs.berkeley.edu/) by Stuart Russell and Peter Norvig.\n",
    "\n",
    "Note:\n",
    "\n",
    "- Chapter 5 in US edition.\n",
    "- Chapter 6 in International (Global) edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "- **Characteristics**: Environments where agents compete against each other.\n",
    "- **Zero-Sum Games**: Often modeled as zero-sum games, where one agent's gain is another's loss.\n",
    "- **Multi-Agent Systems**: Involves multiple agents with conflicting goals.\n",
    "- **Dynamic Interaction**: Agents' actions directly affect each other.\n",
    "- **Uncertainty and Strategy**: Requires anticipation of opponents' actions.\n",
    "\n",
    "### Adversarial Search\n",
    "\n",
    "- **Definition**: A search in a competitive environment where the outcome depends on actions of multiple agents (opponents).\n",
    "- **Goal**: To find optimal strategies that lead to success in spite of adversaries' actions.\n",
    "- **Minimax Algorithm**: A common approach in adversarial search to minimize the possible loss in a worst-case scenario.\n",
    "- **Game Trees**: Used to represent possible moves by players.\n",
    "- **Evaluation Functions**: Estimate the desirability of game positions when it's impractical to search until the end of the game.\n",
    "\n",
    "### Examples of Games\n",
    "\n",
    "- **Chess**: A classic two-player strategy board game with complete information.\n",
    "- **Checkers (Draughts)**: Similar to chess but with simpler rules, played on an 8x8 board.\n",
    "- **Go**: An ancient board game known for its complexity and rich strategy, played on a 19x19 grid.\n",
    "- **Poker**: A card game characterized by incomplete information and uncertainty.\n",
    "- **Tic-Tac-Toe**: A simple two-player game often used as an introductory example of game theory and AI strategy.\n",
    "\n",
    "These topics represent key aspects of how AI can be applied in competitive environments, showcasing the complexity and the need for advanced strategies in game playing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Games\n",
    "\n",
    "Physical games, as opposed to traditional tabletop games like chess or checkers, involve a complex interplay of physical skills, real-time decision making, and often team dynamics. \n",
    "\n",
    "Until recently physical games were considered too complex for AI, but recent advances in robotics and reinforcement learning have enabled AI agents to compete in physical games like soccer and basketball.\n",
    "\n",
    "Here are some examples of physical games and an explanation of their complexity compared to tabletop games:\n",
    "\n",
    "### Soccer (Football)\n",
    "\n",
    "- **Dynamic Environment**: The game is played in a large, open field with continuous play, requiring constant adaptation.\n",
    "- **Physical Skills**: Players need to excel in coordination, endurance, and agility.\n",
    "- **Team Strategy**: Involves complex team dynamics and coordination for defense, midfield control, and attacking.\n",
    "- **Real-Time Decisions**: Players make split-second decisions under physical pressure.\n",
    "- **Unpredictable Play**: The ball's movement can be highly unpredictable, influenced by weather, field conditions, and players' actions.\n",
    "\n",
    "### Basketball\n",
    "\n",
    "- **Rapid Pace**: The game is fast-paced with frequent changes in possession and continuous movement.\n",
    "- **Physical Interaction**: Close physical interaction between players, including blocking and dodging.\n",
    "- **Spatial Awareness**: High level of spatial awareness required to navigate the court and anticipate opponents' and teammates' movements.\n",
    "- **Skill Diversity**: Players need a diverse set of skills like shooting, dribbling, passing, and defending.\n",
    "\n",
    "### Tennis\n",
    "\n",
    "- **Individual Strategy**: Singles tennis requires a high level of personal strategy, adapting to opponents' playing style.\n",
    "- **Physical Precision**: Precision in serving and returning, along with stamina, plays a crucial role.\n",
    "- **Psychological Aspect**: Players often have to overcome psychological challenges and maintain focus throughout the match.\n",
    "\n",
    "### American Football\n",
    "\n",
    "- **Complex Playbooks**: Teams have extensive playbooks, requiring players to memorize and execute complex plays.\n",
    "- **Physical Contact**: High level of physical contact and tackling, demanding robust physical conditioning.\n",
    "- **Positional Specialization**: Each player has a specialized role that contributes differently to the team's strategy.\n",
    "\n",
    "### Volleyball\n",
    "\n",
    "- **Team Coordination**: Requires excellent team coordination, especially in setting up and executing attacks.\n",
    "- **Reflexes and Agility**: Players must have quick reflexes to respond to fast-moving plays and spikes.\n",
    "- **Spatial and Tactical Awareness**: Positioning and movement on the court are critical for both offense and defense.\n",
    "\n",
    "### Comparing to Tabletop Games\n",
    "\n",
    "- **Physicality**: Physical games require athletic skills, whereas tabletop games focus on mental strategy.\n",
    "- **Real-Time Dynamics**: Physical games often happen in real-time, demanding immediate responses, unlike turn-based tabletop games.\n",
    "- **Environmental Factors**: Factors like weather, field conditions, and physical fatigue significantly influence physical games.\n",
    "- **Team Interaction**: Physical games, especially team sports, involve complex interpersonal dynamics and coordination.\n",
    "- **Unpredictability**: The higher level of unpredictability in physical games arises from real-time dynamics and physical interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Strategy Games (RTS)\n",
    "\n",
    "Real-Time Strategy (RTS) games are a genre of video games particularly suited for AI research due to their complexity, real-time decision-making requirements, and dynamic environments. Here are some examples of RTS games and an explanation of their suitability for AI research:\n",
    "\n",
    "### Examples of RTS Games\n",
    "\n",
    "- **StarCraft and StarCraft II**\n",
    "   - **Complexity**: Features multiple factions with unique units and strategies.\n",
    "   - **Economy and Resource Management**: Players must efficiently gather resources and manage economies.\n",
    "   - **Fog of War**: Limited visibility of the map increases uncertainty and strategic depth.\n",
    "- **Age of Empires Series**\n",
    "   - **Historical Context**: Players build and manage civilizations through different historical eras.\n",
    "   - **Diverse Strategies**: Offers a variety of military, economic, and technological strategies.\n",
    "   - **Large Scale**: Involves managing large armies and settlements.\n",
    "- **Command & Conquer Series**\n",
    "   - **Asymmetrical Factions**: Different factions have distinct units and technologies.\n",
    "   - **Base Building and Defense**: Emphasizes base construction and defense along with offensive strategies.\n",
    "   - **Real-Time Tactics**: Requires quick tactical decisions in combat situations.\n",
    "- **Warcraft III**\n",
    "   - **Hero Units**: Introduces powerful hero units that can turn the tide of battles.\n",
    "   - **Micro and Macro Management**: Requires both individual unit control (micro) and overall strategy and resource management (macro).\n",
    "- **Company of Heroes**\n",
    "   - **Realistic Tactics and Cover System**: Focuses on realistic military tactics and the use of cover.\n",
    "   - **Resource Points Control**: Involves capturing specific points on the map to gain resources.\n",
    "\n",
    "### Suitability for AI Research\n",
    "\n",
    "- **Complex Decision-Making**: RTS games require complex, multi-layered decision-making, making them ideal for studying and developing sophisticated AI algorithms.\n",
    "- **Real-Time Analysis**: The real-time nature of these games challenges AI to analyze and react to situations swiftly and efficiently.\n",
    "- **Resource Management**: AI can be tested on its ability to optimally allocate and use resources, a common problem in many real-world scenarios.\n",
    "- **Strategy Formulation**: AI must formulate short-term and long-term strategies based on incomplete and dynamically changing information.\n",
    "- **Learning and Adaptation**: These games provide a rich environment for AI to learn and adapt to different strategies and opponents.\n",
    "- **Handling Uncertainty**: With elements like fog of war and unpredictable opponents, RTS games are excellent for developing AI that can handle uncertainty and incomplete information.\n",
    "- **Multi-Objective Optimization**: Balancing various objectives (e.g., economy, defense, attack) in an RTS game mirrors real-world scenarios where multiple objectives must be managed concurrently.\n",
    "\n",
    "The complexity, pace, and strategic depth of RTS games make them an excellent platform for advancing AI research, particularly in areas like decision-making, learning, and adaptation to complex and dynamic environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Game Theory\n",
    "\n",
    "- **Three Stances Towards Multi-Agent Environments**\n",
    "   - **Economy as a Game**: Treating the entire economy as a game where each agent is a player.\n",
    "   - **Agents as Part of the Environment**: Viewing other agents as part of the environment in which a single agent operates.\n",
    "   - **Modeling Adversarial Agents Explicitly**: Focusing on explicitly modeling the actions and strategies of adversarial agents. This is the main focus of this chapter.\n",
    "- **Modeling the Adversarial Agents Explicitly**\n",
    "   - **Strategic Planning**: Developing strategies based on the anticipated actions of opponents.\n",
    "   - **Predictive Modeling**: Anticipating the moves of the adversary to optimize one's own strategy.\n",
    "- **Concepts in Adversarial Search and Game Theory**\n",
    "   - **Pruning**: Techniques like alpha-beta pruning are used to efficiently search the game tree by eliminating branches that cannot possibly influence the final decision.\n",
    "   - **Evaluation Function**: A heuristic used to estimate the desirability of a game position when it is impractical to search until the end of the game.\n",
    "   - **Imperfect Information**: Games like poker, where players do not have complete information about the game state, requiring strategies that can handle uncertainty and probabilistic outcomes.\n",
    "- **Emphasis on Explicit Agent Modeling**\n",
    "   - **Deep Analysis of Opponents' Strategies**: Understanding and countering specific strategies used by opponents.\n",
    "   - **Adaptive Tactics**: Adjusting one’s own strategy in response to the observed behavior of adversaries.\n",
    "   - **Complex Decision Making**: Making decisions based on a mixture of strategic planning, predictive modeling, and real-time analysis of the game state.\n",
    "\n",
    "This subchapter emphasizes the importance of understanding and explicitly modeling adversarial agents in games, focusing on strategic decision-making, the use of evaluation functions, and dealing with imperfect information. These concepts are crucial in developing AI that can effectively navigate and succeed in multi-agent, competitive environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 - Two-Player Zero-Sum Games\n",
    "\n",
    "- **Definition and Characteristics**\n",
    "   - **Perfect Information**: These games are characterized by perfect information, meaning all players are fully aware of all game states.\n",
    "   - **Zero-Sum Nature**: In a zero-sum game, one player's gain is exactly balanced by the other player's loss.\n",
    "- **Basic Concepts: Move and Position**\n",
    "   - **Move**: An action taken by a player that transitions the game from one state to another.\n",
    "   - **Position**: The current state of the game, determined by the sequence of moves made up to that point.\n",
    "- **Game Structure**\n",
    "   - **Initial State**: The starting state of the game before any moves are made.\n",
    "   - **Transition Model**: Rules that determine how a player’s move changes the state of the game.\n",
    "   - **Terminal Test**: A test to determine when the game has ended (reaching a terminal state).\n",
    "   - **Terminal State**: A state where the game ends, with a win, loss, or draw.\n",
    "- **Representation of Game States**\n",
    "   - **State Space Graph**: Represents all possible states of the game and how one can transition from one state to another.\n",
    "   - **Search Tree**: A tree structure that represents the game from a single player's perspective, branching out from the current state based on potential moves.\n",
    "   - **Game Tree**: Expands on the search tree to include all possible moves by both players from the initial state to all possible terminal states.\n",
    "- **Differences Between State Space Graph, Search Tree, and Game Tree**\n",
    "   - **State Space Graph vs. Search Tree**: The state space graph is a more abstract representation showing all possible states and transitions, while the search tree focuses on the paths available from a current state.\n",
    "   - **Search Tree vs. Game Tree**: The search tree is from one player’s perspective, whereas the game tree includes all possible moves for all players, making it a complete representation of the game's possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Optimal Decisions in Games\n",
    "\n",
    "- **Concept of MAX and MIN in Games**\n",
    "   - **MAX**: Represents the player who is trying to maximize the score/outcome of the game.\n",
    "   - **MIN**: Represents the opposing player who is trying to minimize the score/outcome, or conversely, to maximize their own score in a zero-sum context.\n",
    "- **Minimax Search**\n",
    "   - **Definition**: A decision rule used for minimizing the possible loss for a worst-case scenario, assuming an opponent who makes the best moves against you.\n",
    "   - **Application**: Minimax search is used to determine the best move for a player by considering all possible responses of the opponent.\n",
    "- **The Concept of 'Ply'**\n",
    "   - **Definition**: A ply in game theory is a single turn taken by one of the players.\n",
    "   - **Relevance**: The depth of analysis in a game is often measured in plies (e.g., looking three plies ahead means considering your move, your opponent's move, and your subsequent move).\n",
    "- **Minimax Value**\n",
    "   - **Description**: The minimax value of a node in a game tree is the best score that can be guaranteed for the player at that node, assuming optimal play by both players.\n",
    "   - **Computation**: It is computed by recursively applying the minimax decision process through the game tree.\n",
    "- **Minimax Decision**\n",
    "   - **Definition**: The minimax decision is the decision at the root node that leads to the best possible outcome (maximized for MAX and minimized for MIN).\n",
    "   - **Determination**: This decision is determined by evaluating the minimax values of the root's child nodes.\n",
    "\n",
    "This subchapter lays the groundwork for understanding how optimal decisions are made in games, especially two-player zero-sum games with perfect information. The concepts of MAX and MIN, the use of the minimax search algorithm, and the understanding of game depth in terms of plies are crucial for developing strategies in such games. The minimax value and decision concepts are fundamental in determining the best possible outcomes in a game scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 The Minimax Search Algorithm\n",
    "\n",
    "- **Purpose of Minimax Algorithm**\n",
    "   - Designed for two-player zero-sum games.\n",
    "   - It computes the best move by considering all possible moves of the opponent.\n",
    "- **Working Principle**\n",
    "   - The algorithm searches through the game tree by expanding nodes.\n",
    "   - It assigns values to terminal states (win, lose, draw).\n",
    "   - These values are propagated back up the tree to determine the best move.\n",
    "- **Evaluation of Moves**\n",
    "   - The algorithm evaluates moves by assuming that the opponent plays optimally.\n",
    "   - For the maximizing player (MAX), it selects the move with the highest value.\n",
    "   - For the minimizing player (MIN), it selects the move with the lowest value.\n",
    "- **Depth of the Tree**\n",
    "   - The depth of analysis (number of plies) can be adjusted.\n",
    "   - Deeper trees provide more accurate decisions but require more computation.\n",
    "- **Pseudo-code for the Minimax Algorithm**\n",
    "\n",
    "```\n",
    "function MINIMAX(node, depth, isMaximizingPlayer):\n",
    "    if depth == 0 or node is a terminal node:\n",
    "        return the value of the node\n",
    "\n",
    "    if isMaximizingPlayer:\n",
    "        bestValue = -∞\n",
    "        for each child of node:\n",
    "            val = MINIMAX(child, depth - 1, false)\n",
    "            bestValue = max(bestValue, val)\n",
    "        return bestValue\n",
    "\n",
    "    else:\n",
    "        bestValue = +∞\n",
    "        for each child of node:\n",
    "            val = MINIMAX(child, depth - 1, true)\n",
    "            bestValue = min(bestValue, val)\n",
    "        return bestValue\n",
    "\n",
    "```\n",
    "- **Implementation Considerations**\n",
    "   - The algorithm is typically implemented recursively.\n",
    "   - It requires a well-defined evaluation function for non-terminal states when the depth limit is reached.\n",
    "- **Optimization Techniques**\n",
    "   - Techniques like alpha-beta pruning can be used to reduce the number of nodes evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Optimal Decisions in Multiplayer Games\n",
    "\n",
    "- **Vector of Values for Each Node**\n",
    "   - In multiplayer games, each node in the game tree represents a vector of values rather than a single value.\n",
    "   - This vector accounts for the payoffs or utilities for each player, reflecting the multi-dimensional nature of the game's outcomes.\n",
    "- **Complexity in Multiplayer Games**\n",
    "   - Multiplayer games are more complex than two-player games due to the increased number of possible interactions and outcomes.\n",
    "   - The strategy involves not only competing against multiple players but also potentially forming alliances and collaborations.\n",
    "- **Concepts of Alliances and Collaboration**\n",
    "   - **Alliances**: Players may form temporary alliances to achieve mutual goals, although these alliances can shift or dissolve as the game progresses.\n",
    "   - **Collaboration**: Players might collaborate for mutual benefit, influencing the game dynamics and strategic decisions.\n",
    "   - **Impact on Strategy**: The possibility of alliances and collaborations adds layers of strategic depth, as players must consider not only individual strategies but also group dynamics and potential betrayals.\n",
    "- **Decision-Making in Multiplayer Context**\n",
    "   - Decision-making becomes more complex, as each move affects multiple players differently.\n",
    "   - Strategies must account for the actions and potential responses of all players, not just a single adversary.\n",
    "- **Evaluation of Game States**\n",
    "   - Evaluating game states involves assessing the implications for all players, not just assessing a win/lose outcome for a single player.\n",
    "   - The utility of a state from a player's perspective depends on the utilities for all players, reflecting the interconnected nature of decisions in multiplayer scenarios.\n",
    "\n",
    "This section highlights the intricacies of decision-making in multiplayer games, emphasizing the need to consider a broader range of outcomes and interactions compared to two-player games. The concept of a vector of values for each node and the dynamics of alliances and collaboration significantly impact the strategies and evaluation methods in multiplayer game settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Alpha–Beta Pruning\n",
    "\n",
    "- **Key Idea of Alpha–Beta Pruning**\n",
    "   - **Efficiency Improvement**: Alpha-beta pruning is a technique used to improve the efficiency of the minimax algorithm. It reduces the number of nodes that are evaluated in the search tree, without affecting the final decision.\n",
    "   - **Pruning Redundant Nodes**: The method involves skipping the evaluation of certain branches of the tree that cannot possibly influence the final decision. This is done by maintaining two values, alpha and beta, which represent the minimum score that the maximizing player is assured of (alpha) and the maximum score that the minimizing player is assured of (beta).\n",
    "- **Alpha and Beta Values**\n",
    "   - **Alpha (α)**: The best value that the maximizing player can guarantee at that level or above.\n",
    "   - **Beta (β)**: The best value that the minimizing player can guarantee at that level or above.\n",
    "- **Pruning Condition**\n",
    "   - When the alpha value of a node is greater than or equal to the beta value of its ancestor, further exploration of that node is unnecessary (i.e., it can be pruned).\n",
    "- **Effectiveness**\n",
    "   - **Depth of Search**: Alpha-beta pruning allows for deeper searches in the game tree within the same time constraints, as it significantly cuts down the number of nodes to be evaluated.\n",
    "   - **Optimal Decision Retention**: Despite pruning parts of the tree, the algorithm still returns the same decision as it would have without pruning.\n",
    "- **Application**\n",
    "   - Commonly used in various games, especially in chess and other complex strategy games, to enhance the performance of AI players.\n",
    "\n",
    "Alpha-beta pruning is a critical optimization technique in game playing AI. By intelligently eliminating unnecessary parts of the search tree, it enables more efficient computation without compromising the accuracy of the decision-making process. This method is particularly valuable in games with large search trees, where exhaustive exploration is computationally impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Move Ordering\n",
    "\n",
    "- **Effect on Alpha-Beta Pruning Effectiveness**\n",
    "   - Move ordering significantly affects the efficiency of alpha-beta pruning. Good move ordering can greatly increase the number of prunings, thereby reducing the search space and increasing the efficiency of the search.\n",
    "- **Iterative Deepening**\n",
    "   - This is a strategy where the search is conducted repeatedly, increasing the depth limit with each iteration.\n",
    "   - It ensures that the best moves from shallower searches are tried first in deeper searches, potentially improving move ordering in subsequent iterations.\n",
    "- **Killer Move Heuristic**\n",
    "   - A \"killer move\" is a move that has caused a cutoff in another branch of the search tree at the same depth.\n",
    "   - These moves are given priority in the search order as they are likely to be strong moves.\n",
    "- **Transpositions and Transposition Table**\n",
    "   - A transposition occurs when two different sequences of moves lead to the same game position.\n",
    "   - A transposition table is used to store the evaluations of these positions, so the game doesn't need to re-evaluate them, improving efficiency.\n",
    "- **Claude Shannon’s Type A and Type B Strategies**\n",
    "   - **Type A Strategy**: Focuses on examining as many positions as possible and uses a relatively simple evaluation function. This is more brute-force in nature.\n",
    "   - **Type B Strategy**: Emphasizes the use of more sophisticated evaluation functions and examines fewer positions. This approach relies more on the strategic depth of the evaluation function.\n",
    "- **Importance of Move Ordering**\n",
    "   - Effective move ordering can lead to significant improvements in search efficiency, allowing deeper searches within the same computational constraints.\n",
    "   - It is an essential aspect of optimizing search strategies in game-playing AI, especially in conjunction with alpha-beta pruning.\n",
    "\n",
    "Move ordering in the context of alpha-beta pruning is a crucial element in game-playing AI. By prioritizing certain moves, especially those that have proven effective in similar situations (like killer moves) or avoiding redundant evaluations (as with transposition tables), the AI can search more efficiently and effectively. The balance between breadth (Type A) and depth (Type B) strategies as described by Shannon also plays a key role in determining the overall approach to game-playing AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Heuristic Alpha–Beta Tree Search\n",
    "\n",
    "- **Evaluation Function**\n",
    "   - **Purpose**: Since it's impractical to search the entire game tree in most games, the evaluation function is used to estimate the desirability of a game position.\n",
    "   - **Implementation**: It assigns a numerical value to non-terminal states, helping the algorithm decide which moves are the most promising.\n",
    "   - **Design**: A good evaluation function captures important aspects of the game position (like material count in chess, control of the center, pawn structure, etc.).\n",
    "- **Cutoff Test**\n",
    "   - **Definition**: The cutoff test determines when to apply the evaluation function instead of searching deeper. It acts as a stopping condition for the search.\n",
    "   - **Criteria**: Typically based on the depth of the search (depth limit) or other game-specific considerations (like time constraints or a specific state of the game board).\n",
    "- **Heuristic Alpha-Beta Pruning**\n",
    "   - **Combination with Heuristics**: The alpha-beta pruning technique is often combined with heuristics to enhance its effectiveness.\n",
    "   - **Role of Heuristics**: Heuristics guide the search process, influencing which parts of the tree are pruned and the order in which nodes are explored.\n",
    "   - **Improved Efficiency**: By applying heuristics, the algorithm can prune more branches and reduce the search space, leading to faster decision-making.\n",
    "- **Balancing Accuracy and Efficiency**\n",
    "   - **Depth vs. Breadth**: There is a trade-off between the depth of the search and the breadth. Heuristics help in balancing this by focusing the search on the most promising areas.\n",
    "   - **Complexity of the Evaluation Function**: More complex evaluation functions may provide more accurate assessments but are computationally expensive.\n",
    "- **Practical Considerations**\n",
    "   - **Time Constraints**: In real-world applications, time constraints often dictate the depth of the search, making efficient heuristics crucial.\n",
    "   - **Dynamic Adjustments**: The algorithm may dynamically adjust the depth of the search or the use of heuristics based on the state of the game.\n",
    "\n",
    "In this section, the focus is on the practical application of alpha-beta pruning in real game scenarios, where it's not feasible to search the entire game tree. The evaluation function and the cutoff test are central to this approach, providing a balance between exploring enough of the game tree to make a good decision and doing so within a reasonable amount of time and computational resources. The use of heuristics in this context is key to enhancing the performance and effectiveness of game-playing AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Evaluation Functions\n",
    "\n",
    "- **Features of the State**\n",
    "   - **Definition**: Features of a game state are specific attributes that can be quantitatively assessed to evaluate the state.\n",
    "   - **Examples**: In chess, these could include material balance, control of the center, pawn structure, king safety, etc.\n",
    "- **Material Value in Chess**\n",
    "   - **Concept**: Assigns numerical values to pieces based on their relative strength and importance.\n",
    "   - **Example**: Pawns might be valued at 1, knights and bishops at 3, rooks at 5, and the queen at 9. The king is invaluable as losing it means losing the game.\n",
    "- **Expected Value**\n",
    "   - **Definition**: Represents the average outcome, considering all possible future sequences of moves, each weighted by its probability.\n",
    "   - **Usage**: Useful in games with elements of chance, like backgammon or card games.\n",
    "- **Weighted Linear Function**\n",
    "   - **Function**: Combines various features of a state into a single numerical value.\n",
    "   - **Form**: It's typically a weighted sum of feature values, where each feature is assigned a weight reflecting its relative importance.\n",
    "- **Quiescence**\n",
    "   - **Definition**: Refers to a state of the game where there are no immediate drastic changes expected (like captures or checks in chess).\n",
    "   - **Importance**: Avoids evaluating a position that appears calm but is actually unstable.\n",
    "- **Quiescence Search**\n",
    "   - **Purpose**: To avoid the horizon effect, it continues to search beyond the basic depth limit in positions that are not quiescent.\n",
    "   - **Implementation**: Typically looks for moves that could result in significant material changes, like captures or major threats.\n",
    "- **Horizon Effect**\n",
    "   - **Definition**: A limitation where the algorithm cannot see beyond a certain depth, potentially missing critical developments that occur just beyond this 'horizon'.\n",
    "   - **Problem**: Can lead to poor evaluations if significant changes are just outside the search depth.\n",
    "- **Singular Extensions Strategy**\n",
    "   - **Purpose**: To mitigate the horizon effect.\n",
    "   - **Method**: Extends the depth of search selectively for moves that seem to be particularly consequential, rather than uniformly increasing the search depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Cutoff Tests\n",
    "\n",
    "The next step is to modify ALPHA-BETA-SEARCH so that it will call the heuristic EVAL\n",
    "function when it is appropriate to cut off the search.\n",
    "\n",
    "- **Definition**\n",
    "   - **Purpose**: The cutoff test determines when to apply the evaluation function instead of searching deeper. It acts as a stopping condition for the search.\n",
    "   - **Criteria**: Typically based on the depth of the search (depth limit) or other game-specific considerations (like time constraints or a specific state of the game board).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Forward Pruning\n",
    "\n",
    "- **Concept of Forward Pruning**\n",
    "   - **Definition**: Forward pruning refers to the practice of pruning moves from the search tree early on (forward in the search), based on the assumption that they appear to be poor choices.\n",
    "   - **Risk**: This approach carries the risk of missing potentially good moves that only reveal their value deeper in the search tree.\n",
    "- **Beam Search**\n",
    "   - **Explanation**: Beam search is a type of forward pruning. It limits the number of moves (branches) explored at each level of the tree, focusing only on a predetermined number of best moves (the \"beam\").\n",
    "   - **Application**: Often used in games where the branching factor is very high, making it impractical to explore all possible moves.\n",
    "- **PROBCUT Algorithm (Buro 1995)**\n",
    "   - **Overview**: PROBCUT is an algorithm that applies probabilistic pruning based on the evaluation of moves.\n",
    "   - **Functionality**: It uses statistical models to predict the likely outcome of a move, pruning those moves that fall below a certain probability threshold of being beneficial.\n",
    "- **Late Move Reduction**\n",
    "   - **Concept**: This technique reduces the depth of search for moves considered later in the move generation process, based on the idea that early moves are generally better.\n",
    "   - **Implementation**: Later moves are searched less deeply on the assumption that if they were strong moves, they would have been considered earlier.\n",
    "\n",
    "[Stockfish](https://stockfishchess.org/) is a free and open-source chess engine, developed by Tord Romstad, Marco Costalba, and Joona Kiiski. It is consistently ranked among the top chess engines in the world, competing with the likes of Komodo and Houdini. It is also the engine behind the popular chess website [Lichess](https://lichess.org/) among others.\n",
    "\n",
    "![Stockfish](https://stockfishchess.org/images/logo/icon_512x512@2x.png)\n",
    "\n",
    "- **STOCKFISH Chess Program**\n",
    "   - **Hybrid Approach**: STOCKFISH uses a hybrid approach to move pruning, combining several techniques including forward pruning.\n",
    "   - **Strength**: STOCKFISH is known for its exceptional strength, partly attributed to its sophisticated and efficient pruning strategies.\n",
    "   - **Adaptation**: The program dynamically adjusts its search strategies based on the specifics of the position and the depth of the search.\n",
    "\n",
    "In summary, forward pruning in game-playing AI involves making early decisions to discard certain moves based on their perceived lack of promise. While this can greatly enhance efficiency by reducing the search space, it carries the inherent risk of overlooking potentially good moves. Techniques like beam search, PROBCUT, and late move reductions are implemented to mitigate this risk. Programs like STOCKFISH demonstrate the effectiveness of these techniques, particularly when they are part of a dynamic and multifaceted search strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 25 - Computer Vision\n",
    "\n",
    "*In which we connect the computer to the raw, unwashed world through the eyes of a camera.* - Peter Norvig,Stuart Russell in Artificial Intelligence: A Modern Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Importance of Vision**  \n",
    "- **Biological Costs and Benefits** : Eyes occupy significant space, consume energy, and are delicate, but their ability to provide critical information justifies their biological cost. \n",
    "- **Functional Advantages** : Vision enables agents to predict future interactions with their environment, such as obstacles to avoid, determining when to engage or retreat from threats, assessing terrain, and judging distances to objects. \n",
    "- **Information Processing** : This chapter focuses on extracting valuable information from the vast data provided by biological eyes and cameras, highlighting the translation of visual data into actionable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25.1 Introduction**  \n",
    "- **Vision as a Perceptual Channel** : Vision is described as a channel through which stimuli are received and interpreted to form a representation of the world. Most vision relies on passive sensing, where no signal emission is necessary, unlike active sensing used by some animals and robots. \n",
    "- **Active vs. Passive Sensing** : Active sensing involves emitting signals (like light, sound, or radar) and detecting their reflections. Examples include bats and dolphins using ultrasound and some robots using radar. \n",
    "- **Feature Extraction** : Vision processes involve extracting features from images, which are simple computations yielding essential information. This can directly influence actions, such as an animal's steering response based on time-to-contact estimates with obstacles. \n",
    "- **Model-Based Vision Approaches** : These include object models (from precise CAD designs to general object properties) and rendering models that describe how visual stimuli are produced. Despite sophisticated models, visual stimuli often remain ambiguous (e.g., distinguishing a white object under low light from a black object under intense light). \n",
    "- **Handling Ambiguities** : Ambiguities in vision are managed by prioritizing likely interpretations or disregarding insignificant differences. For example, distant objects might be indistinct but do not affect immediate actions. \n",
    "- **Core Problems in Computer Vision** : \n",
    "- **Reconstruction** : Building a model of the world from images, which can involve creating geometric models or mapping surface textures. \n",
    "- **Recognition** : Differentiating among objects based on visual and other data, which can include identifying objects, their states, and their characteristics. \n",
    "- **Research and Development** : The last thirty years have seen significant advances in tools and methods for solving vision-related problems, driven by deeper understanding of image formation processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

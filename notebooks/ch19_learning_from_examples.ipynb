{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 19 - Learning From Examples\n",
    "\n",
    "*In which we describe agents that can improve their behavior through diligent study of past\n",
    "experiences and predictions about the future.* - [Artificial Intelligence: A Modern Approach](http://aima.cs.berkeley.edu/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- **Learning and machine learning** : An agent is considered to be learning if its performance on tasks improves over time after making observations about the world. This encompasses a broad spectrum of learning, from simple tasks to complex theories. Machine learning specifically refers to this process when the agent is a computer. \n",
    "- **Need for machine learning** : There are two primary reasons for utilizing machine learning: \n",
    "- **Anticipation of future situations** : Designers cannot foresee every possible scenario an agent might encounter, such as a robot navigating unknown mazes or a system predicting stock market trends during economic shifts from boom to bust. \n",
    "- **Complexity of programming certain tasks** : For some tasks, like facial recognition, even skilled programmers may not know how to explicitly program a solution due to the subconscious nature of these tasks in humans. Machine learning algorithms offer a viable approach. \n",
    "- **Content overview** : The chapter discusses various model classes including decision trees, linear models, nonparametric models like nearest neighbors, and ensemble models such as random forests. It also provides practical advice on building machine learning systems and discusses the theory underlying machine learning, covering a comprehensive spectrum from practical implementations to theoretical foundations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Machine Learning\n",
    "\n",
    "Machine learning is a field of artificial intelligence (AI) focused on building systems that learn from data to make decisions or predictions. Here are the basics:\n",
    "### 1. **What is Machine Learning?** \n",
    "\n",
    "Machine learning involves algorithms and statistical models that computer systems use to perform tasks without using explicit instructions. Instead, they rely on patterns and inference derived from data.\n",
    "### 2. **Types of Machine Learning**  \n",
    "- **Supervised Learning:**  The model is trained on a labeled dataset, which means that each training example is paired with an output label. The model makes predictions or decisions based on input data. \n",
    "- **Unsupervised Learning:**  The model is trained on data without labeled responses. It tries to find patterns and relationships in the data by itself. \n",
    "- **Semi-supervised Learning:**  A mix of supervised and unsupervised learning. The model is trained on a partially labeled dataset. \n",
    "- **Reinforcement Learning:**  The model learns to make decisions by performing actions in an environment to achieve some goals. It learns from the consequences of its actions, rather than from being taught explicitly.\n",
    "### 3. **Key Concepts**  \n",
    "- **Dataset:**  A collection of data that the machine learning model learns from. It's usually divided into training and testing sets. \n",
    "- **Features:**  The input variables of the dataset. They are the characteristics based on which the model makes predictions. \n",
    "- **Labels:**  In supervised learning, these are the output variables or the predictions the model aims to make. \n",
    "- **Model:**  A mathematical representation of the real-world process. It's trained using algorithms on a dataset. \n",
    "- **Training:**  The process of teaching a machine learning model to make predictions or decisions based on data. \n",
    "- **Inference:**  Using a trained model to make predictions on new, unseen data.\n",
    "### 4. **Common Algorithms**  \n",
    "- **Linear Regression:**  Used for predicting a continuous value. \n",
    "- **Logistic Regression:**  Used for binary classification tasks. \n",
    "- **Decision Trees:**  Can be used for classification or regression tasks. They split the data based on certain conditions. \n",
    "- **Neural Networks:**  Complex models that can capture non-linear relationships in data. They're particularly useful for image and speech recognition.\n",
    "### 5. **Evaluation Metrics** \n",
    "\n",
    "Different tasks use different metrics for evaluating the performance of machine learning models. Common metrics include accuracy, precision, recall, F1 score, and mean squared error.\n",
    "### 6. **Overfitting and Underfitting**  \n",
    "- **Overfitting:**  The model performs well on the training data but poorly on new, unseen data. It has essentially memorized the training dataset, including the noise and outliers. \n",
    "- **Underfitting:**  The model is too simple to capture the underlying structure of the data, leading to poor performance on both the training and testing sets.\n",
    "### 7. **Improving a Model**  \n",
    "- **Feature Engineering:**  Creating new features or modifying existing ones to improve model performance. \n",
    "- **Regularization:**  Techniques to prevent overfitting by penalizing complex models. \n",
    "- **Hyperparameter Tuning:**  Adjusting the settings of the machine learning algorithm to optimize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1 Forms of Learning**  \n",
    "- **Learning components in agent programs** : Machine learning can enhance any part of an agent program, influenced by which component is being improved, the agent's prior knowledge, and the available data and feedback. \n",
    "- **Agent design components** :\n",
    "1. Direct mapping from state conditions to actions.\n",
    "2. Inferring world properties from percept sequences.\n",
    "3. Understanding how the world evolves and the outcomes of actions.\n",
    "4. Utility information for determining the desirability of world states.\n",
    "5. Action-value information for assessing the desirability of actions.\n",
    "6. Goals that outline the most desirable states.\n",
    "7. A problem generator, critic, and learning element for system improvement. \n",
    "- **Examples of learning in action** : For instance, a self-driving car learning from a human driver might learn when to brake based on observed conditions (1), recognize objects like buses from camera images (2), learn the effects of its actions by experimentation (3), and adjust its utility function based on passenger feedback (4). \n",
    "- **Machine learning in software engineering** : Machine learning technologies have become integral to software development, significantly enhancing efficiency and effectiveness in various applications, from analyzing astronomical images to optimizing data center cooling systems. \n",
    "- **Agent models and learning algorithms** : The chapter discusses learning algorithms for different agent models, including atomic, factored, and relational models, based on logic or probability. \n",
    "- **Assumptions and induction** : The chapter assumes minimal prior knowledge for the agent, focusing on learning from scratch and, briefly, on transfer learning, where knowledge from one domain is applied to a new one. It emphasizes induction, the process of deriving general rules from specific observations, which differs from deduction in its potential for incorrect conclusions. \n",
    "- **Learning problems and inputs** : It covers learning problems where inputs are factored representations or vectors of attribute values, distinguishing between classification (discrete outputs) and regression (numerical outputs) learning problems. \n",
    "- **Types of learning based on feedback** : \n",
    "- **Supervised learning** : Learning a function from input-output pairs (labels), where the environment acts as a teacher. \n",
    "- **Unsupervised learning** : Learning patterns in the input without explicit feedback, such as clustering. \n",
    "- **Reinforcement learning** : Learning from a series of rewards and punishments to modify actions towards achieving more rewards in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch19_learning_from_examples/f19_1_hypothesis.jpg?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2 Supervised Learning**  \n",
    "- **Task of supervised learning** : The goal is to discover a function hhh that approximates an unknown true function fff, given a training set of example input-output pairs (x1,y1),(x2,y2),…,(xN,yN)(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)(x1​,y1​),(x2​,y2​),…,(xN​,yN​). Here, hhh is a hypothesis about the world, selected from a hypothesis space HHH of possible functions. \n",
    "- **Hypothesis space (H)** : Can vary greatly, from polynomials of a certain degree to sets of functions like Javascript functions or 3-SAT Boolean logic formulas. The choice of HHH depends on prior knowledge or exploratory data analysis of the training data. \n",
    "- **Selecting a good hypothesis** : Involves choosing a hypothesis that is consistent with the training data. For continuous outputs, this means seeking a best-fit function. The ultimate measure of a hypothesis is its ability to generalize to unseen data, evaluated using a test set. \n",
    "- **Bias and variance** : \n",
    "- **Bias**  refers to the predictive hypothesis's tendency to consistently deviate from the expected value across different training sets. High bias can lead to underfitting, where the hypothesis fails to capture the data's pattern. \n",
    "- **Variance**  refers to the change in the hypothesis with fluctuations in the training data. High variance can result in overfitting, where the hypothesis is too tailored to the training data and performs poorly on unseen data. \n",
    "- **Bias-variance tradeoff** : Navigating between complex, low-bias hypotheses that fit training data well and simpler, low-variance hypotheses that may generalize better. The goal is to find a hypothesis that matches the data adequately while maintaining simplicity, guided by principles like Ockham's razor. \n",
    "- **Defining simplicity and model fitness** : While simplicity is intuitively appealing, the complexity of models like deep neural networks, which can generalize well despite having billions of parameters, shows that simplicity alone is not always the best criterion. Appropriateness to the data and task is crucial. \n",
    "- **Choosing the best hypothesis** : Depends on the data's nature and the task. Supervised learning can select the most probable hypothesis given the data, using Bayesian principles to balance the likelihood of the data under a hypothesis with the prior probability of the hypothesis. \n",
    "- **Expressiveness vs. computational complexity** : There's a tradeoff between the hypothesis space's expressiveness and the computational effort required to find a good hypothesis. While expressive hypothesis spaces allow for fitting simple models to complex data, they can increase computational complexity and the difficulty of using the learned hypothesis h(x)h(x)h(x). \n",
    "- **Focus on simpler representations** : Historically, learning has concentrated on simpler representations due to computational efficiency and the practicality of using the learned models. However, interest has grown in more complex models like those in deep learning, where computations remain bounded in time with appropriate hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ValRCS/RBS_PBM773_Introduction_to_AI/main/img/ch19_learning_from_examples/DALL%C2%B7E%202024-03-13%2021.54.13%20-%20A%20detailed%20illustration%20depicting%20a%20supervised%20learning%20problem%20scenario%20involving%20a%20couple%20facing%20the%20decision%20of%20waiting%20for%20a%20table%20at%20a%20busy%20resta.webp\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.2.1 Example problem: Restaurant waiting**  \n",
    "- **Problem description** : This supervised learning problem involves deciding whether to wait for a table at a restaurant, based on various factors. The output (yyy) is a Boolean variable named WillWait, indicating whether the decision is to wait. \n",
    "- **Input attributes (x)** : Consists of a vector of ten discrete attributes that might influence the waiting decision: \n",
    "1. **Alternate** : Availability of a suitable alternative restaurant nearby. \n",
    "2. **Bar** : Presence of a comfortable bar area to wait in. \n",
    "3. **Fri/Sat** : Indicator for Fridays and Saturdays. \n",
    "4. **Hungry** : Immediate hunger state. \n",
    "5. **Patrons** : Restaurant's current occupancy level (None, Some, Full). \n",
    "6. **Price** : Price range of the restaurant ($, $$, $$$). \n",
    "7. **Raining** : Weather condition outside. \n",
    "8. **Reservation** : Whether a reservation has been made. \n",
    "9. **Type** : Type of restaurant (French, Italian, Thai, Burger). \n",
    "10. **WaitEstimate** : Estimated waiting time given by the host (0–10 mins, 10–30 mins, 30–60 mins, >60 mins). \n",
    "- **Data sparsity** : The challenge highlighted by this example is the sparse nature of the data. Despite having 9,216 possible combinations of input attributes, only 12 instances are provided for learning. This illustrates the problem of induction in machine learning, where the goal is to make the best guess about the output for the vast majority of possible inputs based on very limited examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch19_learning_from_examples/f19_2_table_data.jpg?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.3 Learning Decision Trees**  \n",
    "- **Function representation** : A decision tree maps a vector of attribute values to a single output value, facilitating decision-making through a series of tests. It starts at the root and progresses along branches based on test outcomes, ending at a leaf that provides the decision. \n",
    "- **Structure of a decision tree** : \n",
    "- **Internal nodes** : Each corresponds to a test on one of the input attributes. \n",
    "- **Branches** : Labeled with possible attribute values, indicating different paths to follow based on the test outcome. \n",
    "- **Leaf nodes** : Specify the decision or output value to return. \n",
    "- **Discrete and continuous values** : Although decision trees can handle both discrete and continuous input and output values, the focus here is on discrete inputs and Boolean classification outputs (true or false). \n",
    "- **Boolean classification** : In this context, outputs are classified as either positive (true) or negative (false), with xjx_jxj​ representing the input vector for the jthj^{th}jth example, yjy_jyj​ the output, and xj,ix_{j,i}xj,i​ denoting the ithi^{th}ith attribute of the jthj^{th}jth example. \n",
    "- **Example application** : The decision tree for deciding whether to wait for a table at a restaurant (the example problem described earlier) illustrates how a decision is reached by evaluating the attributes. For instance, if \"Patrons = Full\" and \"WaitEstimate = 0–10\", the example would be classified as positive, indicating a decision to wait for a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.3.1 Expressiveness of Decision Trees**  \n",
    "- **Logical equivalence** : Boolean decision trees can be represented as logical statements in disjunctive normal form (DNF), where the output is equivalent to a disjunction of paths, each path being a conjunction of attribute-value tests. This allows any function expressible in propositional logic to be represented as a decision tree. \n",
    "- **Decision tree as a logical statement** : The structure of a decision tree can be seen as a series of logical decisions leading to an outcome, effectively mimicking a \"How To\" guide for various decisions, making them intuitively appealing and easy to understand in many cases. \n",
    "- **Limitations on expressiveness** :\n",
    "- Certain functions, such as the majority function (which requires more than half of the inputs to be true for a true output) and the parity function (which requires an even number of true inputs for a true output), demand exponentially large decision trees for accurate representation. \n",
    "- For real-valued attributes, representing functions like y>A1+A2y > A1 + A2y>A1+A2, which have a diagonal decision boundary, is challenging with decision trees due to their inherent structure of dividing the space into rectangular, axis-aligned segments. Approximating a diagonal line would require an impractical number of rectangular segments. \n",
    "- **Inefficiency for some functions** : Although decision trees are efficient and effective for certain types of functions, they are not universally optimal. Their structure makes them unsuitable for functions that require complex, non-linear decision boundaries or that depend on a balance of numerous attributes. \n",
    "- **Representation limitations** : No singular representation can efficiently encapsulate all types of functions due to the vast number of potential functions, especially as the number of attributes increases. For instance, with just 20 Boolean attributes, the total number of possible Boolean functions exceeds 10 million, highlighting the impracticality of representing all possible functions within a constrained bit-length representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch19_learning_from_examples/f19_3_decision_tree.jpg?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.3.2 Learning Decision Trees from Examples**  \n",
    "- **Goal** : To create a decision tree that is both consistent with given examples and as small as possible. Finding the guaranteed smallest consistent tree is intractable, but using heuristics, we can approach an efficient solution. \n",
    "- **LEARN-DECISION-TREE algorithm** :\n",
    "- Employs a greedy divide-and-conquer strategy, prioritizing tests on the \"most important attribute\" first.\n",
    "- \"Most important attribute\" refers to the attribute that significantly affects classification, aiming to keep the tree shallow with short paths.\n",
    "- Recursive approach is taken to handle smaller subproblems created by the outcomes of the initial tests. \n",
    "- **Attribute importance example** : \n",
    "- **Poor attribute** : Type, as it results in outcomes with an equal number of positive and negative examples. \n",
    "- **Good attribute** : Patrons, as certain values (None or Some) directly lead to definitive answers (No and Yes), making it an effective first choice for splitting. \n",
    "- **Handling different cases** :\n",
    "1. All examples are positive or all are negative: Directly return Yes or No.\n",
    "2. Mixed positive and negative examples: Choose another attribute to split them further.\n",
    "3. No examples left: Use the most common output from the parent node's example set.\n",
    "4. No attributes left but mixed examples: Return the most common output among remaining examples, indicating potential data noise or unobserved relevant attributes. \n",
    "- **Algorithm characteristics** :\n",
    "- The algorithm's tree consists of attribute tests (internal nodes), attribute values (branches), and output values (leaf nodes), without explicitly including example data.\n",
    "- The IMPORTANCE function, detailed later, aids in selecting the best attribute to split on.\n",
    "- The resulting tree may differ significantly from an original or intuitive decision tree but is optimized based on given examples. \n",
    "- **Algorithm outcomes and patterns** :\n",
    "- May omit tests for attributes like Raining and Reservation if examples can be classified without them.\n",
    "- Can reveal previously unnoticed patterns, such as a preference for waiting for Thai food on weekends.\n",
    "- Potentially inaccurate in scenarios not covered by examples but can improve with more training data. \n",
    "- **Evaluating performance** :\n",
    "- A learning curve shows accuracy improvement as the training set size increases.\n",
    "- Repeated experiments with varying training and test set sizes demonstrate that accuracy generally grows with more data, validating the efficacy of the learning algorithm in adapting and optimizing based on available examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.3.3 Choosing Attribute Tests**  \n",
    "- **Attribute selection based on IMPORTANCE** : The decision tree learning algorithm selects attributes for testing based on their importance, measured by information gain, a concept derived from entropy in information theory. \n",
    "- **Entropy as a measure of uncertainty** :\n",
    "- Entropy quantifies the uncertainty or unpredictability of a random variable's value. Less uncertainty (or more information) means lower entropy.\n",
    "- Examples: A fair coin has 1 bit of entropy, a fair four-sided die has 2 bits, and an unfair coin that lands heads 99% of the time has entropy close to zero but positive (~0.08 bits). \n",
    "- **Entropy calculation** : For a random variable VVV with possible values vkv_kvk​ and their probabilities P(vk)P(v_k)P(vk​), entropy H(V)H(V)H(V) is defined as H(V)=−∑kP(vk)log⁡2P(vk)H(V) = -\\sum_k P(v_k) \\log_2 P(v_k)H(V)=−∑k​P(vk​)log2​P(vk​). \n",
    "- **Entropy of Boolean variables** : The entropy B(q)B(q)B(q) for a Boolean variable that is true with probability qqq is given by B(q)=−(qlog⁡2q+(1−q)log⁡2(1−q))B(q) = -(q\\log_2 q + (1-q)\\log_2 (1-q))B(q)=−(qlog2​q+(1−q)log2​(1−q)). \n",
    "- **Application to decision tree learning** : \n",
    "- The entropy of the output variable for a training set with ppp positive and nnn negative examples is H(Output)=B(pp+n)H(Output) = B\\left(\\frac{p}{p+n}\\right)H(Output)=B(p+np​). \n",
    "- An attribute test on attribute AAA reduces this entropy, with the reduction quantified as the information gain, Gain(A)Gain(A)Gain(A). \n",
    "- **Information gain and attribute testing** :\n",
    "- Testing an attribute divides the training set into subsets based on the attribute's values, each with its own proportion of positive and negative examples. \n",
    "- The expected entropy after testing an attribute AAA (Remainder(AAA)) considers the entropy in each subset, weighted by the subset's size relative to the whole set. \n",
    "- Information gain from testing AAA is the initial entropy minus the expected entropy after the test: Gain(A)=B(pp+n)−Remainder(A)Gain(A) = B\\left(\\frac{p}{p+n}\\right) - \\text{Remainder}(A)Gain(A)=B(p+np​)−Remainder(A). \n",
    "- **Choosing the best attribute** :\n",
    "- The attribute with the highest information gain is selected for testing because it most effectively reduces uncertainty about the output variable.\n",
    "- Example calculations confirm that the attribute \"Patrons\" has the highest information gain among considered attributes, making it the preferred choice for the root of the decision tree. This aligns with intuition that splitting on \"Patrons\" first effectively classifies examples with minimal entropy remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.3.4 Generalization and Overfitting**  \n",
    "- **Objective** : Learning algorithms aim not just to fit the training data but more crucially, to generalize well to unseen data. Overfitting is a risk, especially with complex models or a large number of attributes, where models may fit the training data too closely at the expense of generalization. \n",
    "- **Overfitting and hypothesis space** : The risk of overfitting increases with the complexity of the hypothesis space (e.g., decision trees with many nodes, high-degree polynomials) and decreases with more training data. Some model classes are more prone to overfitting than others. \n",
    "- **Decision tree pruning** : This technique helps prevent overfitting by simplifying the decision tree, removing nodes that test irrelevant attributes. Starting with a fully grown tree, the algorithm iteratively removes nodes that seem to capture noise rather than meaningful patterns in the data. \n",
    "- **Detecting irrelevant attributes** : An attribute is considered irrelevant if splitting on it does not significantly affect the classification, indicated by a low information gain. Statistical significance tests can quantify the likelihood that observed data patterns occurred by chance under the null hypothesis of no underlying pattern. \n",
    "- **Statistical significance tests** : These tests compare observed deviations in attribute effectiveness from what would be expected by chance. If the deviation is unlikely to arise by random sampling (usually below a 5% probability), the pattern is deemed significant. Otherwise, the attribute may be considered for pruning. \n",
    "- **χ2 pruning** : Uses the χ2 (chi-squared) distribution to evaluate whether the deviation observed by splitting on an attribute is significant. Attributes that do not significantly improve prediction accuracy (according to the χ2 statistic) are pruned to prevent overfitting. \n",
    "- **Tolerance to noise** : Pruning makes decision trees more robust to noise by reducing the impact of incorrect data on the model's performance. Pruned trees are often smaller, simpler, easier to understand, and execute more efficiently. \n",
    "- **Early stopping vs. pruning** : While it might seem efficient to stop growing the tree early when no clear best attribute exists (early stopping), this approach can miss patterns that emerge from combinations of attributes. Pruning after full growth allows for the detection of complex patterns, such as those in the XOR function, that early stopping might overlook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.3.5 Broadening the Applicability of Decision Trees**  \n",
    "- **Handling missing data** :\n",
    "- Missing attribute values are common due to various reasons (unrecorded data, high cost, etc.). Strategies are needed both for classifying examples with missing attributes and adjusting the information-gain calculation when attribute values are missing. \n",
    "- **Continuous and multivalued input attributes** : \n",
    "- **Continuous attributes** : Using a split point test (inequality test) is effective for continuous attributes like Height or Weight, allowing the tree to handle attributes with a range of values efficiently by finding the most informative split point. \n",
    "- **Multivalued attributes without a meaningful order** : For attributes with many values but no order (e.g., Zipcode), using the information gain ratio or equality tests (e.g., Zipcode=10002) can avoid excessive splitting into single-example subtrees. \n",
    "- **Continuous-valued output attribute** :\n",
    "- To predict numerical outputs (e.g., apartment prices), regression trees are used, where each leaf contains a linear function of numerical attributes instead of a single value. The system decides when to switch from splitting to applying linear regression, covering both classification and regression under the CART (Classification And Regression Trees) methodology. \n",
    "- **Importance for real-world applications** :\n",
    "- Handling continuous variables is crucial due to the prevalence of numerical data in physical and financial processes. Decision trees are widely used in industry and commerce for their simplicity, scalability, and versatility. \n",
    "- **Advantages** :\n",
    "- Decision trees are easy to understand and can scale to large datasets. They are versatile, capable of handling discrete and continuous inputs, and can be used for both classification and regression tasks. \n",
    "- **Challenges** :\n",
    "- Despite their advantages, decision trees may suffer from suboptimal accuracy due to their greedy search algorithm. Deep trees can make prediction time-consuming, and trees can be unstable, with small changes in data potentially leading to significant changes in the structure. \n",
    "- **Improvements and alternatives** :\n",
    "- The random forest model is presented as a solution to some of these issues, particularly the instability and accuracy challenges of decision trees, by using ensemble learning to enhance performance and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.4 Model Selection and Optimization**  \n",
    "- **Objective** : The aim in machine learning is to find a hypothesis that will most accurately predict future examples. This requires assuming that future examples will resemble past ones (stationarity assumption) and that examples are independent and identically distributed (i.i.d.). \n",
    "- **Defining optimal fit** : Optimal fit is initially defined as the hypothesis that minimizes the error rate, which is the proportion of incorrect predictions (h(x)≠yh(x) \\neq yh(x)=y) for examples. \n",
    "- **Error rate estimation** : The error rate of a hypothesis is estimated using a test set, distinct from the training set used to develop the hypothesis. This separation ensures unbiased evaluation. \n",
    "- **Hyperparameters and model comparison** : Adjusting model \"knobs\" or hyperparameters, such as decision tree pruning thresholds, involves comparing multiple hypotheses. It's critical that the test set remains untouched during this process to prevent biased evaluation. \n",
    "- **Data set division** : \n",
    "1. **Training set** : Used to train various candidate models. \n",
    "2. **Validation set (dev set)** : For evaluating candidates and selecting the best model. \n",
    "3. **Test set** : For final evaluation of the chosen model to ensure the evaluation is unbiased. \n",
    "- **Handling limited data** : When data is scarce, k-fold cross-validation can maximize data utility, allowing each example to serve as both training and validation data across different rounds. Popular values for kkk are 5 and 10, balancing statistical reliability and computational cost. \n",
    "- **Model selection and optimization** : Model selection involves choosing a suitable hypothesis space (e.g., polynomials vs. decision trees), while optimization involves finding the best hypothesis within that space. This process can be both qualitative, based on problem-specific knowledge, and quantitative, based on performance on validation data. \n",
    "- **Underfitting vs. overfitting** : A linear function might underfit by failing to capture the complexity of the data, while a high-degree polynomial might overfit by capturing noise rather than the underlying trend. The challenge lies in balancing these extremes to select and optimize a model that generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.4.1 Model Selection**  \n",
    "- **Model Selection Algorithm** : It iteratively tests models of increasing complexity, determined by a hyperparameter (e.g., number of nodes in decision trees or degree in polynomials), starting with a simple model likely to underfit. The algorithm selects the model with the lowest average error on validation data. \n",
    "- **Training vs. Validation Error Trends** :\n",
    "- Training error typically decreases as model complexity increases, potentially reaching zero.\n",
    "- Validation error may initially decrease but often increases after a certain point due to overfitting, forming a U-shaped curve. The model at the bottom of this curve best balances underfitting and overfitting. \n",
    "- **Complexity and Error Patterns** :\n",
    "- Some models show a U-shaped validation error curve, where error decreases, bottoms out, and then increases with complexity. This indicates a transition from underfitting to optimal fitting to overfitting.\n",
    "- Others might show a decreasing validation error even at high complexity, suggesting that adding capacity (more parameters or structure) continues to improve model performance on unseen data. \n",
    "- **Interpolation and Overfitting** :\n",
    "- Models that perfectly fit all training data are said to have interpolated the data.\n",
    "- Overfitting is common as models approach the capacity to interpolate, often because excess capacity is allocated inefficiently, not aligning with validation data patterns.\n",
    "- Some model classes, however, manage added capacity better, finding representations that match the true underlying function as capacity increases. \n",
    "- **Decreasing Validation Error in Some Models** : Deep neural networks, kernel machines, random forests, and boosted ensembles tend to exhibit decreasing validation error with increased capacity, unlike decision trees that may not recover from overfitting beyond the interpolation point. \n",
    "- **Extending Model Selection** :\n",
    "- The algorithm could be extended to compare different model classes (e.g., decision trees vs. polynomials) by running model selection for each and comparing outcomes.\n",
    "- Supporting multiple hyperparameters could lead to more sophisticated optimization strategies, like grid search, rather than simple linear search, allowing for a broader exploration of the model space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.4.2 From Error Rates to Loss**  \n",
    "- **Beyond Error Rates** : Minimizing error rate is a start, but understanding the severity of different types of errors can be more important. For instance, mistaking non-spam for spam can have more serious consequences than the reverse. \n",
    "- **Maximizing Expected Utility** : In machine learning, the goal is reformulated as minimizing loss, defined as the difference in utility between the correct answer and the predicted one. This allows for a more nuanced approach to assessing model performance. \n",
    "- **Loss Functions** : \n",
    "- **General** : L(x,y,y^)L(x, y, \\hat{y})L(x,y,y^​) measures the utility lost due to prediction y^\\hat{y}y^​ versus the correct answer yyy, often simplified to L(y,y^)L(y, \\hat{y})L(y,y^​) for practicality. \n",
    "- **Specific cases** : Different types of loss functions are used depending on the nature of the output (e.g., absolute-value loss, squared-error loss, and 0/1 loss for discrete outputs). \n",
    "- **Expected Generalization Loss** : Ideally, a model is chosen to minimize the expected loss across all possible inputs, a theoretical best defined with a prior probability distribution over examples. Since the true distribution P(x,y)P(x,y)P(x,y) is unknown, empirical loss on a given dataset is used as an estimate. \n",
    "- **Reasons for Divergence from the True Function** : \n",
    "- **Unrealizability** : The true function fff might not be in the hypothesis space HHH. \n",
    "- **Variance** : Different sets of examples may lead to different hypotheses. \n",
    "- **Noise** : The target function may be nondeterministic or subject to noise, making perfect prediction impossible. \n",
    "- **Computational complexity** : The search for the optimal hypothesis within a large or complex space may be computationally infeasible. \n",
    "- **Shifts in Learning Scale** : \n",
    "- **Small-scale learning** : Focuses on managing approximation and estimation errors due to limited data and hypothesis space. \n",
    "- **Large-scale learning** : With abundant data, computational limits become the primary constraint, emphasizing the challenge of finding an optimal hypothesis amidst vast possibilities.\n",
    "\n",
    "This nuanced approach to model evaluation, emphasizing loss minimization over mere error rate reduction, allows for the creation of more sophisticated and effectively tuned machine learning models, tailored to the specific costs associated with different types of mispredictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.4.3 Regularization**  \n",
    "- **Concept** : Regularization is a technique to prevent overfitting by penalizing the complexity of the hypothesis. It balances the empirical loss and the hypothesis complexity to select a model that generalizes well without being overly complex. \n",
    "- **Total Cost Calculation** : The total cost of a hypothesis is the sum of its empirical loss and a penalty for complexity, controlled by a hyperparameter λ\\lambdaλ:\n",
    "Cost(h)=EmpLoss(h)+λ⋅Complexity(h)\\text{Cost}(h) = \\text{EmpLoss}(h) + \\lambda \\cdot \\text{Complexity}(h)Cost(h)=EmpLoss(h)+λ⋅Complexity(h)\n",
    "\n",
    "The optimal hypothesis h^∗\\hat{h}^*h^∗ is the one that minimizes this total cost. \n",
    "- ****Role of ** ** : λ\\lambdaλ is a critical hyperparameter that determines the trade-off between the empirical loss and the complexity of the model. A well-chosen λ\\lambdaλ helps to balance simplicity and accuracy, steering the model selection away from overly complex models that might overfit. \n",
    "- **Choosing the Regularization Function** : The regularization function, or the complexity measure, varies depending on the hypothesis space. For instance, in polynomial models, the sum of the squares of the coefficients can serve as a regularization function to discourage overly wiggly polynomials. \n",
    "- **Feature Selection** : Another approach to simplifying models and reducing overfitting is through feature selection, where irrelevant attributes are identified and discarded. Techniques like χ2\\chi^2χ2 pruning are examples of feature selection methods. \n",
    "- **Empirical Loss and Complexity on the Same Scale** : Ideally, both empirical loss and complexity could be measured in bits, allowing for a unified scale of measurement. This approach involves encoding both the hypothesis and the data, with the cost of incorrectly predicted examples depending on the magnitude of the error. \n",
    "- **Minimum Description Length (MDL)** : The MDL principle aims to minimize the total number of bits required to encode the hypothesis and the data. While effective in theory, practical implementation depends on the encoding scheme, especially for smaller problems. MDL provides a probabilistic interpretation of balancing model complexity with the fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.4.4 Hyperparameter Tuning**  \n",
    "- **Introduction** : Hyperparameter tuning is crucial for optimizing machine learning models, especially when dealing with multiple hyperparameters or continuous values. \n",
    "- **Methods** : \n",
    "1. **Hand-tuning** : Involves iteratively adjusting hyperparameters based on intuition and experience, training the model, and evaluating its performance on validation data. \n",
    "2. **Grid search** : A systematic approach for a small set of hyperparameters with discrete values, testing all possible combinations and selecting the one with the best performance on validation data. This method can be resource-intensive but parallelizable. \n",
    "3. **Random search** : Suitable for a large search space or continuous values, it samples hyperparameter settings uniformly at random. It's simpler and often more efficient than grid search for high-dimensional spaces. \n",
    "4. **Bayesian optimization** : Approaches hyperparameter tuning as a machine learning problem itself, where the goal is to learn the function mapping hyperparameters to validation loss. It balances exploration of new parameters with exploitation of known good ones, often using Gaussian processes to model the function. \n",
    "5. **Population-based training (PBT)** : Combines the parallel efficiency of random search with the iterative improvement of Bayesian optimization. It trains a population of models with different hyperparameters, evolving hyperparameter settings over generations based on performance, akin to genetic algorithms. \n",
    "- **Trade-offs** : \n",
    "- **Exploitation vs. Exploration** : Balancing between refining known good hyperparameter settings (exploitation) and trying new settings to discover potentially better ones (exploration) is a key aspect of effective hyperparameter tuning. \n",
    "- **Computational resources** : The choice of method often depends on the available computational resources and the cost of training models. Grid search and PBT can be highly parallelized, while Bayesian optimization efficiently navigates the search space but may require more sequential steps. \n",
    "- **Application** : The choice of hyperparameter tuning method can significantly impact model performance, making it a critical step in the machine learning workflow. Techniques like Bayesian optimization and PBT represent advanced strategies that can outperform traditional methods, especially in complex search spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.5 The Theory of Learning**  \n",
    "- **Foundation Questions** : Addressing how to ensure learned hypotheses will accurately predict new, unseen examples, considering the unknown nature of the target function fff. \n",
    "- **Computational Learning Theory** : Explores the necessary number of examples for effective learning, utilizing principles like PAC (probably approximately correct) learning to estimate performance bounds for algorithms under the assumption of stationarity, where future examples follow the same distribution as past ones. \n",
    "- **PAC Learning** : Defines conditions under which a learning algorithm can produce hypotheses that are both probable and approximately correct, emphasizing the importance of choosing an appropriate hypothesis space HHH. \n",
    "- **Sample Complexity** : Concerns how many training examples are needed for a hypothesis to be probably approximately correct. It's influenced by the desired accuracy (ϵ\\epsilonϵ), confidence (δ\\deltaδ), and the size of the hypothesis space (∣H∣|H|∣H∣). \n",
    "- **Error and Approximate Correctness** : A hypothesis is considered approximately correct if its error rate is below a small constant ϵ\\epsilonϵ, suggesting closeness to the true function within the ϵ\\epsilonϵ-ball in hypothesis space. \n",
    "- **Bounding Error Probability** : The likelihood that a significantly wrong hypothesis agrees with NNN examples is bounded by (1−ϵ)N(1-\\epsilon)^N(1−ϵ)N, aiding in determining the minimum number of examples required to confidently find a good hypothesis. \n",
    "- **Addressing Large Hypothesis Spaces** : For complex spaces (e.g., all Boolean functions of nnn attributes), achieving PAC learning may require an impractically large number of examples, suggesting the need for restricting the hypothesis space. \n",
    "- **Restricting Hypothesis Space** : To effectively generalize and reduce sample complexity, the hypothesis space may be constrained. This can be achieved by:\n",
    "1. Applying prior knowledge to refine the space.\n",
    "2. Preferring simpler hypotheses, which may lead to better generalization. \n",
    "3. Focusing on learnable subsets of hypotheses, assuming the presence of a hypothesis close enough to the true function fff. \n",
    "- **Challenges and Solutions** : The theory navigates between the risk of overlooking the true function by overly constraining HHH and the impracticality of considering excessively large HHH. Strategies include leveraging prior knowledge, simplifying hypotheses, and identifying effectively learnable hypothesis subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.5.1 PAC Learning Example: Learning Decision Lists**  \n",
    "- **Decision Lists** : These are simplified models compared to decision trees, featuring a linear series of tests, each being a conjunction of literals. A test's success leads to a specified outcome; failure moves the process to the next test. This structure allows for representing any Boolean function by varying the complexity of individual tests. \n",
    "- **Representation Capability** : With no limit on test size, decision lists can represent any Boolean function. Limiting tests to k literals enables generalization from fewer examples, indicated as k-DL. A decision list restricted to k conjunctions is denoted as k-DL(n) for n Boolean attributes. \n",
    "- **Learnability of k-DL** : The learnability of a k-DL, meaning its capability to be accurately approximated with a reasonable number of examples, depends on the size of its hypothesis space. This space grows polynomially with the number of attributes (n) and the size limit of conjunctions (k), making k-DL functions PAC-learnable for small k values. \n",
    "- **Calculating Hypotheses Space Size** : The size of the hypothesis space for k-DL(n) functions is determined by the number of possible conjunctions of up to k literals from n attributes, which is polynomial in n. The number of examples needed for PAC learning a k-DL function thus also scales polynomially with n and k. \n",
    "- **Consistent Decision List Algorithm** : An efficient greedy algorithm, DECISION-LIST-LEARNING, constructs consistent decision lists by iteratively selecting tests that match subsets of training data, removing matched examples, and continuing until no examples remain. The selection strategy aims for minimal tests that capture large, uniformly classified subsets, optimizing for compactness and consistency. \n",
    "- **Performance Comparison** : Decision lists and decision trees have shown comparable accuracy levels in learning tasks, with decision trees learning slightly faster but exhibiting more variation in performance. Both methods achieve high accuracy after sufficient training, demonstrating the effectiveness of PAC learning principles in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch19_learning_from_examples/fig19_24_boosting.jpg?raw=true\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

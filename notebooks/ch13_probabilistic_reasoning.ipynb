{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAPrWItgFjGK"
      },
      "source": [
        "# Chapter 13 - Probabilistic Reasoning\n",
        "\n",
        "*In which we explain how to build efficient network models to reason under uncertainty\n",
        "according to the laws of probability theory, and how to distinguish between correlation\n",
        "and causality.* - Artificial Intelligence: A Modern Approach 4th Edition by Stuart Russell and Peter Norvig\n",
        "\n",
        "* Introduction to building efficient network models for reasoning under uncertainty with probability theory.\n",
        "* Distinction between correlation and causality.\n",
        "* Builds on basic elements of probability theory, emphasizing the importance of independence and conditional independence.\n",
        "* Introduction of Bayesian networks for systematic representation of probabilistic relationships.\n",
        "* Discussion on syntax and semantics of Bayesian networks for capturing uncertain knowledge.\n",
        "* Exploration of probabilistic inference, including efficient methods for practical situations and approximate algorithms for infeasible exact inference.\n",
        "* Sets the stage for more advanced probabilistic models in later chapters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEwEhncGFjGL"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ValRCS/RBS_PBM773_Introduction_to_AI/main/img/ch13_probabilistic_reasoning/DALL%C2%B7E%202024-02-19%2016.01.25%20-%20A%20suburban%20street%20scene%20with%20a%20house%20on%20one%20side%2C%20featuring%20a%20lawn%20sprinkler%20actively%20watering%20the%20grass.%20It's%20raining%20at%20the%20same%20time%2C%20causing%20the%20s.webp\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F45jpoWcFjGM"
      },
      "source": [
        "## Probability Theory Review\n",
        "\n",
        "### Random Variables\n",
        "\n",
        "A **random variable** is a variable that can take on different values with certain probabilities. For example, the outcome of a die roll is a random variable that can take on the values 1, 2, 3, 4, 5, or 6, each with a probability of 1/6.\n",
        "\n",
        "### Probability Distributions\n",
        "\n",
        "A **probability distribution** is a function that assigns a probability to each possible value of a random variable. For example, the probability distribution of a fair die roll is the function that assigns a probability of 1/6 to each of the six possible outcomes.\n",
        "\n",
        "### Joint Probability Distribution\n",
        "\n",
        "The **joint probability distribution** of a set of random variables is a function that assigns a probability to every combination of values of the variables. For example, the joint probability distribution of two fair die rolls is the function that assigns a probability of 1/36 to each of the 36 possible outcomes.\n",
        "\n",
        "### Conditional Probability\n",
        "\n",
        "The **conditional probability** of an event A given event B is the probability that event A occurs given that event B has occurred. It is denoted P(A|B) and is defined as:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OD--VoHFjGM"
      },
      "source": [
        "## Probability Formulas\n",
        "\n",
        "#### Event space sum\n",
        "\n",
        "The sum of the probabilities of all the outcomes in the event space is 1:\n",
        "\n",
        "#### Negation of a Proposition\n",
        "\n",
        "Probability of the negation of a proposition is 1 minus the probability of the proposition itself:\n",
        "\n",
        "P(¬A) = 1 - P(A)\n",
        "\n",
        "#### Multiplication Rule\n",
        "\n",
        "Probability of two unrelated propositions occuring BOTH is the product of their probabilities:\n",
        "\n",
        "Example of two unrelated propositions: winning a lottery and getting struck by lightning.\n",
        "\n",
        "P(A ∧ B) = P(A) * P(B)\n",
        "Assuming the two events are independent.\n",
        "\n",
        "#### Addition Rule\n",
        "\n",
        "You have two mutually exclusive propositions, the probability of one or the other occurring is the sum of their probabilities:\n",
        "\n",
        "P(A ∨ B) = P(A) + P(B)\n",
        "\n",
        "Example: two mutually exclusive propositions: getting a 1 or a 2 on a die roll.\n",
        "\n",
        "\n",
        "#### Disjunction\n",
        "\n",
        "Probability of the disjunction of two propositions is the sum of their probabilities minus the probability of their conjunction:\n",
        "\n",
        "P(A ∨ B) = P(A) + P(B) - P(A ∧ B)\n",
        "\n",
        "Note in the above formula, the probability of the conjunction is subtracted to avoid double counting. P(A) + P(B) would work if the events are mutually exclusive.\n",
        "\n",
        "#### Conditional Probability\n",
        "\n",
        "Probability of the conjunction of two propositions is the probability of the first proposition times the probability of the second proposition given the first:\n",
        "\n",
        "P(A ∧ B) = P(A) * P(B|A)\n",
        "\n",
        "Similarly:\n",
        "P(A ∧ B) = P(B) * P(A|B\n",
        "\n",
        "#### Bayes' Rule\n",
        "\n",
        "Bayes' rule is a formula that relates the conditional and marginal probabilities of two propositions:\n",
        "\n",
        "P(A|B) = P(B|A) * P(A) / P(B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYRBZce3FjGN"
      },
      "source": [
        "## 13.1 Representing Knowledge in an Uncertain Domain**\n",
        "\n",
        "- **Key Concepts:**  \n",
        "- **Bayesian Networks:**  Introduced as a data structure to represent dependencies among variables, allowing for concise representation of full joint probability distributions.\n",
        "- **Nodes and Directed Links:**  Nodes represent random variables (discrete or continuous), and directed links connect pairs of nodes, indicating parent-child relationships and defining a directed acyclic graph (DAG).\n",
        "- **Conditional Independence:**  The topology of a Bayesian network specifies conditional independence relationships, simplifying the representation of probability distributions.\n",
        "- **Examples and Applications:**  Demonstrated with examples like the burglar alarm system, highlighting the network's ability to encode dependencies and conditional independencies effectively.\n",
        "- **Probability Information:**  Each node in a Bayesian network is annotated with quantitative probability information, which quantifies the effect of the parents on the node using a finite number of parameters.\n",
        "- **Local Probability Information:**  The specification requires only the conditional distribution of each variable given its parents, allowing for the efficient definition of the full joint distribution.\n",
        "\n",
        "This section delves into the challenges of representing knowledge in uncertain domains, emphasizing the role of Bayesian networks in managing complexity through explicit representation of dependencies and conditional independences among variables. It illustrates how Bayesian networks facilitate a structured approach to modeling uncertainty, leveraging examples to clarify concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2qnEFDOFjGN"
      },
      "source": [
        "### **Burglar Alarm Network:**\n",
        "- The network is designed to represent the probabilistic relationships between burglaries, earthquakes, alarm activations, and the observations of two neighbors, John and Mary.\n",
        "- **Variables:**  \n",
        "- **Burglary (B):**  Indicates whether a burglary has occurred.\n",
        "- **Earthquake (E):**  Indicates whether there has been an earthquake.\n",
        "- **Alarm (A):**  Represents the alarm state, which can be triggered by either a burglary or an earthquake.\n",
        "- **JohnCalls (J):**  Represents whether John calls the police, which is influenced by the alarm state.\n",
        "- **MaryCalls (M):**  Represents whether Mary calls the police, also influenced by the alarm state.\n",
        "- **Directed Links:**\n",
        "- The network contains directed links from Burglary and Earthquake to Alarm, indicating that both can independently trigger the alarm.\n",
        "- Additional links from Alarm to both JohnCalls and MaryCalls indicate that the activation of the alarm influences whether John and Mary call the police.\n",
        "- **Conditional Probabilities:**  Each node is associated with conditional probability tables. For instance, the probability of the alarm going off given a burglary and no earthquake, the likelihood of John calling given the alarm status, etc.\n",
        "- **Purpose:**  This network efficiently encapsulates the domain knowledge about the relationships and conditional independences among these variables, allowing for probabilistic reasoning about the occurrence of events based on observed evidence.\n",
        "\n",
        "This Bayesian Network example demonstrates how complex probabilistic relationships and dependencies can be represented in a structured and efficient manner, enabling effective reasoning in uncertain domains.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_CIYL8PFjGO"
      },
      "source": [
        "<img src=\"https://camo.githubusercontent.com/8b8fe1424ce978685424c5c003b30b4e25ee2c940fcaed5304641100097a5786/687474703a2f2f6e6f727669672e636f6d2f69707974686f6e2f627572676c617279322e6a7067\" width=\"500\">\n",
        "\n",
        "From: https://github.com/aimacode/aima-python/blob/master/probability4e.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHUSPCkzFjGO"
      },
      "source": [
        "### Conditional Probability Tables (CPTs):\n",
        "\n",
        "A Conditional Probability Table (CPT) is a fundamental component of Bayesian Networks that quantifies the relationship between a node and its parents. Here's a detailed explanation of what a CPT is and how it works:\n",
        "- **Purpose:**  A CPT provides a quantitative description of the probabilistic relationships between a node and its parent nodes within a Bayesian Network. It specifies the probability of each possible value of the node given every possible combination of values of its parent nodes.\n",
        "- **Structure:**  For a given node, the CPT lists all possible combinations of parent states along with the corresponding probabilities of the node's states. If a node has no parents (i.e., it is a root node), its CPT simply describes the prior probabilities of its states.\n",
        "- **Example:**  Consider a simple Bayesian Network with a node \"Alarm\" that has two parents: \"Burglary\" and \"Earthquake.\" The \"Alarm\" node might have a CPT that looks something like this:\n",
        "BurglaryEarthquakeProbability(Alarm=True)\n",
        "\n",
        "TrueTrue0.95TrueFalse0.94\n",
        "FalseTrue0.29FalseFalse0.001\n",
        "\n",
        "This table shows the probability of the alarm being true (i.e., going off) given each combination of the burglary and earthquake states.\n",
        "- **Interpretation:**  The CPT allows us to understand how the presence or absence of certain conditions (represented by the parent nodes) affects the likelihood of the node's states. In the example above, the alarm is most likely to go off if there is both a burglary and an earthquake, and least likely if there are neither.\n",
        "- **Utility in Inference:**  CPTs are crucial for performing probabilistic inference in Bayesian Networks. They allow us to compute the posterior probabilities of nodes given evidence by applying Bayes' theorem and related probabilistic rules.\n",
        "- **Specification:**  In practice, the CPT for a node is specified by domain experts or learned from data using statistical methods. The complexity of a CPT grows exponentially with the number of parent nodes, which can make specifying and computing with CPTs challenging for nodes with many parents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlnopaCsFjGO"
      },
      "source": [
        "## 13.2 The Semantics of Bayesian Networks*\n",
        "\n",
        "- **Key Concepts:**  \n",
        "- **Semantics and Syntax:**  The semantics of Bayesian networks relate the syntax (a directed acyclic graph with probability information at each node) to a joint probability distribution over all variables in the network.\n",
        "- **Joint Distribution Representation:**  The probability of any set of variable assignments within the network is represented by the product of local conditional distributions for each variable given its parents, demonstrating how the network encodes the entire joint distribution compactly.\n",
        "- **Conditional Independence:**  The structure of a Bayesian network implies certain conditional independence relationships among variables, which are crucial for simplifying the representation and computation of probabilities.\n",
        "- **Illustrative Examples:**  Practical examples, such as calculating the probability of events given certain conditions (e.g., the alarm sounding without a burglary or earthquake), help illustrate the use of local conditional distributions in computing probabilities.\n",
        "- **Efficiency in Answering Queries:**  The network allows for answering queries about the domain by summing relevant joint probability values, each calculated by multiplying probabilities from local conditional distributions, offering a more efficient method than directly using the full joint distribution.\n",
        "- **Importance of Local Conditional Distributions:**  The parameters in these distributions are equivalent to the conditional probabilities implied by the joint distribution, highlighting the coherence and consistency of the Bayesian network's representation of probabilistic relationships.\n",
        "\n",
        "This subchapter delves into the foundational principles that underpin Bayesian networks, explaining how these networks provide a powerful and efficient framework for representing and reasoning with probabilistic information. Through the semantics of Bayesian networks, we see how complex domains characterized by uncertainty can be modeled in a structured and computationally tractable way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y44duepSFjGP"
      },
      "source": [
        "### A Method for Constructing Bayesian Networks**  \n",
        "- **Nodes:**  Identify all variables that model the domain effectively. Order these variables in a sequence that reflects causality, where causes precede their effects. This ordering helps in creating a more compact network.\n",
        "- **Links:**  For each variable XiX_iXi​, from X1X_1X1​ to XnX_nXn​, perform the following:\n",
        "- Identify a minimal set of parents from the preceding variables (X1X_1X1​ to Xi−1X_{i-1}Xi−1​) such that the network reflects the true conditional dependencies, as expressed by Equation (13.3).\n",
        "- For each identified parent, insert a directed link from the parent to XiX_iXi​.\n",
        "- **Conditional Probability Tables (CPTs):**  For each variable XiX_iXi​, specify the conditional probability table that quantifies the effect of its parents on XiX_iXi​. The selection of parents for XiX_iXi​ should be based on direct influences in the domain. For example, the decision to make Alarm the only parent of MaryCalls is based on the understanding that Mary's decision to call is influenced only by the alarm state, not directly by a burglary or an earthquake.\n",
        "- **Acyclicity and Non-redundancy:**  This construction method ensures the network remains acyclic (no cycles) and non-redundant (no unnecessary probability values), which prevents inconsistencies and violations of probability axioms.\n",
        "\n",
        "This systematic approach to constructing Bayesian networks facilitates the representation of complex probabilistic relationships in a structured and coherent manner, leveraging domain knowledge to identify relevant variables and their dependencies effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiG0u4IFjGP"
      },
      "source": [
        "### A Method for Constructing Bayesian Networks**  \n",
        "- **Nodes:**  Identify all variables that model the domain effectively. Order these variables in a sequence that reflects causality, where causes precede their effects. This ordering helps in creating a more compact network.\n",
        "- **Links:**  For each variable XiX_iXi​, from X1X_1X1​ to XnX_nXn​, perform the following:\n",
        "- Identify a minimal set of parents from the preceding variables (X1X_1X1​ to Xi−1X_{i-1}Xi−1​) such that the network reflects the true conditional dependencies, as expressed by Equation (13.3).\n",
        "- For each identified parent, insert a directed link from the parent to XiX_iXi​.\n",
        "- **Conditional Probability Tables (CPTs):**  For each variable XiX_iXi​, specify the conditional probability table that quantifies the effect of its parents on XiX_iXi​. The selection of parents for XiX_iXi​ should be based on direct influences in the domain. For example, the decision to make Alarm the only parent of MaryCalls is based on the understanding that Mary's decision to call is influenced only by the alarm state, not directly by a burglary or an earthquake.\n",
        "- **Acyclicity and Non-redundancy:**  This construction method ensures the network remains acyclic (no cycles) and non-redundant (no unnecessary probability values), which prevents inconsistencies and violations of probability axioms.\n",
        "\n",
        "This systematic approach to constructing Bayesian networks facilitates the representation of complex probabilistic relationships in a structured and coherent manner, leveraging domain knowledge to identify relevant variables and their dependencies effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3xmjbLbFjGP"
      },
      "source": [
        "### Chain Rule\n",
        "\n",
        "The chain rule of probability is a fundamental principle that underpins the semantics of Bayesian networks. It provides a way to express the joint probability distribution of a set of random variables in terms of the conditional probabilities of each variable given its parents. Here's a detailed explanation of the chain rule and its significance:\n",
        "\n",
        "- **Definition:**  The chain rule of probability states that the joint probability distribution of a set of random variables can be expressed as the product of the conditional probabilities of each variable given its parents in the network.\n",
        "\n",
        "- **Mathematical Formulation:**  For a set of random variables X1,X2,…,XnX_1, X_2, \\ldots, X_nX1​,X2​,…,Xn​, the chain rule can be written as:\n",
        "\n",
        "P(X1,X2,…,Xn)=P(X1)P(X2|X1)P(X3|X1,X2)⋯P(Xn|X1,X2,…,Xn−1)P(X_1, X_2, \\ldots, X_n) = P(X_1)P(X_2|X_1)P(X_3|X_1, X_2) \\cdots P(X_n|X_1, X_2, \\ldots, X_{n-1})P(X1​,X2​,…,Xn​)=P(X1​)P(X2​∣X1​)P(X3​∣X1​,X2​)⋯P(Xn​∣X1​,X2​,…,Xn−1​)\n",
        "\n",
        "- **Significance:**  The chain rule provides a way to represent the joint probability distribution of a set of variables in terms of the local conditional distributions of each variable given its parents. This is crucial for the semantics of Bayesian networks, as it demonstrates how the network's structure encodes the full joint distribution in a compact and efficient manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dR9jFz5FjGP"
      },
      "source": [
        "### Topological Ordering\n",
        "\n",
        "Topological ordering is a concept related to directed graphs, including those used in Bayesian networks. It refers to a sequencing of the nodes (variables) in a directed graph such that for every directed edge from node AAA to node BBB, node AAA appears before node BBB in the ordering. This concept is crucial in the context of Bayesian networks for several reasons:\n",
        "\n",
        "- **Causality and Dependency:**  Topological ordering respects the causality or dependency direction implied by the graph. In Bayesian networks, if there's a directed edge from node AAA (e.g., a cause) to node BBB (an effect), AAA must be processed before BBB, reflecting the causal or dependency relationship.\n",
        "- **Construction and Evaluation:**  When constructing or evaluating Bayesian networks, topological ordering allows for the systematic computation of joint probabilities or the execution of inference algorithms. It ensures that calculations for a node are only performed after all its parent nodes have been considered, which is necessary to accurately compute conditional probabilities.\n",
        "- **Cycle Detection:**  A directed graph can have a topological order if and only if it is acyclic (i.e., it does not contain any cycles). Thus, the possibility of creating a topological order for a graph also serves as a check for acyclicity, which is a prerequisite for Bayesian networks.\n",
        "- **Inference Algorithms:**  For inference algorithms, topological ordering facilitates efficient processing. Algorithms can traverse the network in a topologically sorted order to ensure that all information (e.g., evidence or prior probabilities) has been propagated through the network in a logically coherent manner.\n",
        "\n",
        "In summary, topological ordering is essential for the structure and operation of Bayesian networks, supporting the representation of dependencies, the implementation of algorithms, and the integrity of probabilistic reasoning within the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhmOfaxJFjGQ"
      },
      "source": [
        "### Compactness and Node Ordering**  \n",
        "- **Efficiency and Compactness:**  Bayesian networks can be significantly more compact than the full joint distribution, especially in domains where each variable is directly influenced by only a limited number of other variables. This local structure, or sparsity, leads to a manageable increase in complexity, often linear rather than exponential, as the number of variables grows.\n",
        "- **Construction Principles:**  In constructing a Bayesian network, the goal is to maintain this compactness by carefully selecting which variables influence others directly. This selection is guided by the domain knowledge and the causal relationships between variables. Compactness is achieved by representing only the most significant and direct influences, avoiding unnecessary complexity.\n",
        "- **Node Ordering:**  The order in which nodes (variables) are added to the network affects its compactness and the number of parameters required to define it. A well-chosen order that reflects the causal relationships and dependencies can minimize the number of parameters and the network's complexity. For example, a network that models variables in a causal order (causes before effects) is typically more compact than one that does not.\n",
        "- **Example of Impact on Compactness:**  Changing the order in which nodes are added can lead to different network structures, some more compact than others. For instance, in a network modeling burglary and earthquake alarms, starting with nodes that have few or no parents and progressing to those influenced by many factors can result in a more compact network than starting with highly dependent variables.\n",
        "- **Avoiding Redundancy:**  By excluding links that represent weak or indirect dependencies, the network remains more manageable. However, deciding which links to exclude requires careful consideration of the trade-offs between accuracy and complexity. Sometimes, slight dependencies are ignored to keep the network simple and tractable.\n",
        "\n",
        "In summary, the compactness and node ordering in Bayesian networks are crucial for efficiently representing and computing probabilistic inferences in domains with many variables. By focusing on direct influences and causal relationships, Bayesian networks remain both powerful and practical tools for reasoning under uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ziIpgatFjGQ"
      },
      "source": [
        "### 13.2.1 Conditional Independence Relations in Bayesian Networks**  \n",
        "- **Key Concepts:**  \n",
        "- **Conditional Independence:**  A foundational concept in Bayesian networks, indicating that a variable is independent of its non-descendants given its parents. This property significantly reduces the complexity of the network and simplifies probabilistic inferences.\n",
        "- **Non-Descendants Property:**  Each variable in a Bayesian network is conditionally independent of its non-descendants given its parents. This principle allows for the compact representation of joint probability distributions and facilitates efficient computation of probabilities.\n",
        "- **Markov Blanket:**  A variable is conditionally independent of all other nodes in the network given its Markov blanket, which includes its parents, children, and children’s parents. This property underpins local and distributed stochastic sampling processes used in inference algorithms.\n",
        "- **D-Separation:**  A concept used to determine conditional independence between sets of nodes in a Bayesian network. By examining the network's structure, particularly through its moralized ancestral subgraph, d-separation can efficiently identify conditional independencies.\n",
        "- **Efficient Representation and Inference:**  The conditional independence relationships encoded in a Bayesian network enable efficient representation of the joint probability distribution and support various inference algorithms by exploiting these relationships.\n",
        "\n",
        "This subchapter emphasizes the crucial role of conditional independence in structuring Bayesian networks to represent complex probabilistic domains efficiently. By leveraging conditional independence, Bayesian networks facilitate both the compact representation of knowledge and the development of effective inference methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O267fdTjFjGQ"
      },
      "source": [
        "### Conditional Independence\n",
        "\n",
        "Conditional independence is a key concept in probability theory and statistics that describes a relationship between three or more random variables. Specifically, two variables are conditionally independent given a third variable if the state of one variable does not affect the probability distribution of the second variable, once the state of the third variable is known.\n",
        "#### Formal Definition\n",
        "\n",
        "For three random variables XXX, YYY, and ZZZ, XXX and YYY are conditionally independent given ZZZ if the conditional probability distribution of XXX given YYY and ZZZ is the same as the conditional probability distribution of XXX given ZZZ alone. This can be formally written as:\n",
        "P(X∣Y,Z)=P(X∣Z)P(X | Y, Z) = P(X | Z)P(X∣Y,Z)=P(X∣Z)\n",
        "\n",
        "This equation holds for all values of XXX, YYY, and ZZZ, and implies that knowing YYY, in addition to ZZZ, does not provide any additional information about XXX than ZZZ alone does.\n",
        "#### Implications in Bayesian Networks\n",
        "\n",
        "In the context of Bayesian networks, conditional independence is fundamental for simplifying the representation of joint probability distributions. The structure of a Bayesian network—specifically, its directed edges and the absence of certain connections—encapsulates conditional independence assumptions among the variables it represents. These assumptions allow for:\n",
        "- **Compact Representation:**  The network can represent complex joint distributions compactly, avoiding the need to specify the joint probability of every combination of variable states explicitly.\n",
        "- **Efficient Inference:**  Conditional independence enables efficient probabilistic inference algorithms by allowing calculations to focus on smaller subsets of variables, leveraging the network's structure to factor the joint distribution into a product of simpler conditional distributions.\n",
        "#### Example\n",
        "\n",
        "Consider a Bayesian network representing three variables: Rain (R), Sprinkler (S), and Wet Grass (W), where Rain can cause Wet Grass, and Sprinkler can also cause Wet Grass. In this network, once we know whether the grass is wet (W), the information about the Sprinkler (S) does not change the probability of Rain (R), and vice versa, assuming we consider the effect on the grass's wetness. Thus, Rain and Sprinkler are conditionally independent given Wet Grass.\n",
        "#### Utilization\n",
        "\n",
        "Conditional independence is utilized in various applications, including machine learning, data analysis, and decision-making processes, where understanding the relationships and dependencies between variables is crucial. It aids in model simplification, computational efficiency, and the interpretability of statistical models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ckRm7bFjGQ"
      },
      "source": [
        "### 13.2.2 Efficient Representation of Conditional Distributions**\n",
        "\n",
        "This section delves into techniques for efficiently representing the conditional probability distributions (CPTs) within Bayesian networks, focusing on reducing the complexity and number of parameters needed to describe the relationships between nodes. Here are the key points:\n",
        "- **Canonical Distributions:**  In many cases, the relationships between a node and its parents can be described by a standard, or canonical, distribution pattern. This allows for the specification of the complete CPT by just naming the pattern and providing a few parameters, significantly reducing complexity.\n",
        "- **Deterministic Nodes:**  These nodes have values precisely determined by their parents, without uncertainty. The relationships can be logical (e.g., logical OR) or numerical (e.g., sum or minimum), allowing these deterministic functions to be directly encoded into the network.\n",
        "- **Context-specific Independence (CSI):**  A variable may be conditionally independent of some of its parents given certain values of other parents. This allows for more compact CPTs by specifying conditions under which certain dependencies can be ignored, thus simplifying the model.\n",
        "- **Noisy-OR:**  This is a generalization of the logical OR relationship that accounts for uncertainty, allowing for the possibility that a cause (parent) does not always lead to an effect (child). The Noisy-OR model is particularly useful for representing uncertain causal relationships with fewer parameters than would be required for a full CPT.\n",
        "\n",
        "These methods for efficient representation of conditional distributions highlight the flexibility and power of Bayesian networks to model complex domains with uncertainty. By leveraging deterministic nodes, CSI, and canonical patterns like the Noisy-OR, it's possible to significantly reduce the number of parameters needed, facilitating easier model specification, learning, and inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-z00Qb7FjGQ"
      },
      "source": [
        "### Noisy-OR Model\n",
        "\n",
        "- Let's consider a simplified example relevant to the noisy-OR model concept. Suppose we have a network with three binary parent variables AAA, BBB, and CCC (e.g., three different treatments for a disease), and one binary child variable DDD (e.g., recovery from the disease). The noisy-OR model is used to represent the conditional probability of DDD given AAA, BBB, and CCC, assuming each treatment has an independent probability of not leading to recovery (denoted as qAq_AqA​, qBq_BqB​, and qCq_CqC​ for treatments AAA, BBB, and CCC respectively).\n",
        "\n",
        "Here's a conceptual structure of the conditional probability table for DDD using the noisy-OR model:\n",
        "\n",
        "| A | B | C | P(D=True∣A,B,C)P(D = \\text{True} | A, B, C)P(D=True∣A,B,C) |\n",
        "|------|------|------|----------------------------------|\n",
        "| True | True | True | 1−qA⋅qB⋅qC1 - q_A \\cdot q_B \\cdot q_C1−qA​⋅qB​⋅qC​ |\n",
        "| True | True | False | 1−qA⋅qB1 - q_A \\cdot q_B1−qA​⋅qB​ |\n",
        "| True | False | True | 1−qA⋅qC1 - q_A \\cdot q_C1−qA​⋅qC​ |\n",
        "| True | False | False | 1−qA1 - q_A1−qA​ |\n",
        "| False | True | True | 1−qB⋅qC1 - q_B \\cdot q_C1−qB​⋅qC​ |\n",
        "| False | True | False | 1−qB1 - q_B1−qB​ |\n",
        "| False | False | True | 1−qC1 - q_C1−qC​ |\n",
        "| False | False | False | 000 (or a small probability representing spontaneous recovery) |\n",
        "\n",
        "This table shows how the probability of recovery (D=TrueD = \\text{True}D=True) is calculated given the presence (True) or absence (False) of each treatment (AAA, BBB, and CCC). The qqq-values represent the probability that a treatment fails to lead to recovery. The noisy-OR model simplifies the representation by assuming that each treatment independently contributes to the outcome, with the overall failure rate being the product of the individual failure rates.\n",
        "\n",
        "In practice, the specific qqq-values would depend on empirical data or expert estimation regarding the effectiveness of each treatment. This model allows for a compact representation of conditional probabilities in situations where multiple causes independently affect an outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vYjM8HsFjGQ"
      },
      "source": [
        "### 13.2.3 Bayesian Nets with Continuous Variables**\n",
        "\n",
        "This section addresses the challenges and methodologies for incorporating continuous variables into Bayesian networks, which is essential for modeling many real-world problems involving continuous quantities like height, mass, temperature, and money. Here are the key points:\n",
        "- **Continuous Variables:**  Unlike discrete variables, continuous variables can assume an infinite number of possible values, making it impractical to specify conditional probabilities for each value explicitly.\n",
        "- **Handling Continuous Variables:**  \n",
        "- **Discretization:**  One approach to deal with continuous variables is discretization, which involves dividing the range of possible values into a fixed set of intervals. This method simplifies the representation of continuous variables but involves a trade-off between accuracy and the size of the conditional probability tables (CPTs), which can affect computational efficiency.\n",
        "- **Probability Density Functions:**  Another method uses standard families of probability density functions, such as the Gaussian (normal) distribution, characterized by a mean (μ\\muμ) and variance (σ2\\sigma^2σ2). This approach allows for a compact representation of continuous variables using just a few parameters.\n",
        "- **Nonparametric Representation:**  This approach defines the conditional distribution implicitly through a collection of instances, each specifying values for the parent and child variables. This method will be explored further in Chapter 19.\n",
        "- **Hybrid Bayesian Networks:**  Networks that include both discrete and continuous variables are known as hybrid Bayesian networks. They require specifying:\n",
        "- **Conditional distributions for continuous variables**  given discrete or continuous parents, and\n",
        "- **Conditional distributions for discrete variables**  given continuous parents.\n",
        "- **Example:**  The text illustrates with an example where the purchase decision (a discrete variable) depends on the cost of fruit (a continuous variable), which in turn is influenced by the size of the harvest and the operation of a government subsidy scheme (continuous and discrete variables, respectively).\n",
        "\n",
        "This section emphasizes the versatility of Bayesian networks in modeling complex domains by incorporating continuous variables and outlines methods for their effective representation and integration into the probabilistic models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWO4hlciFjGR"
      },
      "source": [
        "### Probit vs Logit Models\n",
        "\n",
        "- The logit and probit models are both used in statistical analysis to model binary outcome variables, but they differ in the function used to link the linear combination of predictors to the probability of the outcome. Here are the key differences:\n",
        "### Logit Model\n",
        "- **Function:**  The logit model uses the logistic function to model the probability that the dependent variable equals one of two categories. The logistic function is an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1.\n",
        "- **Equation:**  The logit of the probability ppp is modeled as logit(p)=log⁡(p1−p)=β0+β1X1+β2X2+...+βnXn\\text{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_nlogit(p)=log(1−pp​)=β0​+β1​X1​+β2​X2​+...+βn​Xn​, where ppp is the probability of the dependent variable being 1, β0,β1,...,βn\\beta_0, \\beta_1, ..., \\beta_nβ0​,β1​,...,βn​ are the coefficients, and X1,X2,...,XnX_1, X_2, ..., X_nX1​,X2​,...,Xn​ are the predictor variables.\n",
        "- **Distribution:**  The logit model implies a logistic distribution of the error terms.\n",
        "### Probit Model\n",
        "- **Function:**  The probit model uses the cumulative distribution function (CDF) of the standard normal distribution (the probit function) to model the probability. The probit function also produces an S-shaped curve but is derived from the normal distribution.\n",
        "- **Equation:**  The probit model can be expressed as Φ−1(p)=β0+β1X1+β2X2+...+βnXn\\Phi^{-1}(p) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_nΦ−1(p)=β0​+β1​X1​+β2​X2​+...+βn​Xn​, where Φ−1\\Phi^{-1}Φ−1 is the inverse of the standard normal CDF, ppp is the probability of the dependent variable being 1, and the other terms are as defined above.\n",
        "- **Distribution:**  The probit model assumes a normal distribution of the error terms.\n",
        "### Key Differences\n",
        "- **Link Function:**  The primary difference lies in the link function used. Logit models use the logistic function, while probit models use the normal CDF.\n",
        "- **Interpretation:**  Coefficients in logit models are interpreted in terms of odds ratios, whereas in probit models, they are linked to a change in the z-score of the underlying normal distribution.\n",
        "- **Tail Behavior:**  The logistic distribution has heavier tails than the normal distribution, which means the logit model is slightly more robust to outliers than the probit model.\n",
        "- **Use Cases:**  Logit models are more commonly used in many fields due to their simplicity and the interpretability of the logistic function. Probit models may be preferred when there is a theoretical basis for assuming the underlying error distribution is normal.\n",
        "\n",
        "In practice, both models often produce similar results, especially for large samples, and the choice between them may depend on specific research questions, theoretical considerations, or the preference of the analyst.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiF1rDQpFjGR"
      },
      "source": [
        "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch13_probabilistic_reasoning/car_insurance_bayesian_model.jpg?raw=true\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oem_9Q69FjGR"
      },
      "source": [
        "### 13.2.4 Case Study: Car Insurance Premiums**\n",
        "\n",
        "**Insurance Company's Challenge:**  The insurance company needs to decide on an annual premium for a new application, which requires estimating the expected payout for claims. This decision is complicated by the diverse and uncertain nature of factors influencing risk.\n",
        "- **Use of Bayesian Networks:**  To address this challenge, a Bayesian network is employed. This network considers various factors such as the driver's age, vehicle type, and driving history. Each of these factors influences the risk assessment differently, and their relationships are encoded in the network's structure.\n",
        "- **Modeling Risk Factors:**  The network models the probability of incidents (e.g., accidents) and the potential cost of these incidents. It incorporates both discrete variables (e.g., accident history) and continuous variables (e.g., cost of claims), showcasing the network's ability to handle a mix of data types.\n",
        "- **Determining Premiums:**  By analyzing the Bayesian network, the insurance company can estimate the expected cost of claims for the applicant. This estimate is used to set a premium that reflects the assessed risk, aiming to cover the anticipated claims while remaining competitive in the market.\n",
        "- **Advantages of Bayesian Networks:**  This approach allows for a nuanced risk assessment that accounts for the interdependencies between various factors. It enables the insurance company to tailor premiums more accurately to the specific risk profile of each applicant, rather than relying on broad categorizations.\n",
        "- **Impact on Decision-Making:**  The case study illustrates how Bayesian networks facilitate informed decision-making in complex, uncertain environments. By leveraging probabilistic reasoning, companies can make more data-driven decisions that account for the inherent uncertainties in their operations.\n",
        "\n",
        "This case study exemplifies the practical application of Bayesian networks in the insurance industry, highlighting their value in synthesizing information from various sources to make complex decisions like setting insurance premiums."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg9jTW1YFjGR"
      },
      "source": [
        "## 13.3 Exact Inference in Bayesian Networks\n",
        "- **Objective:**  The main goal in this section is to compute the posterior probability distribution for a set of query variables given some observed evidence. This process involves determining the likelihood of various outcomes based on a set of known or observed variables within the Bayesian network framework.\n",
        "- **Query Processing:**  The discussion begins with the process of handling queries within the Bayesian network. A query typically involves computing the posterior probability of a certain event given some evidence. The text provides an example involving a burglary network where the probabilities of a burglary occurring are computed based on the evidence of John and Mary calling.\n",
        "- **Algorithms for Posterior Probabilities:**  This section delves into exact algorithms designed to compute posterior probabilities of query variables. These algorithms take into account the evidence presented and use the structure and conditional probabilities encoded in the Bayesian network to calculate the likelihood of various hypotheses.\n",
        "- **Complexity of Exact Inference:**  A significant part of the discussion is dedicated to addressing the complexity associated with performing exact inference in Bayesian networks. It is noted that, in general, exact inference can be an intractable problem, leading to the exploration of approximate inference methods in the following sections.\n",
        "\n",
        "This section establishes the foundation for understanding how Bayesian networks can be used for probabilistic reasoning and inference, highlighting both the potential and the limitations of exact inference methods in dealing with complex probabilistic models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yc0Q58VFjGR"
      },
      "source": [
        "### 13.3.1 Inference by Enumeration**\n",
        "\n",
        "Here is the pseudo-code for the enumeration algorithm for exact inference in Bayesian networks, as described in Figure 13.11 of \"Artificial Intelligence: A Modern Approach\":\n",
        "\n",
        "```plaintext\n",
        "function ENUMERATION-ASK(X, e, bn) returns a distribution over X\n",
        "inputs: X, the query variable\n",
        "        e, observed values for variables E\n",
        "        bn, a Bayes net with variables vars\n",
        "\n",
        "Q(X) ← a distribution over X, initially empty\n",
        "for each value xi of X do\n",
        "    Q(xi) ← ENUMERATE-ALL(vars, e_xi)\n",
        "    where e_xi is e extended with X = xi\n",
        "return NORMALIZE(Q(X))\n",
        "\n",
        "function ENUMERATE-ALL(vars, e) returns a real number\n",
        "if EMPTY?(vars) then return 1.0\n",
        "V ← FIRST(vars)\n",
        "if V is an evidence variable with value v in e\n",
        "    then return P(v | parents(V)) × ENUMERATE-ALL(REST(vars), e)\n",
        "else return Σ_v P(v | parents(V)) × ENUMERATE-ALL(REST(vars), e_v)\n",
        "    where e_v is e extended with V = v\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "This algorithm provides a method for computing the posterior distribution of a query variable XXX given some evidence eee, utilizing depth-first search to recursively enumerate all possible values of non-evidence variables. It leverages the conditional probabilities specified in the Bayesian network to calculate the likelihood of each potential outcome for XXX, normalizing the results to form a probability distribution​​."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFghKUp6FjGR"
      },
      "source": [
        "### 13.3.2 The Variable Elimination Algorithm**\n",
        "\n",
        "This section introduces the variable elimination algorithm as an improvement over the basic enumeration algorithm for exact inference in Bayesian networks. Here are the summarized points:\n",
        "- **Efficiency Improvement:**  The variable elimination algorithm enhances efficiency by avoiding redundant computations shown in enumeration methods. It achieves this through dynamic programming by calculating once and reusing results.\n",
        "- **Operational Process:**  The algorithm operates by computing expressions in a right-to-left order, storing intermediate results, and performing summations over each variable for only those parts of the expression dependent on that variable. This process is illustrated with an example involving a burglary network.\n",
        "- **Factor Representation:**  Parts of the expression are represented as factors, which are matrices indexed by the values of their argument variables. Factors simplify the expression into manageable components that can be combined through operations like pointwise product and summation.\n",
        "- **Evaluation Steps:**  The algorithm outlines steps for evaluating expressions, starting with the summation of variables from pointwise products of factors. This process eventually yields a new factor representing the solution, i.e., the posterior distribution over the query variable.\n",
        "- **Operations on Factors:**  Two key operations are described:\n",
        "- **Pointwise Product:**  Combines pairs of factors to yield a new factor whose variables are the union of those in the original factors.\n",
        "- **Summing Out a Variable:**  Performed by adding up submatrices formed by fixing the variable to each of its values in turn, which simplifies the overall expression.\n",
        "- **Variable Elimination Algorithm:**  Provides a pseudo-code for the algorithm, demonstrating how it constructs and manipulates factors to perform exact inference efficiently. The process involves creating factors for each variable, summing out hidden variables, and normalizing the pointwise product of factors to obtain the distribution over the query variable​​.\n",
        "\n",
        "This approach significantly reduces the computational complexity associated with exact inference in Bayesian networks by systematically eliminating variables and reusing computations, making it a powerful tool for solving probabilistic queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRkcbEUOFjGR"
      },
      "source": [
        "### Pointwise product\n",
        "\n",
        "The pointwise product operation, commonly used in various algorithms including those for inference in Bayesian networks, is a mathematical operation that combines two or more functions (or tables of values) by multiplying their values together for each corresponding set of variable assignments. Here's a detailed explanation:\n",
        "\n",
        "#### Definition and Context\n",
        "- **Operation:**  The pointwise product of two functions fff and ggg, defined over the same domain or set of variables, is a new function hhh such that for every point xxx in the domain, h(x)=f(x)×g(x)h(x) = f(x) \\times g(x)h(x)=f(x)×g(x).\n",
        "- **Bayesian Networks Context:**  In the context of Bayesian networks and variable elimination algorithms, the pointwise product operation is used to combine factors. A factor is essentially a function over a subset of variables in the network that represents a piece of the joint probability distribution.\n",
        "#### How It Works\n",
        "- **Combining Evidence:**  When performing inference, you often need to combine evidence from different sources or factors. The pointwise product operation allows for this by multiplying the probabilities (or values) associated with the same variable assignments across different factors.\n",
        "- **Resulting Factor:**  The result is a new factor that encapsulates the combined information from the factors being multiplied. This new factor can then be used in subsequent operations, such as summing out variables, to continue the inference process.\n",
        "#### Example\n",
        "\n",
        "Suppose you have two factors in a Bayesian network inference problem:\n",
        "- Factor AAA with variables XXX and YYY, and\n",
        "- Factor BBB with variables YYY and ZZZ.\n",
        "\n",
        "To compute the pointwise product of AAA and BBB, you multiply the values of AAA and BBB for each combination of XXX, YYY, and ZZZ that appears in both factors. The resulting factor CCC will be defined over the variables XXX, YYY, and ZZZ, containing the product of corresponding values from AAA and BBB.\n",
        "#### Importance in Variable Elimination\n",
        "- **Efficiency:**  The pointwise product operation is crucial for the efficiency of the variable elimination algorithm, allowing for the compact representation and manipulation of factors.\n",
        "- **Simplification:**  By combining factors early on, the pointwise product can help reduce the complexity of the factor tables that need to be considered in later steps of the algorithm.\n",
        "- **Flexibility:**  This operation supports the modular combination of information, making it easier to apply the variable elimination algorithm to networks with complex dependencies.\n",
        "\n",
        "In summary, the pointwise product operation is a foundational mathematical tool in probabilistic inference, enabling the effective combination of probabilistic information from different sources within Bayesian networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61x1suqeFjGS"
      },
      "source": [
        "### Operations and Factors\n",
        "\n",
        "**Operations on Factors**  in Bayesian networks explains how factors are manipulated to perform exact inference. Here's a summary based on the provided excerpt​​:\n",
        "- **Pointwise Product Operation:**  This operation combines two factors, fff and ggg, to produce a new factor, hhh. The variables of hhh are the union of the variables in fff and ggg. The value for each entry in hhh is the product of the corresponding entries in fff and ggg.\n",
        "- **Variables in Common:**  If fff and ggg share variables, say Y1Y_1Y1​ to YkY_kYk​, then the operation considers these shared variables in computing the product. The resultant factor, hhh, includes not only the shared variables but also the unique variables from both fff and ggg.\n",
        "- **Illustration with Binary Variables:**  For binary variables, the size of fff and ggg is determined by the number of variables they each involve, with fff having 2j+k2^{j+k}2j+k entries and ggg having 2k+ℓ2^{k+\\ell}2k+ℓ entries. The pointwise product, hhh, consequently has 2j+k+ℓ2^{j+k+\\ell}2j+k+ℓ entries. An example provided shows how the pointwise product of f(XY)f(XY)f(XY) and g(YZ)g(YZ)g(YZ) results in h(XYZ)h(XYZ)h(XYZ) with 8 entries, demonstrating how the operation combines information across factors.\n",
        "- **Complexity Implications:**  The factor resulting from a pointwise product might encompass more variables than either of the original factors, leading to an exponential increase in the size of the factor with respect to the number of variables. This exponential growth highlights a key source of space and time complexity in the variable elimination algorithm used for inference in Bayesian networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_0hzXWKFjGS"
      },
      "source": [
        "### **Variable Ordering and Variable Relevance**\n",
        "- The variable elimination algorithm includes a function to determine the order in which variables are processed. The chosen order impacts the generation of intermediate factors, affecting the computational efficiency of the algorithm.\n",
        "- Different orderings lead to different factors being generated during the calculation. The example given demonstrates that changing the order of variable elimination (e.g., eliminating variable A before E versus another order) results in different intermediate factors and potentially alters the complexity of the computation.\n",
        "- The size of the largest factor generated during variable elimination significantly influences the algorithm's time and space requirements. This size is determined by both the order in which variables are eliminated and the network's structure.\n",
        "- Finding the optimal variable ordering is intractable, but several heuristic methods exist to approximate a good ordering. One effective heuristic is to eliminate variables in a way that minimizes the size of the next factor to be constructed.\n",
        "- The relevance of variables to a query is also discussed. Variables not affecting the query outcome can be considered irrelevant and removed from the network before evaluation. This simplification can lead to significant computational savings.\n",
        "- An example query illustrates that some variables may be entirely irrelevant to the outcome, allowing for their removal and further optimization of the inference process.\n",
        "- Applied to a practical scenario, such as an insurance network, the variable elimination algorithm demonstrates a substantial improvement in efficiency over naive enumeration, highlighting the importance of thoughtful variable ordering and the identification of variable relevance for efficient exact inference in Bayesian networks​​."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVBnIwq-FjGS"
      },
      "source": [
        "### 13.3.3 The Complexity of Exact Inference\"\n",
        "\n",
        "exploring  the inherent difficulties in performing exact inference within Bayesian networks, emphasizing the computational demands of the process.\n",
        "\n",
        "Here are the summarized points:\n",
        "- **Singly Connected Networks:**  In networks with a single undirected path between any two nodes (singly connected networks or polytrees), exact inference is relatively efficient, with time and space complexity linear to the size of the network. This efficiency is due to the limited connectivity, which simplifies the computation.\n",
        "- **Multiply Connected Networks:**  For networks with multiple connections between nodes, the complexity of exact inference can exponentially increase, even if the number of parents per node is limited. This complexity arises from the need to consider multiple paths and interactions between nodes, leading to a significant increase in computational demands.\n",
        "- **NP-Hardness:**  Exact inference in Bayesian networks encompasses inference in propositional logic, making it NP-hard. This complexity implies that there's no polynomial-time solution for all cases of the problem, highlighting the computational challenges in dealing with large or highly connected networks.\n",
        "- **SAT Problems and Bayes Nets:**  The section discusses the relationship between satisfiability problems in propositional logic (SAT problems) and Bayesian network inference. By encoding a SAT problem as a Bayesian network, one can use inference in the network to solve the SAT problem, further illustrating the computational complexity of exact inference in Bayesian networks.\n",
        "- **Tree Width and Complexity:**  The concept of tree width is introduced as a measure of a network's complexity. Networks with a small tree width (more tree-like) can be easier to solve, whereas networks with large tree width present greater computational challenges.\n",
        "\n",
        "This subsection underscores the significant computational hurdles in performing exact inference in Bayesian networks, particularly in complex or highly connected networks. It highlights the importance of finding efficient algorithms and heuristics for practical applications, given the NP-hard nature of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYFNT3cUFjGS"
      },
      "source": [
        "### Weighted Model Counting - WMC\n",
        "\n",
        "Weighted model counting (WMC) is a computational problem that involves counting the number of satisfying assignments to a Boolean formula, where each assignment is assigned a weight. This problem is a generalization of the well-known model counting problem, which aims to count the number of satisfying assignments to a Boolean formula without considering weights.\n",
        "\n",
        "- Weighted model counting (WMC) is a technique used in various fields, including artificial intelligence, for solving problems that can be represented as propositional logic formulas. It's particularly useful in probabilistic reasoning, where it serves as a foundation for performing exact inference in Bayesian networks and other probabilistic graphical models. Here's a detailed explanation:\n",
        "#### Basic Concept\n",
        "- **Model Counting:**  At its core, model counting involves determining the number of satisfying assignments (models) for a given logical formula. For example, given a formula in propositional logic, model counting aims to find how many different ways the variables can be assigned true or false values such that the formula evaluates to true.\n",
        "- **Weighted Model Counting:**  WMC extends this concept by assigning weights to each variable assignment, allowing for the incorporation of probabilities or costs. The goal then becomes to compute the sum of the weights of all satisfying assignments, effectively combining the concepts of counting and weighting to capture the significance of each model.\n",
        "#### Application in Probabilistic Inference\n",
        "- **Bayesian Networks:**  In the context of Bayesian networks, weighted model counting can be used to compute the probability of certain events. Each variable assignment in the network is considered a model, and the weights correspond to the probabilities of these assignments. WMC enables the calculation of marginal probabilities and other queries by summing over the weights of all models that satisfy the query conditions.\n",
        "- **Efficiency:**  WMC provides a systematic way to handle the exponential number of possible variable assignments in large probabilistic models. By exploiting structure and decomposability in the models, as well as employing efficient algorithms and data structures, WMC can sometimes perform exact inference more efficiently than naive enumeration methods.\n",
        "#### Techniques and Tools\n",
        "- **Algorithms:**  Several algorithms and frameworks have been developed to perform WMC efficiently, often utilizing techniques from satisfiability checking (SAT solving) and its weighted extension, #SAT (sharp-SAT) solving.\n",
        "- **Software:**  Tools like Cachet, SharpSAT, and others implement these algorithms, enabling the application of WMC to practical problems in AI, such as probabilistic reasoning, planning, and decision making under uncertainty.\n",
        "#### Challenges and Limitations\n",
        "- **Complexity:**  Despite advances, the computational complexity of WMC remains a challenge for very large or complex networks, as the problem is inherently intractable for general cases.\n",
        "- **Approximations:**  For some applications, approximate methods or sampling-based approaches (e.g., Monte Carlo methods) may be used when exact WMC is computationally prohibitive.\n",
        "\n",
        "In summary, weighted model counting is a powerful tool in the arsenal of techniques for probabilistic inference, offering a principled way to compute probabilities and make decisions based on complex models with uncertainty. Its effectiveness in practice depends on the problem structure, the efficiency of algorithms, and the computational resources available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUd86N52FjGS"
      },
      "source": [
        "### 13.3.4 Clustering Algorithms**  \n",
        "- **Efficiency for Multiple Queries:**  While the variable elimination algorithm is effective for individual queries, its efficiency decreases when computing posterior probabilities for all variables within a network. In polytree networks, for instance, this process could require O(n2)O(n^2)O(n2) time. Clustering algorithms, also known as join tree algorithms, reduce this time to O(n)O(n)O(n), making them a popular choice in commercial Bayesian network tools.\n",
        "- **Formation of Cluster Nodes:**  The fundamental concept behind clustering involves merging individual nodes into cluster nodes to form a polytree structure. An example provided is the transformation of a multiply connected network into a polytree by merging the Sprinkler and Rain nodes into a single cluster node called Sprinkler+Rain.\n",
        "- **Example Network:**  The example network illustrates daily routines and how the weather influences whether the grass gets wet through different causal pathways. By clustering, the network simplifies the representation of these relationships.\n",
        "- **Meganodes and Special-Purpose Inference:**  The clustering process can create meganodes that encompass multiple variable states, necessitating a specialized inference algorithm capable of managing meganodes that share variables. This approach resembles constraint propagation, where the algorithm ensures consistency in the posterior probabilities of shared variables across neighboring meganodes.\n",
        "- **Computational Considerations:**  While clustering algorithms enhance efficiency, they do not eliminate the inherent NP-hardness of the problem. If variable elimination requires exponential time and space, the conditional probability tables (CPTs) within the clustered network will also be exponentially large, indicating that computational challenges remain for networks necessitating extensive computations​​.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luW7r1AGFjGS"
      },
      "source": [
        "## 13.4 Approximate Inference for Bayesian Networks**\n",
        "\n",
        "This section discusses strategies for approximate inference in Bayesian networks, acknowledging that exact inference is often computationally infeasible for large networks. Here are the key points:\n",
        "- **Challenges with Exact Inference:**  Exact inference methods, such as variable elimination and junction tree algorithms, can be prohibitively expensive in terms of computational resources for complex networks.\n",
        "- **Necessity for Approximation:**  Given these challenges, approximate inference methods provide practical solutions for obtaining useful, though not exact, probabilities from Bayesian networks.\n",
        "- **Stochastic Sampling:**  One approach to approximate inference involves stochastic sampling, where samples are drawn from the network according to some strategy, and these samples are then used to estimate probabilities. Methods include:\n",
        "- **Likelihood Weighting:**  Directly samples evidence variables and weights each sample by the likelihood of the evidence given the sample.\n",
        "- **Gibbs Sampling (Markov Chain Monte Carlo):**  A special case of Metropolis-Hastings sampling that generates samples from the posterior distribution by iteratively sampling each variable conditioned on the current values of the other variables.\n",
        "- **Deterministic Approximations:**  Another approach uses deterministic algorithms to approximate the posterior distributions without sampling. These include:\n",
        "- **Variational Methods:**  Approximate the true posterior distribution by a simpler distribution, optimizing parameters to make the approximation as close as possible.\n",
        "- **Expectation Propagation:**  Iteratively refines a set of approximate distributions to more closely match the target posterior distribution.\n",
        "- **Trade-offs and Considerations:**  While approximate methods can significantly reduce computational demands, they introduce trade-offs between accuracy, computational efficiency, and the ease of implementation. The choice of method depends on the specific requirements of the application, including the acceptable level of approximation error and the available computational resources.\n",
        "- **Applications:**  These methods are widely used in various fields, such as machine learning, statistical physics, and bioinformatics, where they support reasoning under uncertainty, parameter estimation, and prediction in the presence of complex, probabilistic models.\n",
        "\n",
        "This section underscores the importance of approximate inference in practical applications of Bayesian networks, highlighting the balance between computational feasibility and the accuracy of probabilistic estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO365HXcFjGT"
      },
      "source": [
        "### 13.4.1 Direct sampling methods\n",
        "\n",
        "This section introduces direct sampling methods for approximate inference in Bayesian networks, focusing on likelihood weighting and Gibbs sampling. Here are the key points:\n",
        "\n",
        "- **Likelihood Weighting:**  This method involves generating samples from the Bayesian network by setting the evidence variables to their observed values and then sampling the remaining variables according to the network's conditional probabilities. Each sample is weighted by the likelihood of the evidence given the sample, providing an estimate of the posterior distribution.\n",
        "- **Gibbs Sampling:**  Gibbs sampling is a Markov Chain Monte Carlo (MCMC) method that iteratively samples each variable in the network conditioned on the current values of the other variables. This process generates a sequence of samples that converges to the true posterior distribution, allowing for approximate inference in complex networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy5hMeIYFjGT"
      },
      "source": [
        "### Rejection Sampling\n",
        "\n",
        "Rejection sampling is a technique used to generate samples from a target probability distribution, especially when the distribution is complex or high-dimensional. Here's a summary of the key points:\n",
        "\n",
        "#### Basic Concept\n",
        "\n",
        "- **Objective:**  The primary goal of rejection sampling is to generate samples from a target probability distribution, which may be difficult to sample directly due to its complexity or high dimensionality.\n",
        "\n",
        "- **Sampling Process:**  The process involves generating samples from a proposal distribution, which is a simpler distribution that can be sampled more easily. These samples are then accepted or rejected based on whether they fall within the target distribution.\n",
        "\n",
        "- **Acceptance Criterion:**  Each sample is accepted with a probability proportional to the ratio of the target distribution to the proposal distribution at the sample's location. This ratio serves as the acceptance criterion, determining whether a sample is retained.\n",
        "\n",
        "#### Algorithm and Steps\n",
        "\n",
        "- **Algorithm:**  The rejection sampling algorithm consists of the following steps:\n",
        "  - Generate a sample from the proposal distribution.\n",
        "  - Evaluate the acceptance probability for the sample based on the ratio of the target distribution to the proposal distribution.\n",
        "  - Accept the sample with the calculated probability, or reject it otherwise.\n",
        "  - Repeat the process to generate a sufficient number of accepted samples.\n",
        "\n",
        "- **Efficiency and Limitations:**  Rejection sampling can be inefficient when the acceptance rate is low, especially if the target distribution has heavy tails or is sparsely distributed. In such cases, a large number of samples may be required to obtain a sufficient number of accepted samples.\n",
        "\n",
        "#### Applications and Variants\n",
        "\n",
        "- **Probabilistic Inference:**  Rejection sampling is used in probabilistic inference, including Bayesian networks and other probabilistic graphical models, to estimate posterior probabilities and perform approximate inference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I1bspRyFjGT"
      },
      "source": [
        "### Rejection Sampling algorithm\n",
        "\n",
        "pseudo-code for the rejection-sampling algorithm for answering queries given evidence in a Bayesian network, as depicted in Figure 13.17 from \"Artificial Intelligence: A Modern Approach\" by Stuart Russell and Peter Norvig​​:\n",
        "\n",
        "```plaintext\n",
        "function REJECTION-SAMPLING(X, e, bn, N) returns an estimate of P(X | e)\n",
        "inputs:\n",
        "    X, the query variable\n",
        "    e, observed values for variables E\n",
        "    bn, a Bayesian network\n",
        "    N, the total number of samples to be generated\n",
        "local variables:\n",
        "    C, a vector of counts for each value of X, initially zero\n",
        "\n",
        "for j = 1 to N do\n",
        "    x ← PRIOR-SAMPLE(bn)\n",
        "    if x is consistent with e then\n",
        "        C[xj] ← C[xj] + 1 where xj is the value of X in x\n",
        "return NORMALIZE(C)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "This algorithm aims to estimate P(X∣e)P(X | e)P(X∣e) by generating samples from the prior distribution specified by the Bayesian network (`bn`), rejecting those samples that do not match the observed evidence (`e`), and counting how often each value of the query variable (`X`) occurs in the samples that are consistent with the evidence. The final estimate is obtained by normalizing the count vector `C`, which tallies the occurrences of each value of `X` among the accepted samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEDYSCRFjGT"
      },
      "source": [
        "### Importance Sampling\n",
        "\n",
        "Importance sampling is an advanced technique used in approximate inference for Bayesian networks, designed to address some of the inefficiencies inherent in simpler sampling methods like rejection sampling. It is particularly useful for estimating probabilities and expectations in complex probabilistic models where direct sampling is challenging due to the presence of rare events or evidence. Here's an overview of how importance sampling works and its application in Bayesian networks:\n",
        "#### Basic Concept\n",
        "- **Weighted Sampling:**  Instead of sampling directly from the joint distribution of the Bayesian network, importance sampling draws samples from a proposal distribution that is easier to sample from and more likely to produce relevant samples (i.e., samples consistent with the evidence).\n",
        "- **Weights:**  Each sample is assigned a weight based on how probable the sample is in the actual distribution relative to the proposal distribution. These weights adjust for the fact that the sampling distribution is not the same as the target distribution.\n",
        "#### Procedure\n",
        "1. **Choose a Proposal Distribution:**  Select a distribution from which to draw samples. Ideally, this distribution should be similar to the target distribution but more likely to generate samples consistent with the evidence.\n",
        "2. **Generate Samples:**  Draw samples from the proposal distribution rather than the target distribution.\n",
        "3. **Calculate Weights:**  For each sample, calculate a weight that represents the ratio of the probability of the sample under the target distribution to its probability under the proposal distribution. This involves evaluating the likelihood of the evidence given the sample in the context of the Bayesian network.\n",
        "4. **Estimate Probabilities:**  Use the weighted samples to estimate the desired probabilities. Estimates are computed by summing the weights of samples that meet certain criteria (e.g., a query variable taking a specific value) and normalizing by the total weight of all samples.\n",
        "#### Advantages\n",
        "- **Efficiency:**  Importance sampling can be much more efficient than rejection sampling, especially when the evidence is rare. By using a proposal distribution that is more likely to produce relevant samples, it reduces the variance of the estimate and requires fewer samples to achieve an accurate approximation.\n",
        "- **Flexibility:**  The method allows for considerable flexibility in choosing the proposal distribution, enabling the algorithm to be tailored to the specifics of the Bayesian network and the evidence.\n",
        "#### Limitations\n",
        "- **Choice of Proposal Distribution:**  The effectiveness of importance sampling heavily depends on the choice of the proposal distribution. A poor choice can lead to high variance in the weights and inefficient sampling.\n",
        "- **Weight Degeneration:**  In some cases, a few samples may end up with very high weights, dominating the estimate and leading to high variance. This situation, known as weight degeneration, can reduce the effectiveness of importance sampling.\n",
        "\n",
        "In summary, importance sampling is a powerful technique for approximate inference in Bayesian networks, offering a more efficient alternative to direct sampling methods for complex models. Its success relies on the careful selection of a proposal distribution that increases the likelihood of sampling relevant instances, making it a valuable tool for probabilistic reasoning in situations where exact inference is infeasible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzYIz1ZQFjGT"
      },
      "source": [
        "### 13.4.2 Inference by Markov Chain Simulation**  \n",
        "- **Markov Chain Monte Carlo (MCMC) Methods:**  Unlike simpler sampling methods, MCMC techniques generate samples by making random changes to the previous sample, creating a Markov chain where each state (sample) is derived from the last.\n",
        "- **Gibbs Sampling:**  A specific MCMC method well-suited for Bayesian networks. It begins with an arbitrary state (with evidence variables fixed) and generates new states by randomly changing the values of non-evidence variables. Each variable is sampled based on its Markov blanket, ensuring the process respects the dependencies within the network.\n",
        "- **Characteristics of Gibbs Sampling:**\n",
        "- Operates by randomly moving through the state space, flipping one variable at a time while keeping evidence variables constant.\n",
        "- The algorithm's efficiency is highlighted by its simplicity in implementation and its ability to generate samples that approximate the true posterior distribution over time.\n",
        "- **Convergence and Ergodicity:**  For Gibbs sampling to be effective, the Markov chain it generates must be ergodic, meaning every state is reachable from every other, and there are no cycles. This ensures that, given enough time, the sampling process will explore the entire state space sufficiently.\n",
        "- **Efficiency and Limitations:**\n",
        "- Each step in Gibbs sampling involves calculations based only on a variable's Markov blanket, making the process relatively efficient.\n",
        "- The convergence rate, or how quickly Gibbs sampling approximates the true distribution, can vary greatly depending on the network's structure and the distributions involved. In some cases, deterministic relationships or specific network configurations can slow convergence significantly.\n",
        "- **Metropolis-Hastings Algorithm:**  Another MCMC method that allows for greater flexibility in sample generation. It proposes new states from a specified distribution and accepts or rejects these based on a calculated acceptance probability, ensuring that the samples eventually conform to the target distribution.\n",
        "- **Advantages of MCMC Methods:**\n",
        "- They provide a powerful tool for approximate inference in cases where exact calculation is impractical.\n",
        "- These methods are particularly useful for dealing with high-dimensional spaces and complex dependency structures typical of Bayesian networks.\n",
        "- **Challenges:**\n",
        "- The choice of proposal distribution in Metropolis-Hastings and the initial state in Gibbs sampling can significantly affect performance.\n",
        "- Ensuring efficient exploration of the state space and convergence to the true distribution requires careful algorithm design and understanding of the underlying probabilistic model.\n",
        "\n",
        "MCMC methods, including Gibbs sampling and Metropolis-Hastings, offer robust frameworks for approximate inference in Bayesian networks, allowing for the estimation of posterior distributions even in complex models where direct sampling and exact inference are not feasible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k16d_vhBFjGT"
      },
      "source": [
        "### Why Gibbs Sampling works\n",
        "\n",
        "**Why Gibbs Sampling Works**  \n",
        "- **Consistent Estimates:**  Gibbs sampling provides consistent estimates for posterior probabilities. Its stationary distribution precisely matches the posterior distribution for non-evidence variables based on the given evidence, a result of the method's state transition strategy.\n",
        "- **Sampling Method:**  In Gibbs sampling, a variable XiX_iXi​ is chosen and then sampled conditionally on the current values of all other variables. This is equivalent to sampling based on the variable's Markov blanket in Bayesian networks, ensuring that each sample reflects the influence of directly related variables.\n",
        "- **Transition Kernel Cases:**  The transition kernel k(x→x′)k(x \\rightarrow x')k(x→x′) in Gibbs sampling considers three scenarios:\n",
        "1. No transition if xxx and x′x'x′ differ in two or more variables since Gibbs sampling only alters one variable at a time.\n",
        "2. A specific transition probability if xxx and x′x'x′ differ in exactly one variable, based on the conditional probability of the new value given the current state.\n",
        "3. A calculation for the probability of staying in the same state if no variable changes, summing the probabilities of choosing any variable and sampling its current value.\n",
        "- **Detailed Balance and Stationarity:**  Gibbs sampling satisfies the detailed balance condition, ensuring that the transition probabilities between any two states xxx and x′x'x′ are balanced in such a way that π(x)k(x→x′)=π(x′)k(x′→x)π(x)k(x \\rightarrow x') = π(x')k(x' \\rightarrow x)π(x)k(x→x′)=π(x′)k(x′→x), where π(x)π(x)π(x) is the true posterior distribution P(x∣e)P(x|e)P(x∣e).\n",
        "- **Ergodicity:**  The algorithm is ergodic, meaning every state is reachable from any other state, and there are no perpetual cycles. This is critical for ensuring that the sampling process covers the entire state space over time, allowing the Gibbs sampling to accurately reflect the posterior distribution.\n",
        "- **Efficiency and Convergence:**  Given that the conditional probability tables (CPTs) avoid absolute certainties (probabilities of 0 or 1), Gibbs sampling efficiently transitions between states, ensuring that, over time, samples are representative of the true posterior distribution. This reachability and absence of cycles confirm the method's ability to converge to accurate posterior estimates.\n",
        "\n",
        "This section underscores Gibbs sampling's effectiveness in Bayesian network inference, highlighting its mathematical foundation and practical implications for generating reliable posterior probability estimates​​."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuTBxfmsFjGT"
      },
      "source": [
        "### Metroplis-Hastings Algorithm\n",
        "\n",
        "- The Metropolis–Hastings (MH) sampling method is a broadly applicable Markov Chain Monte Carlo (MCMC) algorithm used for generating samples from a probability distribution. It is designed to sample from distributions difficult to sample directly, making it particularly useful for inference in Bayesian networks. Here's a summary of how the MH sampling works:\n",
        "1. **Proposal Distribution:**  The algorithm starts with a current state and proposes a new state based on a proposal distribution q(x′∣x)q(x'|x)q(x′∣x), where x′x'x′ is the proposed new state and xxx is the current state.\n",
        "2. **Acceptance Probability:**  The new state x′x'x′ is accepted with a probability a(x′∣x)=min⁡(1,π(x′)q(x∣x′)π(x)q(x′∣x))a(x'|x) = \\min\\left(1, \\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)a(x′∣x)=min(1,π(x)q(x′∣x)π(x′)q(x∣x′)​), where π(x)\\pi(x)π(x) is the target probability distribution of the state xxx, and qqq is the proposal distribution. This ensures that the chain has the desired stationary distribution.\n",
        "3. **Rejection:**  If the proposed state x′x'x′ is rejected, the algorithm remains in the current state xxx, and this counts as another sample of xxx.\n",
        "\n",
        "The MH algorithm guarantees convergence to the correct stationary distribution for any choice of proposal distribution, provided the Markov chain is ergodic, meaning every state is reachable from every other state, and there are no periodic cycles. This property is assured by the design of the acceptance probability, which ensures detailed balance—a condition necessary for the stationary distribution of the chain to match the target distribution.\n",
        "\n",
        "The choice of the proposal distribution is crucial for the efficiency of the MH algorithm. A well-chosen proposal can lead to faster convergence and more efficient sampling, particularly in high-dimensional spaces or complex distributions common in Bayesian networks.\n",
        "\n",
        "The MH sampling method is celebrated for its flexibility and broad applicability, making it a foundational tool in Bayesian inference, statistical physics, and other domains requiring efficient sampling from complex distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK3gr30FjGX"
      },
      "source": [
        "## 13.5 Causal Networks**\n",
        "\n",
        "This section delves into causal networks, highlighting their construction, benefits, and applications, especially in decision-making contexts. Here's a summary of the key points:\n",
        "- **Causation vs. Correlation:**  While Bayesian networks are powerful for representing probabilistic dependencies, they do not inherently distinguish between causation and correlation. Causal networks, a subset of Bayesian networks, are designed to represent causal relationships explicitly.\n",
        "- **Construction and Ordering:**  Causal networks enforce a causally compatible ordering of nodes, enhancing the ease of assessing conditional probabilities and the compactness of the network. Despite any node ordering allowing for a consistent joint distribution representation, causal networks prefer orderings that align with the direction of causation.\n",
        "- **Causal Relationships:**  The section illustrates the fundamental difference between merely probabilistic dependencies and causal relationships. For example, reversing the direction of arrows in a Bayesian network (e.g., from Fire → Smoke to Smoke → Fire) does not change the joint distribution it represents, but it fails to capture the causal nature of the relationship.\n",
        "- **Causal Diagrams:**  Causal Bayesian networks, or causal diagrams, are introduced as tools to represent and reason with causal information. They rely on more than just probabilistic dependence, asking which variables causally influence others. This is formalized through structural equations representing stable mechanisms in nature.\n",
        "- **Representing Interventions:**  The section discusses how causal networks can represent interventions (actions that change the system) using the \"do-operator\". This allows for modeling how changes in one part of the system (e.g., turning on a sprinkler) directly affect other parts, independent of their normal probabilistic relationships.\n",
        "- **Stability and Local Changes:**  Causal networks' representation of mechanisms as structural equations highlights their stability against local changes. This makes them particularly useful for modeling interventions and understanding their effects on the system.\n",
        "- **Decision Making:**  The ability to model and reason about interventions makes causal networks invaluable for decision-making tasks. They provide a framework for predicting the outcomes of actions, offering insights that go beyond what is possible with standard Bayesian networks.\n",
        "\n",
        "This section underscores the importance of distinguishing between causation and correlation in probabilistic reasoning and demonstrates how causal networks facilitate a deeper understanding of causal relationships and their implications for decision-making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z0xZBGOFjGY"
      },
      "source": [
        "### Structural Equation\n",
        "\n",
        "- Structural equations are a mathematical representation used to model and analyze relationships between variables, particularly in the context of causal inference and structural equation modeling (SEM). They are central to understanding the causal structure of systems in various fields, including economics, sociology, psychology, and epidemiology. Here's an overview of structural equations and their significance:\n",
        "#### Definition\n",
        "- **Structural Equation:**  A structural equation expresses how one variable (the dependent variable) is generated by one or more other variables (independent variables) and an error term. The equation is typically linear but can also be nonlinear. The form of a simple linear structural equation for variable YYY might be Y=β0+β1X+ϵY = \\beta_0 + \\beta_1X + \\epsilonY=β0​+β1​X+ϵ, where:\n",
        "- YYY is the dependent variable,\n",
        "- XXX is an independent variable,\n",
        "- β0\\beta_0β0​ and β1\\beta_1β1​ are coefficients representing the intercept and the effect of XXX on YYY, respectively,\n",
        "- ϵ\\epsilonϵ represents the error term, capturing unmodeled influences on YYY.\n",
        "#### Components\n",
        "- **Independent Variables:**  These are the variables that influence or cause changes in other variables. They can be observed quantities, latent factors, or even interventions in experimental designs.\n",
        "- **Dependent Variables:**  These are the variables being influenced or caused by the independent variables. The relationship is specified by the structural equation.\n",
        "- **Coefficients:**  These quantify the strength and direction of the influence between variables. They are key to interpreting the relationships in the model.\n",
        "- **Error Term:**  This captures all other factors influencing the dependent variable that are not explicitly modeled by the independent variables.\n",
        "#### Usage\n",
        "- **Causal Inference:**  Structural equations form the basis of models that aim to infer causal relationships rather than just associations. They allow researchers to explicitly model and test theories about how variables interact causally.\n",
        "- **Structural Equation Modeling (SEM):**  SEM is a comprehensive statistical approach that involves constructing complex models composed of multiple structural equations. These models can include both observed and latent (unobserved) variables, allowing for the analysis of intricate causal structures.\n",
        "#### Advantages\n",
        "- **Flexibility:**  Structural equations can model complex relationships, including mediated effects, moderation, and feedback loops.\n",
        "- **Causal Interpretation:**  When correctly specified, structural equations can provide insights into causal mechanisms, not just correlations.\n",
        "#### Considerations\n",
        "- **Identification:**  A key challenge in working with structural equations is ensuring that the model is identifiable, meaning that there is enough information in the data to estimate all the model parameters uniquely.\n",
        "- **Assumptions:**  The causal interpretations derived from structural equations rely heavily on the model's assumptions, including the absence of unmeasured confounders and the correct specification of the causal structure.\n",
        "\n",
        "In summary, structural equations are a powerful tool for modeling the causal relationships between variables. They are foundational to SEM and are crucial for advancing understanding in areas where causal mechanisms are of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCljYUGpFjGY"
      },
      "source": [
        "### 13.5.1 Representing Actions: The Do-Operator**\n",
        "\n",
        "This section discusses the conceptual framework for modeling actions within Bayesian networks, particularly through the use of the \"do-operator\" as part of the causal inference theory. Here are the key points:\n",
        "- **Structural Equations and Bayesian Networks:**  The discussion begins with an illustration of how Bayesian networks encode causal relationships through structural equations. These equations describe how each variable in a network (e.g., the presence of rain or a sprinkler system's status) is determined by its causes, along with some unmodeled factors (error terms) that capture additional influences not explicitly modeled​​.\n",
        "- **Introducing the Do-Operator:**  The do-operator is presented as a formalism for representing interventions within a causal model. An intervention, such as turning the sprinkler on (do(Sprinkler = true)), modifies the causal structure by setting the value of a variable directly, rather than through its causal inputs. This action effectively \"mutilates\" the network by removing the variable's dependencies on its parents, reflecting the imposition of a condition from outside the system​​.\n",
        "- **Implications of Interventions:**  The section elaborates on how interventions affect the joint distribution of variables in the network. By applying the do-operator, one can compute the new distribution of outcomes, taking into account the direct effects of the intervention while ignoring the original causal pathways that would normally determine the intervened variable's value. For instance, turning the sprinkler on directly influences the wetness of the grass without considering whether it was a cloudy day, fundamentally altering the relationships within the network​​.\n",
        "- **Contrast with Observation:**  A crucial distinction is made between observing an outcome (e.g., the sprinkler being on) and actively intervening to bring about that outcome. Observations can inform about the state of the world and influence beliefs about causally related variables (e.g., the likelihood of it being a cloudy day), whereas interventions directly change the state of the world without providing new information about the pre-existing causal structure. This difference is critical for understanding causal effects and is a key contribution of the do-operator to causal reasoning​​.\n",
        "\n",
        "In essence, the do-operator formalizes the notion of intervention within causal models, enabling the analysis of actions' effects on systems represented by Bayesian networks. It allows for distinguishing between mere observations and active manipulations, a fundamental aspect of causal inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8ZpTC4FjGY"
      },
      "source": [
        "### 13.5.2 The Back-door Criterion\n",
        "- **Concept:**  The back-door criterion is a rule for identifying sets of variables in a causal diagram (Bayesian network) that, if conditioned on, allow for the estimation of the causal effect of one variable on another, effectively blocking \"back-door\" paths that could introduce spurious correlations.\n",
        "- **Criteria:**  A set of variables Z satisfies the back-door criterion relative to an ordered pair of variables (X, Y) if no node in Z is a descendant of X, and Z blocks every path between X and Y that contains an arrow into X.\n",
        "- **Application:**  By conditioning on a set of variables that satisfy the back-door criterion, one can estimate the causal effect of X on Y from observational data, assuming the model accurately reflects the causal structure of the system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlI1sn-uFjGY"
      },
      "source": [
        "## Chapter Summary\n",
        "\n",
        "- This chapter provides a comprehensive overview of Bayesian networks, emphasizing their significance in representing uncertain knowledge, analogous to the role of propositional logic for definite knowledge. Here's a summary of the key points:\n",
        "- **Bayesian Networks Structure:**  These are directed acyclic graphs where nodes represent random variables, each associated with a conditional distribution given its parent nodes. This structure enables the concise representation of conditional independence relationships within the domain.\n",
        "- **Joint Probability Distribution:**  Bayesian networks specify a joint probability distribution for all their variables. The probability of any assignment to all variables is the product of the entries in the local conditional distributions, making the network size often exponentially smaller than a fully enumerated joint distribution.\n",
        "- **Compact Representation of Distributions:**  Conditional distributions within Bayesian networks can often be efficiently represented using canonical distribution families. Hybrid networks, which include both discrete and continuous variables, utilize these canonical forms to manage complexity.\n",
        "- **Inference in Bayesian Networks:**  The process involves computing the probability distribution for a set of query variables, given evidence. Exact inference algorithms like variable elimination aim to perform these computations as efficiently as possible, though the task becomes intractable in non-polytree (multiply connected) networks.\n",
        "- **Efficiency and Intractability:**  While exact inference is linear in time for polytrees, it is generally intractable for more complex networks. However, approximate techniques such as likelihood weighting and Markov chain Monte Carlo (MCMC) methods can provide reasonable estimates for posterior probabilities in larger networks.\n",
        "- **Causal Networks:**  Beyond capturing probabilistic influences, causal networks delineate causal relationships, enabling predictions about the effects of interventions in addition to mere observations.\n",
        "\n",
        "This summary encapsulates the foundational aspects of Bayesian networks, their operational mechanisms for representing and inferring uncertain knowledge, and their extension into causal analysis, highlighting both their theoretical importance and practical applications in AI and statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz5e99dkFjGY"
      },
      "source": [
        "## Bibliographical and Historical Notes\n",
        "\n",
        "- **Early 20th Century:**  Sewall Wright's work on genetic inheritance and animal growth factors (1921, 1934) marks the early use of networks to represent probabilistic information.\n",
        "- **1961:**  I.J. Good, in collaboration with Alan Turing, developed probabilistic representations and Bayesian inference methods, a precursor to modern Bayesian networks.\n",
        "- **1970s-1980s:**  Development of the influence diagram representation for decision problems and Judea Pearl's message-passing method for inference in tree and polytree networks.\n",
        "- **Mid-1980s:**  Boom in rule-based expert systems with ad hoc methods for handling uncertainty. Peter Cheeseman's defense of probability (1985) and subsequent work contributed to a shift back towards probabilistic approaches.\n",
        "- **1988:**  Judea Pearl's book, \"Probabilistic Reasoning in Intelligent Systems,\" outlined representational issues and algorithmic approaches, significantly influencing the field.\n",
        "- **1990s:**  Expansion into hybrid Bayesian networks with both discrete and continuous variables, and the application of Bayesian networks in various domains such as medicine, engineering, and genetics.\n",
        "- **Key Algorithms and Developments:**\n",
        "- Clustering algorithm by Pearl (1986) for exact inference in general networks.\n",
        "- Variable elimination algorithm developed by Zhang and Poole (1994).\n",
        "- Importance of conditional independence and the \"Bayes-ball\" algorithm by Shachter (1998).\n",
        "- **Applications:**\n",
        "- Early medical applications like the MUNIN system (Andersen et al., 1989) and the PATHFINDER system (Heckerman, 1991).\n",
        "- Engineering applications, including NASA's work on displaying time-critical information (Horvitz and Barry, 1995).\n",
        "- Diagnostic modules in Microsoft Windows and Office Assistant (Breese and Heckerman, 1996; Horvitz et al., 1998).\n",
        "- **Causal Inference:**\n",
        "- Contributions to theories of causal inference by Rubin (1974), Robins (1986), and a fully articulated theory by Judea Pearl (2000).\n",
        "- **Recent Advances:**  Continued development of approximation algorithms, importance sampling innovations, and the application of Markov chain Monte Carlo (MCMC) algorithms.\n",
        "- **Variational Methods and Loopy Belief Propagation:**  Highlighting the role of variational approximation methods and the application of loopy belief propagation in statistical physics and Bayesian statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy1DWZuqFjGY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bobenUAfFjGZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9Ugu9WFjGZ"
      },
      "source": [
        "## External Sources\n",
        "\n",
        "* https://web.stanford.edu/class/archive/cs/cs221/cs221.1196/lectures/bayes1.pdf - Stanford University - CS221: Artificial Intelligence: Principles and Techniques - Lecture Slides.\n",
        "\n",
        "* https://courses.engr.illinois.edu/ece448/sp2020/slides/lec15.pdf - University of Illinois at Urbana-Champaign - ECE 448: Introduction to Artificial Intelligence - Lecture Slides.\n",
        "\n",
        "* https://www.bayesserver.com/docs/introduction/bayesian-networks/ - Bayes Server Documentation - software is paid, but documentation is free."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSXAcstFjGZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhQGC3n8FjGZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq5QoAGTFjGZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMm1XOhdFjGZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7da6bab7"
      },
      "source": [
        "# Task\n",
        "Simulate a Bayesian network for a burglar alarm system based on the following probabilities:\n",
        "*   **Prior Probabilities:**\n",
        "    *   `P(Burglary=True) = 0.001`\n",
        "    *   `P(Earthquake=True) = 0.002`\n",
        "*   **Conditional Probabilities for Alarm:**\n",
        "    *   `P(Alarm=True | Burglary=True, Earthquake=True) = 0.95`\n",
        "    *   `P(Alarm=True | Burglary=True, Earthquake=False) = 0.94`\n",
        "    *   `P(Alarm=True | Burglary=False, Earthquake=True) = 0.29`\n",
        "    *   `P(Alarm=True | Burglary=False, Earthquake=False) = 0.001`\n",
        "*   **Conditional Probabilities for JohnCalls:**\n",
        "    *   `P(JohnCalls=True | Alarm=True) = 0.90`\n",
        "    *   `P(JohnCalls=True | Alarm=False) = 0.05`\n",
        "*   **Conditional Probabilities for MaryCalls:**\n",
        "    *   `P(MaryCalls=True | Alarm=True) = 0.70`\n",
        "    *   `P(MaryCalls=True | Alarm=False) = 0.01`\n",
        "\n",
        "The simulation should run for 100,000 iterations. After the simulation, report the observed frequencies for each individual event (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) and the following conditional probabilities:\n",
        "*   `P(Burglary=True | JohnCalls=True, MaryCalls=True)`\n",
        "*   `P(Alarm=True | JohnCalls=True, MaryCalls=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ce08d70"
      },
      "source": [
        "## Define Probabilities\n",
        "\n",
        "### Subtask:\n",
        "Define the prior and conditional probabilities for Burglary, Earthquake, Alarm, JohnCalls, and MaryCalls based on the user's prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b60e3a50"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the prior and conditional probabilities for the Bayesian network variables (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) using Python variables. I will extract the probability values from the provided notebook content and common AIMA examples to define these.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9455ed2",
        "outputId": "3e35475b-1d93-4cfb-a485-85593f0981b1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Define Python variables for the prior probabilities of 'Burglary' and 'Earthquake'.\n",
        "# These are standard values often used in the AIMA Burglar Alarm example.\n",
        "p_burglary = 0.001\n",
        "p_earthquake = 0.002\n",
        "\n",
        "# 2. Define Python variables to store the conditional probabilities for 'Alarm'\n",
        "# given the states of 'Burglary' and 'Earthquake'.\n",
        "# Values for Alarm CPT are directly from the notebook's example in cell JHUSPCkzFjGO.\n",
        "p_alarm_given_be = {\n",
        "    (True, True): 0.95,  # P(Alarm=True | Burglary=True, Earthquake=True)\n",
        "    (True, False): 0.94, # P(Alarm=True | Burglary=True, Earthquake=False)\n",
        "    (False, True): 0.29, # P(Alarm=True | Burglary=False, Earthquake=True)\n",
        "    (False, False): 0.001 # P(Alarm=True | Burglary=False, Earthquake=False)\n",
        "}\n",
        "\n",
        "# 3. Define Python variables for the conditional probabilities of 'JohnCalls' given 'Alarm'.\n",
        "# These are standard values often used in the AIMA Burglar Alarm example.\n",
        "p_johncalls_given_a = {\n",
        "    True: 0.90,  # P(JohnCalls=True | Alarm=True)\n",
        "    False: 0.05   # P(JohnCalls=True | Alarm=False)\n",
        "}\n",
        "\n",
        "# 4. Define Python variables for the conditional probabilities of 'MaryCalls' given 'Alarm'.\n",
        "# These are standard values often used in the AIMA Burglar Alarm example.\n",
        "p_marycalls_given_a = {\n",
        "    True: 0.70,  # P(MaryCalls=True | Alarm=True)\n",
        "    False: 0.01   # P(MaryCalls=True | Alarm=False)\n",
        "}\n",
        "\n",
        "print(\"Probabilities defined successfully.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c486513"
      },
      "source": [
        "## Implement Simulation Logic\n",
        "\n",
        "### Subtask:\n",
        "Create a function to simulate a single day's events, determining the state of each variable based on its parents and the defined probabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8e1b6e"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the `random` module and then define the `simulate_day` function as described in the instructions, which will simulate the states of Burglary, Earthquake, Alarm, JohnCalls, and MaryCalls based on their probabilities and dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4799063",
        "outputId": "dbc01b06-69c2-416c-d0c0-6e879d460a70"
      },
      "source": [
        "import random\n",
        "\n",
        "def simulate_day():\n",
        "    \"\"\"Simulates a single day's events for the burglar alarm system.\"\"\"\n",
        "\n",
        "    # Simulate Burglary\n",
        "    burglary = random.random() < p_burglary\n",
        "\n",
        "    # Simulate Earthquake\n",
        "    earthquake = random.random() < p_earthquake\n",
        "\n",
        "    # Simulate Alarm based on Burglary and Earthquake\n",
        "    # Determine the probability of Alarm=True based on parents' states\n",
        "    prob_alarm_true = p_alarm_given_be[(burglary, earthquake)] # so we look up the probablity from our table\n",
        "    alarm = random.random() < prob_alarm_true\n",
        "\n",
        "    # Simulate JohnCalls based on Alarm\n",
        "    prob_johncalls_true = p_johncalls_given_a[alarm]\n",
        "    johncalls = random.random() < prob_johncalls_true\n",
        "\n",
        "    # Simulate MaryCalls based on Alarm\n",
        "    prob_marycalls_true = p_marycalls_given_a[alarm]\n",
        "    marycalls = random.random() < prob_marycalls_true\n",
        "\n",
        "    return {\n",
        "        'Burglary': burglary,\n",
        "        'Earthquake': earthquake,\n",
        "        'Alarm': alarm,\n",
        "        'JohnCalls': johncalls,\n",
        "        'MaryCalls': marycalls\n",
        "    }\n",
        "\n",
        "print(\"simulate_day() function defined.\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulate_day() function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1f3063"
      },
      "source": [
        "## Run Simulation and Collect Data\n",
        "\n",
        "### Subtask:\n",
        "Execute the daily simulation function for 100,000 iterations and store the outcomes for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129919bf"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires running the `simulate_day()` function for 100,000 iterations, collecting the results, and storing them in a Pandas DataFrame named `simulation_results` for further analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886f6e65",
        "outputId": "e6c5179b-4d35-4f57-ba5c-a9190d5e51d1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store the results\n",
        "simulation_data = []\n",
        "\n",
        "# Set the number of iterations for the simulation\n",
        "num_iterations = 100000\n",
        "\n",
        "# Loop through the specified number of iterations\n",
        "for _ in range(num_iterations):\n",
        "    # Call the simulate_day() function and append the result to the list\n",
        "    simulation_data.append(simulate_day())\n",
        "\n",
        "# Convert the list of dictionaries into a Pandas DataFrame\n",
        "simulation_results = pd.DataFrame(simulation_data)\n",
        "\n",
        "print(f\"Simulation completed for {num_iterations} iterations.\")\n",
        "print(\"First 5 rows of the simulation_results DataFrame:\")\n",
        "print(simulation_results.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulation completed for 100000 iterations.\n",
            "First 5 rows of the simulation_results DataFrame:\n",
            "   Burglary  Earthquake  Alarm  JohnCalls  MaryCalls\n",
            "0     False       False  False      False      False\n",
            "1     False       False  False      False      False\n",
            "2     False       False  False      False      False\n",
            "3     False       False  False      False      False\n",
            "4     False       False  False      False      False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97812399"
      },
      "source": [
        "**Reasoning**:\n",
        "The simulation results are now available in the `simulation_results` DataFrame. The next step is to calculate the observed frequencies for each individual event (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) and the requested conditional probabilities from this DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7feeb9f",
        "outputId": "198c3535-d7a6-47e5-990a-1f8058ce0d40"
      },
      "source": [
        "print(\"Observed Frequencies for individual events:\")\n",
        "for column in simulation_results.columns:\n",
        "    # Calculate the frequency of 'True' for each event\n",
        "    frequency = simulation_results[column].value_counts(normalize=True).get(True, 0)\n",
        "    print(f\"P({column}=True): {frequency:.4f}\")\n",
        "\n",
        "# Calculate P(Burglary=True | JohnCalls=True, MaryCalls=True)\n",
        "# Filter for cases where JohnCalls is True and MaryCalls is True\n",
        "called_by_both = simulation_results[(simulation_results['JohnCalls'] == True) & (simulation_results['MaryCalls'] == True)]\n",
        "\n",
        "# Count how many of these cases also have Burglary=True\n",
        "burglary_given_calls = called_by_both['Burglary'].mean()\n",
        "print(f\"P(Burglary=True | JohnCalls=True, MaryCalls=True): {burglary_given_calls:.4f}\")\n",
        "\n",
        "# Calculate P(Alarm=True | JohnCalls=True, MaryCalls=True)\n",
        "# Count how many of these cases also have Alarm=True\n",
        "alarm_given_calls = called_by_both['Alarm'].mean()\n",
        "print(f\"P(Alarm=True | JohnCalls=True, MaryCalls=True): {alarm_given_calls:.4f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed Frequencies for individual events:\n",
            "P(Burglary=True): 0.0010\n",
            "P(Earthquake=True): 0.0021\n",
            "P(Alarm=True): 0.0025\n",
            "P(JohnCalls=True): 0.0535\n",
            "P(MaryCalls=True): 0.0117\n",
            "P(Burglary=True | JohnCalls=True, MaryCalls=True): 0.3268\n",
            "P(Alarm=True | JohnCalls=True, MaryCalls=True): 0.7707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3297e48e"
      },
      "source": [
        "## Analyze and Report Results\n",
        "\n",
        "### Subtask:\n",
        "Calculate and print the observed frequencies of individual events and key conditional probabilities from the simulation, comparing them to the input probabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c21ef2b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **What are the observed frequencies for individual events?**\n",
        "    *   The observed frequency for `P(Burglary=True)` is 0.0010.\n",
        "    *   The observed frequency for `P(Earthquake=True)` is 0.0021.\n",
        "    *   The observed frequency for `P(Alarm=True)` is 0.0025.\n",
        "    *   The observed frequency for `P(JohnCalls=True)` is 0.0535.\n",
        "    *   The observed frequency for `P(MaryCalls=True)` is 0.0117.\n",
        "*   **What are the observed conditional probabilities?**\n",
        "    *   The observed `P(Burglary=True | JohnCalls=True, MaryCalls=True)` is 0.3268.\n",
        "    *   The observed `P(Alarm=True | JohnCalls=True, MaryCalls=True)` is 0.7707.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The simulation, run for 100,000 iterations, yielded individual event frequencies that closely match the initial prior probabilities:\n",
        "    *   `P(Burglary=True)` was observed as 0.0010, identical to the input prior of 0.001.\n",
        "    *   `P(Earthquake=True)` was observed as 0.0021, very close to the input prior of 0.002.\n",
        "*   The overall frequency of `Alarm=True` was observed to be low at 0.0025, indicating it's a rare event influenced by the low prior probabilities of Burglary and Earthquake.\n",
        "*   The observed conditional probabilities when both John and Mary call are significant:\n",
        "    *   `P(Burglary=True | JohnCalls=True, MaryCalls=True)` is approximately 0.3268. This indicates that while still less than 50%, the probability of a burglary increases substantially from its prior of 0.001 when both John and Mary call.\n",
        "    *   `P(Alarm=True | JohnCalls=True, MaryCalls=True)` is approximately 0.7707. This suggests a high likelihood that the alarm has indeed gone off if both individuals call, which is expected given their dependency on the alarm.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The simulation results for individual event frequencies align well with the defined prior probabilities, confirming the simulation's accuracy for these base events.\n",
        "*   The analysis highlights the significant increase in the probability of a burglary from 0.001 to 0.3268 when both John and Mary call, demonstrating the diagnostic power of the Bayesian network in inferring causes from observed effects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5ba1e3"
      },
      "source": [
        "# Task\n",
        "## Visualize Individual Event Frequencies\n",
        "\n",
        "### Subtask:\n",
        "Generate a bar chart showing the observed frequencies for each individual event (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) alongside their prior probabilities for comparison. The chart should include a legend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a53cbd9e"
      },
      "source": [
        "## Visualize Individual Event Frequencies\n",
        "\n",
        "### Subtask:\n",
        "Generate a bar chart showing the observed frequencies for each individual event (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls) alongside their prior probabilities for comparison. The chart should include a legend.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44984f5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to calculate the true prior probabilities for Alarm, JohnCalls, and MaryCalls based on the provided CPTs and initial prior probabilities. This involves using the law of total probability to marginalize over parent variables. Then I will prepare the data for plotting by combining observed frequencies and true prior probabilities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "69b33c7f",
        "outputId": "3ce1ab6a-c09d-4c6c-ceab-7788cbd546b9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 2. Define the true prior probabilities for Burglary and Earthquake\n",
        "true_prior_burglary = p_burglary\n",
        "true_prior_earthquake = p_earthquake\n",
        "\n",
        "# 3. Calculate the true marginal prior probability for Alarm\n",
        "# P(A) = P(A|B,E)P(B)P(E) + P(A|B,~E)P(B)P(~E) + P(A|~B,E)P(~B)P(E) + P(A|~B,~E)P(~B)P(~E)\n",
        "# where P(~B) = 1 - P(B) and P(~E) = 1 - P(E)\n",
        "true_prior_alarm = \\\n",
        "    p_alarm_given_be[(True, True)] * p_burglary * p_earthquake + \\\n",
        "    p_alarm_given_be[(True, False)] * p_burglary * (1 - p_earthquake) + \\\n",
        "    p_alarm_given_be[(False, True)] * (1 - p_burglary) * p_earthquake + \\\n",
        "    p_alarm_given_be[(False, False)] * (1 - p_burglary) * (1 - p_earthquake)\n",
        "\n",
        "# 4. Calculate the true marginal prior probability for JohnCalls\n",
        "# P(J) = P(J|A)P(A) + P(J|~A)P(~A)\n",
        "true_prior_johncalls = \\\n",
        "    p_johncalls_given_a[True] * true_prior_alarm + \\\n",
        "    p_johncalls_given_a[False] * (1 - true_prior_alarm)\n",
        "\n",
        "# 5. Calculate the true marginal prior probability for MaryCalls\n",
        "# P(M) = P(M|A)P(A) + P(M|~A)P(~A)\n",
        "true_prior_marycalls = \\\n",
        "    p_marycalls_given_a[True] * true_prior_alarm + \\\n",
        "    p_marycalls_given_a[False] * (1 - true_prior_alarm)\n",
        "\n",
        "# 6. Create lists for variable names, observed frequencies, and true prior probabilities\n",
        "events = ['Burglary', 'Earthquake', 'Alarm', 'JohnCalls', 'MaryCalls']\n",
        "\n",
        "observed_frequencies = [\n",
        "    simulation_results['Burglary'].mean(),\n",
        "    simulation_results['Earthquake'].mean(),\n",
        "    simulation_results['Alarm'].mean(),\n",
        "    simulation_results['JohnCalls'].mean(),\n",
        "    simulation_results['MaryCalls'].mean()\n",
        "]\n",
        "\n",
        "true_prior_probabilities = [\n",
        "    true_prior_burglary,\n",
        "    true_prior_earthquake,\n",
        "    true_prior_alarm,\n",
        "    true_prior_johncalls,\n",
        "    true_prior_marycalls\n",
        "]\n",
        "\n",
        "# 7. Create a Pandas DataFrame to hold these values\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Event': events,\n",
        "    'Observed Frequency': observed_frequencies,\n",
        "    'True Prior Probability': true_prior_probabilities\n",
        "})\n",
        "\n",
        "# 8. Generate a bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(events))\n",
        "\n",
        "bar1 = ax.bar(index - bar_width/2, comparison_df['Observed Frequency'], bar_width, label='Observed Frequency', color='skyblue')\n",
        "bar2 = ax.bar(index + bar_width/2, comparison_df['True Prior Probability'], bar_width, label='True Prior Probability', color='lightcoral')\n",
        "\n",
        "# 9. Set the title of the plot\n",
        "ax.set_title('Observed Frequencies vs. True Prior Probabilities')\n",
        "\n",
        "# 10. Label the x-axis and y-axis\n",
        "ax.set_xlabel('Event')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(index)\n",
        "ax.set_xticklabels(events, rotation=45, ha='right')\n",
        "\n",
        "# 11. Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# 12. Rotate x-axis labels for readability (done above)\n",
        "\n",
        "# 13. Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Comparison DataFrame:\")\n",
        "print(comparison_df.to_string())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison DataFrame:\n",
            "        Event  Observed Frequency  True Prior Probability\n",
            "0    Burglary             0.00096                0.001000\n",
            "1  Earthquake             0.00205                0.002000\n",
            "2       Alarm             0.00247                0.002516\n",
            "3   JohnCalls             0.05346                0.052139\n",
            "4   MaryCalls             0.01170                0.011736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59e27c07"
      },
      "source": [
        "## Visualize Conditional Probabilities\n",
        "\n",
        "### Subtask:\n",
        "Create a bar chart comparing the observed conditional probabilities P(Burglary=True | JohnCalls=True, MaryCalls=True) and P(Alarm=True | JohnCalls=True, MaryCalls=True) against their respective true conditional probabilities. The chart should include a legend.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76180584"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will calculate the true conditional probabilities for P(Burglary=True | JohnCalls=True, MaryCalls=True) and P(Alarm=True | JohnCalls=True, MaryCalls=True) using the principles of Bayesian networks and the law of total probability. This involves summing over all possible states of the unobserved parent variables to find the joint probabilities and then applying Bayes' rule. I will utilize the `true_prior_alarm` value calculated in a previous step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "adfc1d4c",
        "outputId": "80aea64b-0822-4f1b-8c58-875fd77af88e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate P(J=T, M=T)\n",
        "# P(J,M|A) = P(J|A) * P(M|A) because J and M are conditionally independent given A\n",
        "p_j_true_m_true_given_a_true = p_johncalls_given_a[True] * p_marycalls_given_a[True]\n",
        "p_j_true_m_true_given_a_false = p_johncalls_given_a[False] * p_marycalls_given_a[False]\n",
        "\n",
        "# P(J,M) = P(J,M|A)P(A) + P(J,M|~A)P(~A)\n",
        "true_prob_jm = (p_j_true_m_true_given_a_true * true_prior_alarm) + \\\n",
        "               (p_j_true_m_true_given_a_false * (1 - true_prior_alarm))\n",
        "\n",
        "# Calculate P(Burglary=True, JohnCalls=True, MaryCalls=True)\n",
        "# This requires summing over all states of E (Earthquake) and A (Alarm) for B=True\n",
        "prob_b_true_j_true_m_true = 0.0\n",
        "\n",
        "# Iterate through all states of Earthquake\n",
        "for e_state in [True, False]:\n",
        "    p_e = p_earthquake if e_state else (1 - p_earthquake)\n",
        "\n",
        "    # P(B=T, E=e_state, A=T, J=T, M=T) = P(J=T|A=T) * P(M=T|A=T) * P(A=T|B=T,E=e_state) * P(B=T) * P(E=e_state)\n",
        "    prob_b_true_j_true_m_true += p_j_true_m_true_given_a_true * p_alarm_given_be[(True, e_state)] * p_burglary * p_e\n",
        "\n",
        "    # P(B=T, E=e_state, A=F, J=T, M=T) = P(J=T|A=F) * P(M=T|A=F) * P(A=F|B=T,E=e_state) * P(B=T) * P(E=e_state)\n",
        "    prob_b_true_j_true_m_true += p_j_true_m_true_given_a_false * (1 - p_alarm_given_be[(True, e_state)]) * p_burglary * p_e\n",
        "\n",
        "# Now calculate P(Burglary=True | JohnCalls=True, MaryCalls=True)\n",
        "# P(B|J,M) = P(B,J,M) / P(J,M)\n",
        "true_prob_b_given_jm = prob_b_true_j_true_m_true / true_prob_jm if true_prob_jm > 0 else 0.0\n",
        "\n",
        "# Calculate P(Alarm=True | JohnCalls=True, MaryCalls=True)\n",
        "# P(A|J,M) = P(J,M|A) * P(A) / P(J,M)\n",
        "true_prob_a_given_jm = (p_j_true_m_true_given_a_true * true_prior_alarm) / true_prob_jm if true_prob_jm > 0 else 0.0\n",
        "\n",
        "\n",
        "# Create a Pandas DataFrame to store the event names, observed and true conditional probabilities\n",
        "conditional_events = ['P(Burglary=True | J=T, M=T)', 'P(Alarm=True | J=T, M=T)']\n",
        "\n",
        "observed_conditional_probs = [\n",
        "    burglary_given_calls, # from previous output\n",
        "    alarm_given_calls     # from previous output\n",
        "]\n",
        "\n",
        "true_conditional_probabilities = [\n",
        "    true_prob_b_given_jm,\n",
        "    true_prob_a_given_jm\n",
        "]\n",
        "\n",
        "conditional_comparison_df = pd.DataFrame({\n",
        "    'Event': conditional_events,\n",
        "    'Observed Probability': observed_conditional_probs,\n",
        "    'True Conditional Probability': true_conditional_probabilities\n",
        "})\n",
        "\n",
        "# Generate a bar chart\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "bar_width_cond = 0.35\n",
        "index_cond = np.arange(len(conditional_events))\n",
        "\n",
        "bar1_cond = ax.bar(index_cond - bar_width_cond/2, conditional_comparison_df['Observed Probability'], bar_width_cond, label='Observed Probability', color='teal')\n",
        "bar2_cond = ax.bar(index_cond + bar_width_cond/2, conditional_comparison_df['True Conditional Probability'], bar_width_cond, label='True Conditional Probability', color='darkorange')\n",
        "\n",
        "# Set the title of the plot\n",
        "ax.set_title('Observed vs. True Conditional Probabilities')\n",
        "\n",
        "# Label the x-axis and y-axis\n",
        "ax.set_xlabel('Conditional Probability')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(index_cond)\n",
        "ax.set_xticklabels(conditional_events, rotation=15, ha='center')\n",
        "ax.set_ylim(0, 1) # Probabilities are between 0 and 1\n",
        "\n",
        "# Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Conditional Probability Comparison DataFrame:\")\n",
        "print(conditional_comparison_df.to_string())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Probability Comparison DataFrame:\n",
            "                         Event  Observed Probability  True Conditional Probability\n",
            "0  P(Burglary=True | J=T, M=T)              0.326829                      0.284172\n",
            "1     P(Alarm=True | J=T, M=T)              0.770732                      0.760692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452f6b02"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide an interpretation of the visualizations and summarize the key insights from the Bayesian Network simulation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b5c3b05"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The visualizations indicate that the Bayesian Network simulation closely approximates the true prior and conditional probabilities for the events. While most observed frequencies and conditional probabilities are very close to their theoretical counterparts, there are slight deviations, particularly for the observed conditional probability of Burglary given calls.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Individual Event Frequencies vs. True Priors**:\n",
        "    *   The true marginal prior probabilities were successfully calculated: P(Alarm) was approximately 0.002516, P(JohnCalls) was approximately 0.052139, and P(MaryCalls) was approximately 0.011736.\n",
        "    *   The observed frequencies from the simulation were very close to the true prior probabilities for all individual events. For example, the observed frequency for Burglary was 0.00096 compared to a true prior of 0.001, and for Alarm, it was 0.00247 observed versus 0.002516 true prior.\n",
        "*   **Conditional Probabilities vs. True Conditionals**:\n",
        "    *   The true conditional probabilities were calculated: P(Burglary=True | JohnCalls=True, MaryCalls=True) was approximately 0.284172, and P(Alarm=True | JohnCalls=True, MaryCalls=True) was approximately 0.760692.\n",
        "    *   The observed conditional probabilities from the simulation showed reasonable agreement but with some noticeable deviations for Burglary. The observed P(Burglary=True | J=T, M=T) was 0.326829, while the true conditional probability was 0.284172. For Alarm, the observed P(Alarm=True | J=T, M=T) was 0.770732, closely matching the true conditional probability of 0.760692.\n",
        "*   **Visualization**: Bar charts were successfully generated for both individual event frequencies and conditional probabilities, visually representing the comparison between observed and true values.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The simulation generally provides a good approximation of the underlying Bayesian Network's probabilities, validating the simulation setup.\n",
        "*   Further investigation could focus on the slight overestimation of P(Burglary=True | J=T, M=T) by the simulation, potentially by increasing the number of simulation runs to see if the observed probability converges closer to the true value.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Chapter 7 - \"Logical Agents\"\n",
    "\n",
    "\n",
    "- **Knowledge-based agents in AI These agents use reasoning over an internal representation of knowledge to decide actions. This contrasts with the limited knowledge of problem-solving agents in earlier chapters, which know only available actions and their specific outcomes.\n",
    "- **Limitations of Problem-Solving Agents Traditional problem-solving agents lack general facts knowledge. Examples include a route-finding agent not knowing the impossibility of negative road lengths or an 8-puzzle agent unaware that two tiles cannot occupy the same space.\n",
    "- **Atomic Representations and Limitations In partially observable environments, problem-solving agents struggle, as they must list all possible concrete states. This is less efficient compared to human-like understanding and goal setting.\n",
    "- **Development of Factored Representations Chapter 6 introduced states represented as assignments of values to variables, a step towards domain-independent functioning and more efficient algorithms.\n",
    "- **Logic as a Representation for Knowledge-Based Agents This chapter explores logic as a general class of representations, allowing agents to combine information for various purposes. These agents can handle new tasks, quickly adapt to new knowledge, and adjust to environmental changes.\n",
    "- **Chapter Structure and Content\n",
    "   - Section 7.1 discusses the overall design of knowledge-based agents.\n",
    "   - Section 7.2 introduces a new environment, the wumpus world, as a practical example.\n",
    "   - Sections 7.3 and 7.4 cover the principles of general logic and propositional logic, respectively.\n",
    "   - Section 7.5 and 7.6 delve into the inference technologies in propositional logic.\n",
    "   - Section 7.7 combines knowledge-based agent concepts with propositional logic technologies, applying them to the wumpus world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Knowledge-Based Agents\n",
    "\n",
    "\n",
    "- **Knowledge Base (KB) A central component of a knowledge-based agent, storing all the knowledge the agent has. It contains a set of sentences, each representing a piece of knowledge.\n",
    "- **Sentence in Knowledge Base Sentences are the specific statements or assertions in a knowledge representation language, forming the content of the knowledge base. They express facts, rules, and relationships about the world.\n",
    "- **Knowledge Representation Language A formal language used to encode the sentences in the knowledge base. This language must be expressive enough to capture relevant knowledge and allow for effective reasoning.\n",
    "- **Axiom An axiom is a sentence that is assumed to be true within the knowledge base. It serves as a fundamental truth from which other knowledge is derived.\n",
    "- **Inference The process of deriving new sentences or conclusions from the existing knowledge base. Inference is essential for agents to make decisions or predictions based on their knowledge.\n",
    "- **Background Knowledge Refers to the general, domain-independent knowledge incorporated into the knowledge base, enabling the agent to function effectively in diverse scenarios.\n",
    "- **Knowledge Level vs. Implementation Level\n",
    "   - **Knowledge Level Concerned with what knowledge is represented and how it's used in reasoning.\n",
    "   - **Implementation Level Focuses on how the knowledge is actually stored, accessed, and manipulated within the system.\n",
    "\n",
    "### Declarative vs. Procedural Approach\n",
    "\n",
    "\n",
    "- **Declarative Approach In knowledge-based systems, this approach focuses on 'what' knowledge is represented. The emphasis is on the representation of knowledge as facts or axioms in a knowledge base.\n",
    "- **Procedural Approach Contrasts with the declarative approach by focusing on 'how' knowledge is used. It emphasizes procedures or algorithms that manipulate or reason with the knowledge, often leading to more efficient systems but at the cost of flexibility and generality found in declarative systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 The Wumpus World\n",
    "\n",
    "- **Description of the Wumpus World The Wumpus World is a cave environment presented as a 4x4 grid of rooms interconnected by passageways. Key elements include:\n",
    "   - A dangerous creature called the wumpus, which can eat agents entering its room.\n",
    "   - Bottomless pits in some rooms, posing a threat to agents (but not the wumpus).\n",
    "   - A heap of gold as a reward within the cave.\n",
    "\n",
    "### Performance Measure\n",
    "\n",
    "\n",
    "- Gaining +1000 points for successfully exiting the cave with the gold.\n",
    "- Losing -1000 points for falling into a pit or being eaten by the wumpus.\n",
    "- A penalty of -1 point for each action taken and -10 for using the only arrow available.\n",
    "\n",
    "### Environment\n",
    "\n",
    "\n",
    "- The cave is structured as a 4×4 grid surrounded by walls.\n",
    "- The agent starts at [1,1], facing east.\n",
    "- Random distribution of the gold and the wumpus in squares other than the start.\n",
    "- Each square (except the start) may contain a pit with a 20% probability.\n",
    "\n",
    "### Actuators\n",
    "\n",
    "\n",
    "- The agent can move forward, turn left or right by 90 degrees.\n",
    "- It can grab gold, shoot an arrow, or climb out of the cave.\n",
    "- Restrictions include only one arrow available and safe exit only from square [1,1].\n",
    "\n",
    "### Sensors and Perceptions\n",
    "\n",
    "\n",
    "- Stench near the wumpus.\n",
    "- Breeze near a pit.\n",
    "- Glitter where the gold is.\n",
    "- Bump when walking into a wall.\n",
    "- Scream heard throughout the cave upon the wumpus's death.\n",
    "- Percepts provided as a list of symbols indicating the presence or absence of these elements.\n",
    "\n",
    "**Logical Reasoning The chapter emphasizes the use of logical reasoning in the Wumpus World. Agents can draw guaranteed correct conclusions from the available information, illustrating fundamental properties of logical reasoning. The chapter proceeds to explain the construction of logical agents capable of representing information and making such deductions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/wumpus_world.jpg?raw=true\" alt=\"wumpus world\" width=\"400\">\n",
    "\n",
    "A typical wumpus world. The agent is in the bottom left corner [1,1], facing east\n",
    "(rightward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/wumpus_agent_moving.jpg?raw=true\" widht=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Logic \n",
    "\n",
    "- **Fundamental Concepts of Logical Representation and Reasoning This section introduces the core ideas of logic which are applicable across various forms. Using arithmetic as a familiar example, it postpones the technical details of specific forms of logic.\n",
    "- **Syntax and Semantics\n",
    "   - **Syntax Refers to the rules and structure of the language used in logic. It dictates how sentences are formed correctly.\n",
    "   - **Semantics Involves the meaning of the sentences. It determines how the truth of sentences is established in relation to models (or \"possible worlds\").\n",
    "\n",
    "####  Truth of Each Sentence with Respect to a Model The truth of a sentence in logic is evaluated with respect to a model. A model represents a possible world where certain conditions hold. A sentence is true if it accurately describes that model.\n",
    "\n",
    "####  Satisfaction in Logic A model satisfies a sentence if the sentence is true in that model. The concept of satisfaction is key to understanding how sentences relate to the worlds they describe.\n",
    "\n",
    "####  Logical Entailment Between Sentences Entailment is a fundamental concept where one sentence logically follows from another. If a set of sentences (premises) entails another sentence (conclusion), the conclusion is a logical consequence of the premises.\n",
    "\n",
    "####  Soundness of Inference Algorithms An inference algorithm is sound or truth-preserving if it derives only sentences that are entailed by the premises. Soundness is crucial because an unsound algorithm might produce false or baseless conclusions.\n",
    "\n",
    "####  Completeness of Inference Procedures Completeness is a property where an inference algorithm can derive any sentence that is entailed. This is important because, in many cases, the set of all consequences (the \"haystack\") can be infinite, and a complete procedure ensures that all valid inferences can be made.\n",
    "\n",
    "####  Grounding This concerns the connection between logical reasoning processes and the real world in which an agent operates. It involves translating general rules and learned knowledge into practical applications.\n",
    "\n",
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/representation_real_world.jpg?raw=true\" width=\"700\">\n",
    "\n",
    "####  Learning in Logic and its Limitations Learning is the process of constructing new sentences or rules. It is not always perfect and may not always accurately reflect the real world. However, with effective learning procedures, there is optimism for the accuracy and applicability of the knowledge base in real-world situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Propositional Logic: A Very Simple Logic\n",
    "\n",
    "- **Overview of Propositional Logic This section introduces propositional logic, a fundamental form of logic in AI. It is described as a very simple yet powerful system for logical representation and reasoning.\n",
    "- **Syntax of Propositional Logic The syntax refers to the structure of sentences in propositional logic. This part explains how sentences (propositions) are formed, including the use of logical connectives like 'and', 'or', 'not', etc.\n",
    "- **Semantics of Propositional Logic Semantics deals with how the truth of sentences is determined in propositional logic. It explains how the truth values of propositions are assigned and how these values determine the truth of complex sentences built using logical connectives.\n",
    "- **Logical Inference Algorithm From the syntax and semantics, the section derives a syntactic algorithm for logical inference. This algorithm is designed to implement the semantic notion of entailment, determining whether a certain proposition logically follows from others.\n",
    "- **Application in the Wumpus World The principles of propositional logic are applied within the context of the Wumpus World. This setting is used to illustrate how propositional logic can be used for reasoning and decision-making in a specific, controlled environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Syntax of Propositional Logic**\n",
    "\n",
    "\n",
    "- **Definition of Allowable Sentences The syntax of propositional logic defines what constitutes a valid sentence. This includes both atomic and complex sentences, structured according to specific rules.\n",
    "- **Atomic Sentences\n",
    "   - These are the simplest form of sentences in propositional logic, consisting of a single proposition symbol.\n",
    "   - Each symbol represents a proposition that can be either true or false.\n",
    "   - Symbols typically start with an uppercase letter and may include other letters or subscripts (e.g., P, Q, R, W1,3, FacingEast).\n",
    "   - The choice of names for these symbols is often mnemonic, meaning they are selected to be suggestive of their meaning.\n",
    "\n",
    "####  Special Proposition Symbols\n",
    "\n",
    "\n",
    "- 'True': This symbol represents the always-true proposition.\n",
    "- 'False': This symbol stands for the always-false proposition.\n",
    "\n",
    "####  Construction of Complex Sentences\n",
    "\n",
    "\n",
    "- Complex sentences are formed by combining simpler sentences.\n",
    "- This combination is done using parentheses for grouping and logical connectives.\n",
    "\n",
    "####  Logical Connectives\n",
    "\n",
    "\n",
    "- There are five commonly used connectives in propositional logic:\n",
    "- **Negation Used to negate an atomic sentence. A negated atomic sentence is also known as a negative literal, while a non-negated atomic sentence is a positive literal.\n",
    "- **Conjunction Represents the logical 'and'.\n",
    "- **Disjunction Represents the logical 'or'.\n",
    "- **Implication Involves a premise (or antecedent) and a conclusion (or consequent), forming if-then statements. These are also known as rules.\n",
    "- **Biconditional Represents a bidirectional conditional, indicating that two propositions are equivalent.\n",
    "\n",
    "This section lays the foundational structure for creating valid sentences in propositional logic, essential for the logical reasoning processes that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/truth_tables_prop_log.jpg?raw=true\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  EBNF Grammar for Propositional Logic\n",
    "\n",
    "In Extended Backus-Naur Form (EBNF), a formal grammar for propositional logic can be described as follows. This grammar defines how sentences in propositional logic are constructed using atomic propositions, logical connectives, and parentheses:\n",
    "\n",
    "```ebnf<span class=\"\" data-state=\"closed\"><button class=\"flex gap-1 items-center\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" class=\"icon-sm\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12 4C10.8954 4 10 4.89543 10 6H14C14 4.89543 13.1046 4 12 4ZM8.53513 4C9.22675 2.8044 10.5194 2 12 2C13.4806 2 14.7733 2.8044 15.4649 4H17C18.6569 4 20 5.34315 20 7V19C20 20.6569 18.6569 22 17 22H7C5.34315 22 4 20.6569 4 19V7C4 5.34315 5.34315 4 7 4H8.53513ZM8 6H7C6.44772 6 6 6.44772 6 7V19C6 19.5523 6.44772 20 7 20H17C17.5523 20 18 19.5523 18 19V7C18 6.44772 17.5523 6 17 6H16C16 7.10457 15.1046 8 14 8H10C8.89543 8 8 7.10457 8 6Z\" fill=\"currentColor\"></path></svg>Copy code</button>\n",
    "<proposition> ::= <atomic-proposition> | <complex-proposition>\n",
    "\n",
    "<atomic-proposition> ::= <proposition-symbol> | \"True\" | \"False\"\n",
    "\n",
    "<proposition-symbol> ::= <uppercase-letter> { <letter> | <digit> | <subscript> }*\n",
    "\n",
    "<complex-proposition> ::= \"(\" <proposition> <binary-connective> <proposition> \")\" \n",
    "                         | <unary-connective> <proposition>\n",
    "                         | \"(\" <proposition> \")\"\n",
    "\n",
    "<binary-connective> ::= \"∧\" | \"∨\" | \"→\" | \"↔\"\n",
    "\n",
    "<unary-connective> ::= \"¬\"\n",
    "\n",
    "<uppercase-letter> ::= \"A\" | \"B\" | \"C\" | ... | \"Z\"\n",
    "\n",
    "<letter> ::= <uppercase-letter> | <lowercase-letter>\n",
    "\n",
    "<lowercase-letter> ::= \"a\" | \"b\" | \"c\" | ... | \"z\"\n",
    "\n",
    "<digit> ::= \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\n",
    "\n",
    "<subscript> ::= \"_\" <digit> { <digit> }*\n",
    "\n",
    "```\n",
    "\n",
    "- `\n",
    "` can be either an `\n",
    "` or a `\n",
    "`.\n",
    "- `\n",
    "` consists of a single proposition symbol or the constants \"True\" or \"False\".\n",
    "- `\n",
    "` is defined as an uppercase letter followed optionally by additional letters, digits, or subscripts.\n",
    "- `\n",
    "` is formed using logical connectives (binary or unary) and encompasses nested propositions.\n",
    "- Binary connectives include \"∧\" (and), \"∨\" (or), \"→\" (implies), and \"↔\" (if and only if).\n",
    "- The unary connective is \"¬\" (not).\n",
    "- The grammar includes definitions for uppercase and lowercase letters, digits, and subscripts.\n",
    "\n",
    "This EBNF formalism provides a precise framework for constructing valid expressions in propositional logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 Semantics of Propositional Logic\n",
    "\n",
    "\n",
    "- **Role of Semantics In propositional logic, semantics defines the rules for determining the truth of a sentence within the context of a specific model. This involves setting truth values for each proposition in a model and then computing the truth value of complex sentences based on these values.\n",
    "- **Model in Propositional Logic\n",
    "   - A model in propositional logic is a specification that assigns a truth value (true or false) to every proposition symbol.\n",
    "   - The model serves as the basis for determining the truth of sentences.\n",
    "\n",
    "####  Computing Truth Values Recursively\n",
    "\n",
    "\n",
    "- The process of determining the truth value of any sentence in propositional logic is recursive.\n",
    "- Since all sentences are constructed from atomic sentences and the five logical connectives (negation, conjunction, disjunction, implication, and biconditional), the semantics must specify rules for computing the truth of these basic elements.\n",
    "\n",
    "####  Truth of Atomic Sentences\n",
    "\n",
    "\n",
    "- The truth value of atomic sentences is directly determined by their assignment in the model.\n",
    "- An atomic sentence is true if the model assigns it true, and false if the model assigns it false.\n",
    "\n",
    "####  Truth of Sentences with Connectives\n",
    "\n",
    "\n",
    "- The truth value of complex sentences formed using logical connectives is computed based on the truth values of their constituent sentences and the specific nature of the connectives.\n",
    "- Each of the five connectives has a specific rule for how it affects the truth value of the sentence it forms.\n",
    "\n",
    "####  Use of Truth Tables\n",
    "\n",
    "\n",
    "- Truth tables are used to express the rules for each of the logical connectives.\n",
    "- A truth table specifies the truth value of a complex sentence for every possible combination of truth values of its component sentences.\n",
    "- These tables are essential tools for understanding and applying the semantics of propositional logic.\n",
    "\n",
    "In summary, the semantics in propositional logic provide a systematic way to determine the truth of sentences based on the truth values assigned to their atomic components and the rules associated with each logical connective, with truth tables serving as a practical method for visualizing and applying these rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Truth tables for propositional logic\n",
    "\n",
    "Truth tables in propositional logic show how the truth values of complex sentences are determined based on the truth values of their component atomic sentences and the logical connectives used. Here are the truth tables for the five common logical connectives: negation (¬), conjunction (∧), disjunction (∨), implication (→), and biconditional (↔).\n",
    "\n",
    "\n",
    "- **Negation (¬)\n",
    "P\n",
    "¬P\n",
    "T\n",
    "F\n",
    "F\n",
    "T\n",
    "- **Conjunction (∧)\n",
    "P\n",
    "Q\n",
    "P ∧ Q\n",
    "T\n",
    "T\n",
    "T\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "F\n",
    "- **Disjunction (∨)\n",
    "P\n",
    "Q\n",
    "P ∨ Q\n",
    "T\n",
    "T\n",
    "T\n",
    "T\n",
    "F\n",
    "T\n",
    "F\n",
    "T\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "- **Implication (→)\n",
    "P\n",
    "Q\n",
    "P → Q\n",
    "T\n",
    "T\n",
    "T\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "T\n",
    "T\n",
    "F\n",
    "F\n",
    "T\n",
    "- **Biconditional (↔)\n",
    "P\n",
    "Q\n",
    "P ↔ Q\n",
    "T\n",
    "T\n",
    "T\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "T\n",
    "F\n",
    "F\n",
    "F\n",
    "T\n",
    "\n",
    "In these tables, 'T' stands for 'True' and 'F' for 'False'. The truth tables provide a clear way to understand how the truth value of complex propositions is derived from their components in propositional logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 A Simple Knowledge Base in Propositional Logic\n",
    "\n",
    "\n",
    "- **Application of Propositional Logic Semantics With the semantics of propositional logic established, this section demonstrates how to construct a knowledge base for the Wumpus World, a key example used throughout the chapter.\n",
    "- **Focus on Immutable Aspects of the Wumpus World\n",
    "   - The initial construction of the knowledge base concentrates on the immutable or unchanging aspects of the Wumpus World.\n",
    "   - Immutable aspects include the layout of the grid, the locations of pits, the Wumpus, and the gold, which do not change once the game starts.\n",
    "\n",
    "####  Representing Wumpus World Knowledge\n",
    "\n",
    "\n",
    "- Knowledge about the Wumpus World is encoded using propositional logic.\n",
    "- This includes facts about what each grid cell contains (like pits or the Wumpus) and the rules governing the behavior and interactions within the world.\n",
    "\n",
    "####  Knowledge Base Structure\n",
    "\n",
    "\n",
    "- The knowledge base is structured as a set of logical sentences, each representing a piece of information about the Wumpus World.\n",
    "- These sentences use the syntax and abide by the semantics of propositional logic as outlined in the previous sections.\n",
    "\n",
    "####  Leaving Mutable Aspects for Later\n",
    "\n",
    "\n",
    "- Mutable or changeable aspects of the Wumpus World, such as the agent's actions or perceptions, are not included in this initial knowledge base.\n",
    "- These dynamic elements are addressed in a later section, focusing first on establishing a solid foundation of immutable knowledge.\n",
    "\n",
    "In summary, this section illustrates how to apply propositional logic to create a basic knowledge base for a defined environment, emphasizing immutable aspects that set the foundational knowledge for further logical reasoning and decision-making within that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wumpus world knowledge base symbols\n",
    "\n",
    "\n",
    "- P<sub>x,y</sub> is true if there is a pit in [x, y].\n",
    "- W<sub>x,y</sub> is true if the Wumpus is in [x, y], dead or alive.\n",
    "- B<sub>x,y</sub> is true if there is a breeze in [x, y].\n",
    "- S<sub>x,y</sub> is true if there is a stench in [x, y].\n",
    "- G<sub>x,y</sub> is true if the gold is in [x, y].\n",
    "- L<sub>x,y</sub> is true if the agent is in [x, y].\n",
    "\n",
    "-- not covered is state of our arrow, but it is not needed for this task\n",
    "\n",
    "We label each sentence with a number for reference. The sentences are:\n",
    "\n",
    "- R1: B<sub>1,1</sub> ⇔ (P<sub>1,2</sub> ∨ P<sub>2,1</sub>)\n",
    "- R2: B<sub>2,1</sub> ⇔ (P<sub>1,1</sub> ∨ P<sub>2,2</sub> ∨ P<sub>3,1</sub>)\n",
    "and so on for all 16 squares. The last sentence is:\n",
    "- R16: B<sub>4,4</sub> ⇔ (P<sub>3,4</sub> ∨ P<sub>4,3</sub>)\n",
    "\n",
    "So sentences are labeled R1 to R16. The first sentence is R1, the second is R2, and so on. The last sentence is R16.\n",
    "We actually do need more sentences to describe the Wumpus world. For example, we need to say that the Wumpus is in exactly one of the 16 squares. We can do this with four sentences:\n",
    "\n",
    "- R17: W<sub>1,1</sub> ∨ W<sub>1,2</sub> ∨ W<sub>1,3</sub> ∨ W<sub>1,4</sub>\n",
    "- R18: W<sub>2,1</sub> ∨ W<sub>2,2</sub> ∨ W<sub>2,3</sub> ∨ W<sub>2,4</sub>\n",
    "- R19: W<sub>3,1</sub> ∨ W<sub>3,2</sub> ∨ W<sub>3,3</sub> ∨ W<sub>3,4</sub>\n",
    "- R20: W<sub>4,1</sub> ∨ W<sub>4,2</sub> ∨ W<sub>4,3</sub> ∨ W<sub>4,4</sub>\n",
    "we could have done this with one sentence, but it would have been more complicated.\n",
    "\n",
    "Notes: The origin [1,1] is in the lower left corner.\n",
    "x,y are not variables, but part of the symbol name!!! We discuss variables in logic in another chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/truth_table_wumpus_start.jpg?raw=true\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 A Simple Inference Procedure\n",
    "\n",
    "- **Goal of the Inference Procedure The objective is to determine whether a knowledge base (KB) entails a sentence α (KB |= α). For example, to verify if ¬P1,2 (not in pit at location [1,2]) is entailed by the knowledge base.\n",
    "- **Model-Checking Approach\n",
    "   - This approach is a direct implementation of the definition of entailment. It involves enumerating all possible models and checking if α is true in every model where KB is true.\n",
    "   - A model in this context is an assignment of truth values (true or false) to every proposition symbol in the knowledge base.\n",
    "\n",
    "####  Soundness and Completeness\n",
    "\n",
    "\n",
    "- The algorithm is sound, meaning it correctly implements the definition of entailment and does not produce false entailments.\n",
    "- It is also complete, applicable to any KB and α, and always terminates as there are only a finite number of models to examine.\n",
    "\n",
    "####  Consideration of Complexity\n",
    "\n",
    "\n",
    "- Although there are finitely many models, the number is not necessarily small. For a knowledge base and sentence α containing n symbols in total, there are 2^n possible models.\n",
    "- The time complexity of the model-checking algorithm is O(2<sup>n</sup>), which can be prohibitive for large n. However, its space complexity is more manageable at O(n), as the enumeration can be done in a depth-first manner.\n",
    "\n",
    "####  Efficiency and Limitations\n",
    "\n",
    "\n",
    "- While this approach is straightforward, it may not be the most efficient, especially for large knowledge bases.\n",
    "- Later in the chapter, more efficient algorithms are introduced for many cases.\n",
    "- It's important to note that propositional entailment is co-NP-complete, indicating that in general, efficient algorithms for all cases are unlikely (comparable to the complexity of NP-complete problems).\n",
    "\n",
    "In summary, this section discusses a basic, sound, and complete inference procedure for propositional logic through model checking. While reliable and theoretically robust, its practical limitations in terms of computational complexity are acknowledged, setting the stage for the exploration of more efficient algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Propositional Theorem Proving\n",
    "\n",
    "- **Transition from Model Checking to Theorem Proving This section shifts from determining entailment through model checking to the use of theorem proving. Theorem proving involves applying rules of inference directly to sentences in a knowledge base to construct a proof of a desired sentence, bypassing the need for consulting models.\n",
    "- **Efficiency of Theorem Proving Theorem proving can be more efficient than model checking, particularly when the number of models is large but the length of the proof is relatively short.\n",
    "- **Key Concepts in Theorem Proving\n",
    "   - **Logical Equivalence Two sentences are logically equivalent if they have the same truth value in every model.\n",
    "   - **Validity and Tautology A sentence is valid (or a tautology) if it is true in every model.\n",
    "   - **Deduction Theorem This theorem relates entailment to implication, stating that if β is deducible from α, then the sentence (α → β) is a tautology.\n",
    "   - **Satisfiability and SAT Problem A sentence is satisfiable if there is some model in which it is true. The SAT (Satisfiability) problem involves determining whether such a model exists for a given sentence.\n",
    "\n",
    "####  Proving by Reductio ad Absurdum (Reduction to the Absurd)\n",
    "\n",
    "\n",
    "- This method involves proving β from α by checking the unsatisfiability of (α ∧ ¬β).\n",
    "- It is a standard mathematical proof technique also known as proof by refutation or contradiction.\n",
    "- According to this approach, α entails β (α |= β) if and only if the sentence (α∧¬β) is unsatisfiable.\n",
    "\n",
    "The section emphasizes the practicality and efficiency of theorem proving in propositional logic, especially when direct proofs are shorter than the exhaustive model-checking process. It also introduces several fundamental concepts that underpin the practice of theorem proving and logical reasoning in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/standard_logical_equiv.jpg?raw=true\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1 Inference and Proofs**\n",
    "\n",
    "\n",
    "- **Overview This section delves into the inference rules used in propositional logic to derive a proof, which is a sequence of conclusions leading to a desired goal or sentence.\n",
    "- **Modus Ponens\n",
    "   - One of the best-known and most commonly used inference rules.\n",
    "   - It states that if a sentence α is true, and if α implies β (α → β) is also true, then β must be true.\n",
    "\n",
    "Modus Ponens can be written in two forms:\n",
    "\n",
    "- α, α → β |= β\n",
    "or over two lines\n",
    "- α - premise\n",
    "- α → β - premise\n",
    "- β - conclusion\n",
    "\n",
    "####  And-Elimination\n",
    "\n",
    "\n",
    "- Another useful inference rule.\n",
    "- It allows for the conclusion of either part of a conjunction if the entire conjunction is known to be true (i.e., from α ∧ β, one can infer α or β).\n",
    "\n",
    "####  Soundness of Inference Rules\n",
    "\n",
    "\n",
    "- The soundness of rules like Modus Ponens and And-Elimination is established by considering the possible truth values of α and β.\n",
    "- Soundness means these rules never lead to a false conclusion if the premises are true.\n",
    "\n",
    "####  Directionality of Inference Rules\n",
    "\n",
    "\n",
    "- Not all inference rules work in both directions, meaning some rules are applicable only under specific conditions or with certain types of sentences.\n",
    "\n",
    "####  Proof Search as an Alternative to Model Enumeration\n",
    "\n",
    "\n",
    "- The section discusses how any of the search algorithms from Chapter 3 can be adapted to find a sequence of inference steps constituting a proof.\n",
    "- Proof search involves defining a problem where the initial state is the knowledge base, actions are applications of inference rules, and the goal is a state containing the sentence to be proved.\n",
    "\n",
    "####  Efficiency of Proof Search\n",
    "\n",
    "\n",
    "- In many practical cases, finding a proof can be more efficient than enumerating models.\n",
    "- Proofs can ignore irrelevant propositions, which is advantageous especially when there are many such propositions.\n",
    "\n",
    "####  Monotonicity in Logical Systems\n",
    "\n",
    "\n",
    "- Monotonicity is a property where the set of sentences entailed by a knowledge base can only increase as more information is added.\n",
    "- This means that adding new information to the knowledge base does not invalidate previously derived conclusions.\n",
    "\n",
    "In summary, this section highlights key inference rules in propositional logic, the concept of proof search as an efficient alternative to model enumeration, and the importance of monotonicity in logical reasoning. These principles form the backbone of logical theorem proving in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2 Proof by Resolution**\n",
    "\n",
    "\n",
    "- **Completeness of Inference Rules This section discusses the completeness of inference algorithms in the context of propositional logic. While search algorithms like iterative deepening search are complete (able to find any reachable goal), the inference rules used within them must also be adequate. Inadequate rules may render some goals unreachable, indicating an incomplete set of inference rules.\n",
    "- **Resolution: A Complete Inference Rule\n",
    "   - Resolution is introduced as a powerful, single inference rule that, when combined with a complete search algorithm, yields a complete inference algorithm.\n",
    "   - This means that resolution can be used to find a proof for any provable sentence in propositional logic.\n",
    "\n",
    "####  Concept of Resolvent\n",
    "\n",
    "\n",
    "- In resolution, a resolvent is the clause produced by applying the resolution rule to two clauses containing complementary literals.\n",
    "- The resolvent contains all the literals of the original clauses except the pair of complementary literals.\n",
    "\n",
    "####  Unit Resolution Rule\n",
    "\n",
    "\n",
    "- Unit resolution is a specific case of the resolution rule.\n",
    "- It involves a clause (a disjunction of literals) and a unit clause (a single literal).\n",
    "- The rule produces a new clause by removing the complementary literal from the larger clause.\n",
    "\n",
    "####  Factoring\n",
    "\n",
    "\n",
    "- This process involves the removal of multiple copies of literals in a clause.\n",
    "- Factoring simplifies clauses without changing their meaning.\n",
    "\n",
    "####  Completeness of Resolution-Based Theorem Provers\n",
    "\n",
    "\n",
    "- The resolution rule forms the basis for a family of complete inference procedures.\n",
    "- Resolution-based theorem provers can decide whether α |= β for any sentences α and β in propositional logic.\n",
    "- The next subsections in the chapter explain how resolution achieves this completeness.\n",
    "\n",
    "In summary, proof by resolution introduces a singular, powerful inference rule that ensures completeness in propositional logic. Coupled with a complete search algorithm, resolution can be used to determine entailment for any pair of sentences in propositional logic, making it a cornerstone of theorem proving in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  7.5.2.1 Conjunctive Normal Form (CNF)**\n",
    "\n",
    "\n",
    "- **Relevance of Resolution Rule The resolution rule is specifically applicable to clauses, which are disjunctions of literals. This might seem to limit its relevance, as it appears applicable only to knowledge bases and queries formed of such clauses.\n",
    "- **Completeness for All Propositional Logic Despite its specific application to clauses, the resolution rule can lead to a complete inference procedure for all of propositional logic. This is because every sentence in propositional logic can be transformed into a logically equivalent sentence in CNF.\n",
    "- **Conjunctive Normal Form (CNF)\n",
    "   - A sentence is in CNF if it is expressed as a conjunction of clauses.\n",
    "   - Each clause in this form is a disjunction of literals.\n",
    "   - Thus, CNF is a conjunction (logical AND) of one or more clauses, where each clause is a disjunction (logical OR) of literals.\n",
    "\n",
    "####  Procedure for Converting to CNF\n",
    "\n",
    "\n",
    "- The section outlines a method for converting any propositional logic sentence into CNF.\n",
    "- This conversion ensures that the resolution rule can be applied to any sentence in propositional logic, not just those initially presented in clause form.\n",
    "\n",
    "The significance of CNF in the context of resolution-based theorem proving lies in its ability to make the resolution rule universally applicable within propositional logic. By converting any propositional logic sentence into CNF, the powerful resolution rule can be employed for a complete inference procedure, making it a versatile tool in logical reasoning and AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  7.5.2.2 A Resolution Algorithm\n",
    "\n",
    "- **Principle of Proof by Contradiction Resolution-based inference procedures primarily use the principle of proof by contradiction. This method involves assuming the opposite of what you want to prove and showing that this assumption leads to a contradiction.\n",
    "- **Resolution Algorithm Example\n",
    "\n",
    "\n",
    "- **Convert to CNF Start by converting all sentences in the knowledge base (KB) and the negation of the sentence to be proved (¬α) into Conjunctive Normal Form (CNF).\n",
    "- **Add ¬α to KB Add the negated sentence ¬α to the knowledge base, creating a new, augmented knowledge base. This is based on the idea that if KB entails α (KB |= α), then KB combined with ¬α should be unsatisfiable (contradictory).\n",
    "- **Apply Resolution Repeatedly apply the resolution rule to every pair of clauses that contain complementary literals. Each application of the resolution rule produces a new clause (the resolvent).\n",
    "- **Check for Contradiction If the empty clause (a clause with no literals, symbolizing a contradiction) is derived, then the original assumption (¬α) is contradicted, proving that KB |= α.\n",
    "- **Termination If it's not possible to derive the empty clause, and no new clauses can be produced, the algorithm terminates. In this case, it is concluded that KB does not entail α (KB ≠|= α).\n",
    "- **Efficiency of the Algorithm\n",
    "   - The resolution algorithm is efficient for certain types of problems but can become computationally intensive for larger or more complex knowledge bases due to the potential exponential growth in the number of clauses generated.\n",
    "\n",
    "####  Completeness\n",
    "\n",
    "\n",
    "- This algorithm is complete, meaning if KB entails α, the resolution algorithm will eventually derive the empty clause, proving the entailment.\n",
    "\n",
    "In summary, resolution algorithms in propositional logic use the principle of proof by contradiction. By converting sentences into CNF and using resolution to derive new clauses, these algorithms can systematically prove entailments or identify contradictions, showcasing a powerful and complete method for logical inference in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  7.5.2.3 Completeness of Resolution\n",
    "\n",
    "- **Topic Overview This section addresses the completeness of the resolution inference procedure in propositional logic, specifically through the concept of the resolution closure.\n",
    "- **Resolution Closure (RC(S))\n",
    "   - The resolution closure of a set of clauses S, denoted as RC(S), is defined as the set of all clauses that can be derived by repeatedly applying the resolution rule to clauses in S or to clauses derived from S.\n",
    "   - It essentially represents the exhaustive application of the resolution rule to a given set of clauses.\n",
    "\n",
    "####  Ground Resolution Theorem\n",
    "\n",
    "\n",
    "- This theorem is central to establishing the completeness of resolution in propositional logic.\n",
    "- It states that if a set of clauses is unsatisfiable, then the resolution closure of these clauses contains the empty clause.\n",
    "- The empty clause, having no literals, symbolizes a contradiction and thus unsatisfiability.\n",
    "\n",
    "####  Proof by Contrapositive\n",
    "\n",
    "\n",
    "- The theorem is usually proved by demonstrating its contrapositive: If the resolution closure of a set of clauses does not contain the empty clause, then the set of clauses is satisfiable.\n",
    "- This approach proves that if there's no way to derive a contradiction (the empty clause) from the set of clauses using resolution, then the original set of clauses must be consistent (satisfiable).\n",
    "\n",
    "####  Implication for PL-Resolution's Completeness\n",
    "\n",
    "\n",
    "- This theorem underpins the completeness of the PL-RESOLUTION algorithm.\n",
    "- Completeness here means that if a set of clauses is unsatisfiable (and hence, if the knowledge base entails a certain sentence), the resolution process will eventually derive the empty clause, confirming this entailment.\n",
    "\n",
    "In summary, the completeness of the resolution procedure in propositional logic is established by the ground resolution theorem and its proof. This theorem ensures that the resolution process will always find a proof (if one exists) by deriving the empty clause in the case of unsatisfiable sets of clauses, thus confirming the power and reliability of resolution as an inference mechanism in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.3 Horn Clauses and Definite Clauses\n",
    "\n",
    "- **Relevance of Resolution Completeness While resolution's completeness makes it a vital inference method in AI, full resolution power is often not necessary in practical situations. Certain restrictions on the form of sentences in knowledge bases allow for more efficient inference algorithms.\n",
    "- **Definite Clauses\n",
    "   - A definite clause is a disjunction of literals with exactly one positive literal.\n",
    "   - It can be written as an implication whose premise is a conjunction of positive literals and whose conclusion is a single positive literal.\n",
    "   - Example: `¬A ∨ ¬B ∨ C` can be interpreted as `A ∧ B → C`.\n",
    "\n",
    "####  Horn Clauses\n",
    "\n",
    "\n",
    "- Horn clauses are slightly more general than definite clauses.\n",
    "- They are disjunctions of literals with at most one positive literal.\n",
    "- All definite clauses are Horn clauses, but Horn clauses also include goal clauses (clauses with no positive literals).\n",
    "- Horn clauses are closed under resolution: resolving two Horn clauses results in another Horn clause.\n",
    "\n",
    "####  Goal Clauses\n",
    "\n",
    "\n",
    "- These are a type of Horn clause with no positive literals.\n",
    "\n",
    "####  k-CNF Sentences\n",
    "\n",
    "\n",
    "- A k-CNF sentence is a CNF sentence where each clause has at most k literals. This is another form of restriction that can be useful in certain contexts.\n",
    "\n",
    "####  Reasons for Interest in Definite Clause Knowledge Bases\n",
    "\n",
    "\n",
    "- **Implication Form They can be represented as implications, making them more intuitive and easier to understand.\n",
    "- **Forward-Chaining and Backward-Chaining Algorithms Inference with Horn clauses can be efficiently performed using these algorithms. These methods are natural and straightforward, forming the basis for logic programming.\n",
    "- **Linear Time Entailment Deciding entailment with Horn clauses can be achieved in time linear to the size of the knowledge base, which is computationally advantageous.\n",
    "\n",
    "In summary, Horn clauses, and particularly definite clauses, provide a more restricted yet efficient framework for logical inference. They allow for straightforward representation, efficient inference algorithms, and linear-time entailment decision, making them highly practical for many real-world AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.4 Forward and Backward Chaining**\n",
    "\n",
    "\n",
    "- **Forward-Chaining Algorithm (PL-FC-ENTAILS?(KB, q))\n",
    "   - **Purpose Determines if a single proposition symbol q (the query) is entailed by a knowledge base (KB) consisting of definite clauses.\n",
    "   - **Process Starts from known facts in the KB. If all the premises of an implication are known, the conclusion is added to the known facts.\n",
    "   - **Soundness Forward chaining is sound because each inference is an application of Modus Ponens.\n",
    "   - **Completeness It is also complete, as it will derive every entailed atomic sentence. The final state of the inference table, containing true for inferred symbols and false for others, serves as a logical model where every definite clause in KB is true.\n",
    "   - **Nature Represents data-driven reasoning, where reasoning starts from known data and works forward.\n",
    "\n",
    "####  Backward-Chaining Algorithm\n",
    "\n",
    "\n",
    "- **Approach Works backward from the query. It is used when the query is not initially known to be true.\n",
    "- **Process Identifies implications in KB whose conclusion is the query q. If all the premises of one of these implications can be proved true (via further backward chaining), then q is deemed true.\n",
    "- **Efficiency Particularly efficient in cases where many facts are known but only a few are relevant to the query. It avoids unnecessary inference steps by focusing only on those premises that could lead to proving the query.\n",
    "\n",
    "Both forward and backward chaining are fundamental algorithms in propositional logic, particularly suited for knowledge bases consisting of definite clauses. While forward chaining is a data-driven approach, starting with known facts and deriving new ones, backward chaining works by targeting the query and working backward to find supporting premises, making it efficient for querying specific propositions within a large knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  More on backward chaining\n",
    "\n",
    "Backward chaining is a form of goal-directed reasoning, which is particularly useful in situations where specific questions need to be answered. This method is called goal-directed because it starts with a goal (or query) and works backwards to find the premises that support it. Let's explore this concept in more detail:\n",
    "\n",
    "\n",
    "- **Goal-Oriented Nature In backward chaining, the reasoning process begins with the end goal or query. For instance, if the question is \"Where are my keys?\" the backward chaining process will start with this specific goal and trace back through the knowledge base to find information that leads to the answer.\n",
    "- **Answering Specific Questions This approach is highly effective for targeted queries like \"What shall I do now?\" or \"Where are my keys?\" because it directly addresses the specific query rather than analyzing unrelated facts or rules. It's like starting at the end of a maze (the goal) and working your way back to the start (the known facts).\n",
    "- **Efficiency Backward chaining can be much more efficient than forward chaining, especially in large knowledge bases. This is because backward chaining focuses only on the facts and rules that are relevant to the specific goal. It doesn't waste resources considering the entire knowledge base, but rather selectively examines those parts of the knowledge base that are directly related to answering the specific question at hand.\n",
    "- **Cost Relative to Knowledge Base Size Often, the computational cost of backward chaining is less than linear in relation to the size of the knowledge base. While forward chaining might require examining or inferring from every fact in the knowledge base, backward chaining can bypass irrelevant information, leading to a quicker resolution of the query.\n",
    "\n",
    "In summary, backward chaining's goal-directed nature makes it an effective and efficient reasoning method for answering specific, targeted questions. Its selective approach to processing information in the knowledge base allows it to be particularly efficient in terms of computational resources and time, especially when compared to methods that might require a more exhaustive examination of the knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Effective Propositional Model Checking\n",
    "\n",
    "- **Overview This section focuses on efficient algorithms for general propositional inference based on model checking. It specifically discusses two approaches: backtracking search and local hill-climbing search, which are integral to the technology of propositional logic.\n",
    "- **Context for First Reading It's suggested that this section can be skimmed on a first reading, implying its technical depth and focus on algorithmic details.\n",
    "- **Algorithms for Satisfiability (SAT Problem)\n",
    "   - The algorithms described are designed to check satisfiability, known as the SAT problem.\n",
    "   - Testing for entailment (α |= β) is achieved by testing the unsatisfiability of α ∧ ¬β.\n",
    "   - The connection between finding a satisfying model for a logical sentence and solving a constraint satisfaction problem is highlighted.\n",
    "\n",
    "####  Backtracking Algorithms\n",
    "\n",
    "\n",
    "- These algorithms resemble those discussed in Section 6.3 of the book.\n",
    "- Backtracking is a methodical way of trying out various sequences of decisions until finding one that \"works\" to solve a problem.\n",
    "- In the context of SAT, backtracking involves systematically exploring truth assignments to propositions until a satisfying assignment is found or all possibilities are exhausted.\n",
    "\n",
    "####  Local Search Algorithms\n",
    "\n",
    "\n",
    "- Similar to those in Section 6.4, local search algorithms use a different strategy.\n",
    "- Local search involves starting with a random assignment and then iteratively making small changes (such as flipping the truth value of a single proposition) to find a satisfying assignment.\n",
    "- It's a form of hill-climbing search, where each step is taken in the direction that seems to lead most directly towards a goal.\n",
    "\n",
    "####  Importance in Computer Science\n",
    "\n",
    "\n",
    "- These algorithms are crucial because many combinatorial problems in computer science can be reduced to the SAT problem.\n",
    "- Improvements in satisfiability algorithms have significant implications for our ability to manage complexity in a broad range of applications.\n",
    "\n",
    "In summary, Section 7.6 delves into advanced algorithms for propositional model checking, focusing on backtracking and local search techniques for solving the SAT problem. These methods are critical in the field of computer science, as they have wide-reaching implications for addressing complex combinatorial problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1 A Complete Backtracking Algorithm: The DPLL Algorithm\n",
    "\n",
    "- **Background The Davis-Putnam-Logemann-Loveland (DPLL) algorithm is an advanced backtracking algorithm for propositional logic, named after its developers Martin Davis, Hilary Putnam, George Logemann, and Donald Loveland. It was developed as an enhancement over the earlier Davis–Putnam algorithm.\n",
    "- **Improvements Over TT-ENTAILS? The DPLL algorithm incorporates three key improvements that make it more efficient than the basic truth table (TT) entailment-checking approach:\n",
    "\n",
    "\n",
    "- **Early Termination\n",
    "   - The algorithm can determine the truth or falsehood of a sentence with a partially completed model.\n",
    "   - This feature allows it to terminate early in many cases, avoiding the need to check every possible model fully.\n",
    "- **Pure Symbol Heuristic\n",
    "   - A pure symbol is one that consistently appears with the same polarity (either always positive or always negative) across all clauses in the sentence.\n",
    "   - The pure symbol heuristic involves selecting such symbols and assigning them a truth value that makes all clauses containing them true. This can significantly reduce the search space.\n",
    "- **Unit Clause Heuristic\n",
    "   - A unit clause is defined as a clause with only one literal, or in the context of DPLL, clauses where all literals but one are already assigned false by the model.\n",
    "   - The heuristic dictates that if a unit clause is found, the single unassigned literal must be true for the clause to be true. This provides a direct way to make assignments that satisfy part of the sentence, further pruning the search space.\n",
    "\n",
    "The DPLL algorithm represents a sophisticated approach to solving the SAT problem in propositional logic. By incorporating early termination, pure symbol, and unit clause heuristics, it improves efficiency and effectiveness compared to simpler model-checking methods, making it a valuable tool in logical reasoning and AI problem-solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2 Local Search Algorithms for Satisfiability Problems**\n",
    "\n",
    "\n",
    "- **Background Local search algorithms like Hill-Climbing and Simulated-Annealing, previously discussed in the book, can be effectively adapted for satisfiability (SAT) problems. The key is in choosing an appropriate evaluation function.\n",
    "- **Evaluation Function\n",
    "   - The goal in SAT problems is to find an assignment that satisfies all clauses.\n",
    "   - An effective evaluation function for this purpose is one that counts the number of unsatisfied clauses.\n",
    "   - This is similar to the MIN-CONFLICTS algorithm used for Constraint Satisfaction Problems (CSPs), which seeks to minimize the number of conflicts (or unsatisfied constraints).\n",
    "\n",
    "####  Approach in Local Search Algorithms\n",
    "\n",
    "\n",
    "- These algorithms operate in the space of complete assignments, flipping the truth value of one symbol at a time.\n",
    "- The search space typically contains many local minima, and randomness is required to escape from these minima.\n",
    "- A balance between greediness (systematically reducing unsatisfied clauses) and randomness (to escape local minima) is crucial.\n",
    "\n",
    "####  WALKSAT Algorithm\n",
    "\n",
    "\n",
    "- WALKSAT is a simple yet effective algorithm emerging from this approach.\n",
    "- On each iteration, it selects an unsatisfied clause and then chooses a symbol within that clause to flip.\n",
    "- The algorithm randomly chooses between a “min-conflicts” step, which minimizes the number of unsatisfied clauses, and a “random walk” step, where the symbol is chosen randomly.\n",
    "\n",
    "####  Limitations and Use Cases of WALKSAT\n",
    "\n",
    "\n",
    "- When WALKSAT finds a model, the sentence is satisfiable. However, failure to find a model doesn't definitively prove unsatisfiability—it could indicate that more time is needed.\n",
    "- WALKSAT is most effective in scenarios where a solution is expected to exist, as often is the case in problems discussed in earlier chapters.\n",
    "- It is less reliable for proving unsatisfiability or entailment, as it cannot always definitively identify when a sentence is unsatisfiable.\n",
    "- For instance, in the Wumpus World, WALKSAT might indicate that a square is likely safe after extensive searching without finding a contradictory model, but this does not constitute a formal proof.\n",
    "\n",
    "In summary, local search algorithms, particularly WALKSAT, provide a practical approach for solving SAT problems by iteratively seeking to reduce the number of unsatisfied clauses. While effective in many scenarios, their use is more suited for situations where a solution is expected and less so for formal proof of unsatisfiability or entailment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.3 The Landscape of Random SAT Problems**\n",
    "\n",
    "\n",
    "- **Variability in SAT Problem Difficulty\n",
    "   - SAT problems vary in difficulty. Some are easily solvable by basic algorithms, but due to SAT being NP-complete, certain instances inevitably require exponential run time.\n",
    "\n",
    "####  Comparative Ease of Certain Problems\n",
    "\n",
    "\n",
    "- Surprising findings from Chapter 6 illustrate this variability. For instance, the n-queens problem, seemingly difficult for backtracking search algorithms, is relatively easy for local search methods like min-conflicts.\n",
    "- This ease is due to solutions being densely distributed in the assignment space, making the n-queens problem underconstrained and thus easier to solve.\n",
    "\n",
    "####  Underconstrained SAT Problems\n",
    "\n",
    "\n",
    "- In the context of satisfiability problems, particularly those in conjunctive normal form (CNF), underconstrained problems have relatively few clauses imposing restrictions on variables.\n",
    "\n",
    "####  Random Sentence Generation and CNFk(m,n)\n",
    "\n",
    "\n",
    "- To understand random SAT problems, a method for generating random sentences is needed.\n",
    "- CNFk(m,n) refers to a k-CNF sentence with m clauses and n symbols, where clauses are chosen uniformly and independently. Each clause contains k distinct literals, randomly assigned positive or negative values, without repetition within a clause or sentence.\n",
    "\n",
    "####  Satisfiability Threshold Conjecture\n",
    "\n",
    "\n",
    "- This conjecture suggests that for every k ≥ 3, there exists a threshold ratio rk. As n increases, the probability that a CNFk(rn,n) sentence is satisfiable approaches 1 for r values below the threshold and 0 for values above it.\n",
    "- Though unproven, this thresholding effect is commonly observed in SAT problems and other NP-hard problems.\n",
    "\n",
    "####  Location of Hard Problems\n",
    "\n",
    "\n",
    "- Interestingly, the most challenging SAT problems often lie at the threshold value identified by the satisfiability threshold conjecture.\n",
    "- These threshold problems present a balance between being overconstrained and underconstrained, making them particularly difficult for algorithms to solve efficiently.\n",
    "\n",
    "In summary, the difficulty of SAT problems varies widely, with underconstrained problems being easier and overconstrained ones harder. The satisfiability threshold conjecture provides a theoretical framework for understanding the probability of satisfiability in random CNF sentences. Hard problems in SAT often occur at the conjectured threshold, presenting unique challenges for satisfiability algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ValRCS/RBS_PBM773_Introduction_to_AI/blob/main/img/ch7_logical_agents/satisfied_graph.jpg?raw=true\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Agents Based on Propositional Logic**\n",
    "\n",
    "\n",
    "- **Integration of Propositional Logic in Wumpus World Agents This section demonstrates how to apply the principles of propositional logic learned in previous sections to construct agents for the Wumpus World game.\n",
    "- **Deducing the State of the World\n",
    "   - The first step involves enabling the agent to deduce the state of the world as accurately as possible based on its percept history.\n",
    "   - This requires developing a complete logical model that details the effects of various actions within the game world.\n",
    "\n",
    "### Use of Logical Inference\n",
    "\n",
    "\n",
    "- The section explores how logical inference, such as the techniques discussed earlier, can be applied by an agent in the Wumpus World.\n",
    "- Logical inference helps the agent make decisions based on its knowledge of the world and its perceptions.\n",
    "\n",
    "### Efficient Tracking of the World State\n",
    "\n",
    "\n",
    "- A significant challenge for agents is to keep track of the world state efficiently.\n",
    "- The section discusses methods by which an agent can maintain an understanding of the world without needing to constantly refer back to its entire perceptual history.\n",
    "\n",
    "### Constructing Plans with Logical Inference\n",
    "\n",
    "\n",
    "- The agent can use logical inference to construct plans that are designed to achieve its goals.\n",
    "- These plans are based on the agent's knowledge base and are effective as long as the knowledge base accurately reflects the actual world.\n",
    "\n",
    "### Guaranteeing Goal Achievement\n",
    "\n",
    "\n",
    "- If the agent's knowledge base is a true representation of the world, the plans formulated through logical inference are guaranteed to help the agent achieve its goals.\n",
    "- This aspect highlights the importance of accurate knowledge representation and effective logical reasoning in AI agents.\n",
    "\n",
    "In summary, Section 7.7 combines the elements of propositional logic with practical agent design for the Wumpus World scenario. It covers the steps from deducing the state of the world, through efficient state tracking and logical inference, to plan construction, emphasizing the critical role of a well-structured knowledge base and robust logical reasoning in the effectiveness of AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1 The Current State of the World in Logical Agents**\n",
    "\n",
    "\n",
    "- **Agent Operation and Knowledge Base Composition\n",
    "   - Logical agents operate by deducing actions from a knowledge base (KB) comprising axioms (general knowledge about the world) and percept sentences derived from the agent's experiences.\n",
    "   - The focus here is on deducing the current state in the Wumpus World, such as the agent's location, safety of squares, etc.\n",
    "\n",
    "#### Collecting Axioms\n",
    "\n",
    "\n",
    "- Axioms are collected to represent general truths about the world and its workings.\n",
    "- They form the foundational knowledge that the agent uses to make inferences.\n",
    "\n",
    "#### Fluents and Atemporal Variables\n",
    "\n",
    "\n",
    "- A fluent is defined as an aspect of the world that changes over time.\n",
    "- Symbols representing permanent aspects of the world don't require a time superscript and are referred to as atemporal variables.\n",
    "\n",
    "#### Transition Model in Wumpus World\n",
    "\n",
    "\n",
    "- Constructing the transition model involves writing logical sentences that describe how the world changes.\n",
    "- Effect axioms are used to specify the outcomes of actions at the next time step.\n",
    "\n",
    "#### The Frame Problem\n",
    "\n",
    "\n",
    "- A challenge arises when effect axioms fail to state what remains unchanged as a result of an action. This is known as the frame problem.\n",
    "- One solution to the frame problem is to add frame axioms that explicitly assert all propositions that stay the same.\n",
    "- In a world with 'm' actions and 'n' fluents, the set of frame axioms can be large, of size O(mn), leading to what is called the representational frame problem.\n",
    "\n",
    "#### Representational Frame Problem\n",
    "\n",
    "\n",
    "- The real world has many fluents, making the representational frame problem significant.\n",
    "- Each action typically changes only a small number 'k' of fluents, indicating locality in the world.\n",
    "- Solving the representational frame problem involves defining a transition model with a set of axioms of size O(mk) rather than O(mn).\n",
    "\n",
    "#### Inferential Frame Problem\n",
    "\n",
    "\n",
    "- This problem relates to projecting forward the results of a t-step action plan.\n",
    "- The goal is to project these results in time O(kt) rather than O(nt), focusing on the fluents affected by actions rather than considering all possible fluents.\n",
    "\n",
    "#### Qualification Problem\n",
    "\n",
    "\n",
    "- The qualification problem involves specifying all the preconditions under which an action will have its intended effect.\n",
    "- This problem arises because it's often impractical to list every possible precondition for each action, especially in complex or real-world scenarios.\n",
    "\n",
    "In summary, Section 7.7.1 addresses how logical agents can deduce the current state of the world from their knowledge base. It involves understanding fluents, handling the frame and qualification problems, and efficiently modeling the effects of actions within the world. This approach forms the basis for logical agents to operate effectively in dynamic environments like the Wumpus World."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2 A Hybrid Agent for the Wumpus World**\n",
    "\n",
    "\n",
    "- **Combining Deduction with Action Rules and Problem-Solving\n",
    "   - The hybrid agent in the Wumpus World integrates the ability to deduce various aspects of the world state with condition-action rules (as seen in Section 2.4.2) and problem-solving algorithms from Chapters 3 and 4.\n",
    "   - This combination allows the agent to make informed decisions based on its understanding of the environment and predefined action strategies.\n",
    "\n",
    "#### Knowledge Base and Current Plan Maintenance\n",
    "\n",
    "\n",
    "- The agent program actively maintains and updates a knowledge base (KB) alongside a current plan for action.\n",
    "- The KB starts with atemporal axioms, which are general truths that do not depend on time, such as the relationship between breeziness in squares and the presence of pits.\n",
    "\n",
    "#### Updating the Knowledge Base\n",
    "\n",
    "\n",
    "- With each time step, the agent adds new percept sentences to its KB.\n",
    "- It also includes time-dependent axioms, like successor-state axioms, which describe how the world changes over time.\n",
    "- The section notes that axioms for future time steps are not necessary for the agent, a topic further explained in the next section.\n",
    "\n",
    "#### Logical Inference for Decision Making\n",
    "\n",
    "\n",
    "- The agent uses logical inference to ASK questions of its KB to determine safe squares and those that have not been visited.\n",
    "- This process helps the agent understand the current state of the Wumpus World and make decisions about where to move next.\n",
    "\n",
    "<li>*<em>Route Planning with A* Search</em>*:\n",
    "\n",
    "\n",
    "- For planning routes, the agent employs A* search algorithm, a different approach than using ASK for logical inference.\n",
    "- A* search is used for its efficiency in finding optimal paths, considering factors like distance and safety in the Wumpus World.\n",
    "\n",
    "In summary, Section 7.7.2 describes a hybrid agent that combines logical deduction, condition-action rules, and problem-solving algorithms to operate effectively in the Wumpus World. The agent maintains a dynamic knowledge base, utilizes logical inference for understanding the world, and employs A* search for efficient route planning. This hybrid approach enables the agent to navigate and make decisions effectively in a complex, changing environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.3 Logical State Estimation**\n",
    "\n",
    "\n",
    "- **Issue with Computational Expense in ASK Calls\n",
    "   - The previously discussed agent program becomes increasingly computationally expensive over time due to the growing complexity of ASK calls.\n",
    "   - As the agent's life progresses, inferences require revisiting more distant past events and involve an increasing number of proposition symbols.\n",
    "   - This results in longer processing times for each new percept, which is unsustainable for the agent.\n",
    "\n",
    "#### Need for Constant Update Time\n",
    "\n",
    "\n",
    "- The goal is to achieve a constant update time for processing percepts, independent of the time variable 't'.\n",
    "- The solution is to cache or save the results of inferences, allowing the agent to build on previous results rather than starting from scratch each time.\n",
    "\n",
    "#### Replacing History with Belief State\n",
    "\n",
    "\n",
    "- As discussed in Section 4.4, the extensive history of percepts and their implications can be replaced by a belief state.\n",
    "- The belief state represents the set of all possible current states of the world.\n",
    "- State estimation is the process of updating this belief state as new percepts are received.\n",
    "\n",
    "#### Challenges in Maintaining an Exact Belief State\n",
    "\n",
    "\n",
    "- Maintaining an exact belief state as a logical formula is complex.\n",
    "- With 'n' fluent symbols at time 't', there are 2^n possible states, making the representation of the belief state computationally challenging.\n",
    "\n",
    "#### Approximate State Estimation with 1-CNF Formulas\n",
    "\n",
    "\n",
    "- A common method for approximate state estimation involves representing belief states as conjunctions of literals, or 1-CNF formulas.\n",
    "- The agent program attempts to prove both Xt and ¬Xt for each symbol Xt.\n",
    "- However, this approach may result in some loss of information over time.\n",
    "\n",
    "#### 1-CNF Belief State as a Conservative Approximation\n",
    "\n",
    "\n",
    "- The 1-CNF belief state serves as a simple, conservative approximation of the exact belief state.\n",
    "- This concept of using conservative approximations for complex sets recurs in various areas of AI, offering a balance between accuracy and computational feasibility.\n",
    "\n",
    "In summary, Section 7.7.3 addresses the challenge of increasing computational expense in logical state estimation for AI agents. The solution involves using a belief state, updated as new percepts arrive, and approximating this state using 1-CNF formulas. This approach, while potentially losing some precision, maintains a manageable level of computational complexity and allows the agent to update its understanding of the world efficiently over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.4 Making Plans by Propositional Inference\n",
    "\n",
    "- **Integrating Logical Inference with Planning\n",
    "   - This section demonstrates how the agent in the Wumpus World can use logical inference, rather than A* search, to make plans.\n",
    "   - The basic approach involves constructing a sentence encompassing assertions about the initial state, transition axioms for actions up to a maximum time 't', and the goal state at time 't'.\n",
    "\n",
    "#### Steps in Propositional Planning\n",
    "\n",
    "\n",
    "- **Sentence Construction\n",
    "   - Includes assertions about the initial state (Init0), transition axioms for all possible actions (Transition1,...,Transitiont), and the goal state (e.g., HaveGoldt ∧ ClimbedOutt).\n",
    "- **SAT Solver Application\n",
    "   - The constructed sentence is presented to a SAT solver. A satisfying model indicates that the goal is achievable; unsatisfiability means the problem cannot be solved.\n",
    "- **Plan Extraction\n",
    "   - If a model is found, extract the action variables assigned true to form a plan.\n",
    "\n",
    "#### SATPLAN Algorithm\n",
    "\n",
    "\n",
    "- SATPLAN implements the approach described, with an added twist: it tries different plan lengths 't' up to a maximum Tmax to find the shortest plan.\n",
    "- This method, however, is not suitable for partially observable environments, as SATPLAN might set unobservable variables as needed for a solution.\n",
    "\n",
    "#### Knowledge Base Construction for SATPLAN\n",
    "\n",
    "\n",
    "- Building the knowledge base for SATPLAN requires care, as the requirements for satisfiability differ from those for entailment.\n",
    "- Special attention is needed to ensure the agent cannot be in two places at once, and to express that the agent can have only one orientation at a time.\n",
    "\n",
    "#### Addressing the Frame Problem\n",
    "\n",
    "\n",
    "- To prevent plans with illegal or simultaneous actions, precondition axioms and action exclusion axioms are added.\n",
    "- This allows the creation of plans that include multiple simultaneous actions only when they don't interfere with each other.\n",
    "\n",
    "#### Effectiveness of SATPLAN\n",
    "\n",
    "\n",
    "- SATPLAN effectively finds models for sentences that include initial state, goal state, successor-state axioms, precondition axioms, and action exclusion axioms.\n",
    "- It ensures that only feasible plans are generated without spurious solutions.\n",
    "\n",
    "#### Limitations and Need for More Expressive Language\n",
    "\n",
    "\n",
    "- Implementing phrases like \"for each time t\" and \"for each square [x,y]\" can be cumbersome and lead to very large knowledge bases.\n",
    "- This limitation highlights the need for a more expressive language that can naturally express these generalizations, leading to the introduction of first-order logic in Chapter 8.\n",
    "\n",
    "In summary, Section 7.7.4 presents a method for constructing plans using propositional inference in the Wumpus World. This approach, encapsulated in the SATPLAN algorithm, is more declarative and avoids the computational intensity of generating and storing millions of sentences. However, it also reveals the limitations of propositional logic in expressing general rules across time and space, setting the stage for the introduction of first-order logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Summary: Logical Agents**\n",
    "\n",
    "\n",
    "- **Introduction to Knowledge-Based Agents\n",
    "   - The chapter introduces knowledge-based agents and the logic required for these agents to reason about the world.\n",
    "\n",
    "#### Knowledge as a Basis for Decision Making\n",
    "\n",
    "\n",
    "- Intelligent agents need knowledge about the world to make informed decisions.\n",
    "- This knowledge is stored in a knowledge representation language within the agent's knowledge base.\n",
    "\n",
    "#### Components of a Knowledge-Based Agent\n",
    "\n",
    "\n",
    "- A knowledge-based agent consists of a knowledge base and an inference mechanism.\n",
    "- It operates by storing sentences about the world, inferring new sentences, and using these inferences to decide on actions.\n",
    "\n",
    "#### Representation Language: Syntax and Semantics\n",
    "\n",
    "\n",
    "- The representation language is defined by syntax (structure of sentences) and semantics (truth of sentences in each possible world or model).\n",
    "\n",
    "#### Entailment and Inference\n",
    "\n",
    "\n",
    "- Entailment is a key concept, where a sentence α entails β if β is true in all worlds where α is true.\n",
    "- Inference is the process of deriving new sentences from existing ones, with sound algorithms only deriving entailed sentences and complete algorithms deriving all entailed sentences.\n",
    "\n",
    "#### Propositional Logic\n",
    "\n",
    "\n",
    "- Propositional logic includes proposition symbols and logical connectives.\n",
    "- It deals with propositions that are either true, false, or unknown.\n",
    "\n",
    "#### Model-Checking Inference Algorithms\n",
    "\n",
    "\n",
    "- Given a fixed vocabulary in propositional logic, entailment can be checked by enumerating models.\n",
    "- Efficient model-checking inference algorithms include backtracking and local search methods.\n",
    "\n",
    "#### Inference Rules and Proof Methods\n",
    "\n",
    "\n",
    "- Inference rules like the resolution rule provide a complete algorithm for knowledge bases in conjunctive normal form (CNF).\n",
    "- Forward chaining and backward chaining are natural reasoning algorithms for Horn form knowledge bases.\n",
    "\n",
    "#### Local Search Methods\n",
    "\n",
    "\n",
    "- Algorithms like WALKSAT use local search methods to find solutions, being sound but not complete.\n",
    "\n",
    "#### Logical State Estimation\n",
    "\n",
    "\n",
    "- Involves maintaining a logical sentence that describes possible states consistent with observation history.\n",
    "- Each update step requires inference using the transition model of the environment, built from successor-state axioms.\n",
    "\n",
    "#### Decision Making in Logical Agents\n",
    "\n",
    "\n",
    "- Decisions can be made using SAT solving, which finds possible models for future actions that achieve goals.\n",
    "- Effective only in fully observable or sensorless environments.\n",
    "\n",
    "#### Limitations of Propositional Logic\n",
    "\n",
    "\n",
    "- Propositional logic lacks expressive power for unbounded environments, as it can't concisely handle time, space, and universal patterns of relationships among objects.\n",
    "\n",
    "The chapter provides a comprehensive overview of how logical agents use knowledge and inference to make decisions, the structure and application of propositional logic, and the limitations of this logic in complex environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical and Biographical Notes Summary**\n",
    "\n",
    "\n",
    "- **Origins in AI and Declarativism\n",
    "   - John McCarthy's paper \"Programs with Common Sense\" (1958, 1968) introduced the idea of agents using logical reasoning. It emphasized declarativism, advocating for telling agents what they need to know.\n",
    "   - Allen Newell's article \"The Knowledge Level\" (1982) argued that rational agents can be understood at an abstract level based on their knowledge rather than their programs.\n",
    "\n",
    "#### Early History of Logic\n",
    "\n",
    "\n",
    "- Logic originated in ancient Greek philosophy, with contributions from Plato on sentence structure and truth, and Aristotle's systematic study in his work \"Organon.\"\n",
    "- The Megarian and Stoic schools studied logical connectives and truth tables. The Stoics recognized five basic inference rules, including Modus Ponens.\n",
    "\n",
    "#### Mechanical Inference and Formal Logic Systems\n",
    "\n",
    "\n",
    "- Wilhelm Leibniz proposed reducing logical inference to a mechanical process.\n",
    "- George Boole introduced a formal logic system in \"The Mathematical Analysis of Logic\" (1847). Extensions to his work led to modern propositional and first-order logic.\n",
    "- The Stanhope Demonstrator and William Stanley Jevons's \"logical piano\" were early mechanical devices for logical inferences.\n",
    "\n",
    "#### Early Computational Logic\n",
    "\n",
    "\n",
    "- Martin Davis (1954) and the Logic Theorist by Newell, Shaw, and Simon (1957) were among the first programs for logical inference.\n",
    "- Emil Post and Ludwig Wittgenstein independently used truth tables for propositional logic validity testing.\n",
    "\n",
    "#### Advancements in Propositional Logic\n",
    "\n",
    "\n",
    "- The Davis–Putnam algorithm and the DPLL backtracking algorithm significantly improved efficiency in propositional resolution.\n",
    "- Stephen Cook (1971) identified the SAT problem in propositional logic as NP-complete.\n",
    "- Early research showed polynomial average-case complexity for DPLL in certain problem distributions.\n",
    "\n",
    "#### Local Search Algorithms and SAT Solvers\n",
    "\n",
    "\n",
    "- Local search algorithms like GSAT and WALKSAT proved effective for solving hard problems quickly.\n",
    "- SAT solvers evolved rapidly, with innovations like watched literal indexing and clause learning techniques. CHAFF solver emerged as a significant development.\n",
    "\n",
    "#### Random SAT Problems and Phase Transitions\n",
    "\n",
    "\n",
    "- The \"phase transition\" phenomenon in random k-SAT problems attracted much research due to its connection to statistical physics.\n",
    "- Survey propagation algorithms showed great efficiency near satisfiability thresholds.\n",
    "\n",
    "#### Agents Using Propositional Logic\n",
    "\n",
    "\n",
    "- The concept dates back to McCulloch and Pitts (1943), with subsequent developments by Stan Rosenschein and Rod Brooks.\n",
    "- NASA’s hybrid agents combine reasoning and circuits for spacecraft control.\n",
    "\n",
    "#### State Estimation and Planning with Propositional Representations\n",
    "\n",
    "\n",
    "- The temporal-projection problem and state estimation with propositional variables were key research areas.\n",
    "- SATPLAN emerged as an effective planning tool, leveraging advancements in SAT solvers.\n",
    "\n",
    "#### The Frame Problem\n",
    "\n",
    "\n",
    "- First recognized by McCarthy and Hayes (1969), it led to research in nonmonotonic logics. Ray Reiter's successor-state axioms provided a solution.\n",
    "\n",
    "#### Industrial Applications of Propositional Solvers\n",
    "\n",
    "\n",
    "- Used in various applications, including computer hardware synthesis and security protocol analysis.\n",
    "\n",
    "#### Wumpus World as a Testbed\n",
    "\n",
    "\n",
    "- Created by Gregory Yob (1975) and adapted into AI research by Michael Genesereth, the Wumpus World serves as an agent testbed in a simplified grid environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula:  (a ∨ b)\n",
      "Valuation for {a} :  True\n",
      "Counterexample:  set()\n",
      "Formula:  (a → b)\n",
      "Valuation for {a} :  False\n",
      "Counterexample:  {a}\n",
      "Formula:  (a ↔ b)\n",
      "Valuation for {a} :  False\n",
      "Counterexample:  {b}\n",
      "Formula:  (a ∧ b)\n",
      "Valuation for {a, b} :  True\n",
      "Counterexample:  set()\n",
      "Formula:  ((a ∧ b) ∧ c)\n",
      "Valuation for {a, b} :  False\n",
      "Counterexample:  set()\n"
     ]
    }
   ],
   "source": [
    "from lib.logic_formula import Atom\n",
    "# from https://gist.github.com/gvx/2185287\n",
    "\n",
    "a = Atom('a')\n",
    "b = Atom('b')\n",
    "c = Atom('c')\n",
    "\n",
    "def dop(f, e):\n",
    "\tprint(\"Formula: \", f)\n",
    "\tprint(\"Valuation for\", e, \": \", f.v(e))\n",
    "\tprint(\"Counterexample: \", f.t())\n",
    "\n",
    "dop(a | b, {a})\n",
    "dop(a >> b, {a})\n",
    "dop(a << b, {a}) # not part of our logic\n",
    "dop(a & b, {a,b})\n",
    "dop(a & b & c, {a,b})\n",
    "\n",
    "# TODO explore this library a bit more\n",
    "# TODO add it to our wumpus project\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
